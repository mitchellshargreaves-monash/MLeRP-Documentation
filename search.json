[
  {
    "objectID": "tutorials/2_dask_offloading.html",
    "href": "tutorials/2_dask_offloading.html",
    "title": "Dask Offloading",
    "section": "",
    "text": "Testing with a LocalCluster\nOnce you’ve written your function and are ready to move things over to . Working with Dask workers introduces another layer of complexity where things can go wrong, which make Dask LocalClusters the easiest way to prepare your code for offloading. This will mean that code will execute in the notebook session, just like running your function straight, allowing you to view print statements and debug errors normally rather than dealing with remote code execusion before we’re ready. Once you’re satisfied with your code you can switch over to a SLURMCluster to accelerate with GPU.\n\nfrom distributed import Client, LocalCluster\n\ncluster = LocalCluster()\nclient = Client(cluster)\n\nWe can submit our function to the cluster with the client.submit method. This will return a future which can be unpacked with its result using future.result(). We can see the outputs of print statements while we’re using a LocalCluster. Print statements will not be visible when executing remotely with SLURMCluster. Similarly, the full stack trace is still visible when an error or assertion is raised within the function.\n\ndef client_test(input1, input2, error=False, test=False):\n    # Force an error\n    if error:\n        assert 0 == 1\n    \n    # Stop after one batch when testing        \n    if test: \n        print(\"When running in a local cluster you can see print statements!\")\n\n    return input1, input2\n\n\nfuture = client.submit(client_test, \"input1\", \"input2\", test=True)\nfuture.result()\n\nWhen running in a local cluster you can see print statements!\n\n\n('input1', 'input2')\n\n\n\nfuture = client.submit(client_test, \"input1\", \"input2\", error=True)\nfuture.result()\n\n2024-05-31 06:32:22,017 - distributed.worker - WARNING - Compute Failed\nKey:       client_test-821dd3f7995546bf5d9280be38a9afd3\nFunction:  client_test\nargs:      ('input1', 'input2')\nkwargs:    {'error': True}\nException: 'AssertionError()'\n\n\n\nAssertionError: \n\n\n\nclient.shutdown()\n\n\n\nRunning on a SLURMCluster\nWe can pass in extra SLURM requirements in job_extra_directives to request a GPU for our jobs. To read more about configuring the SLURMCluster to interact with the SLURM queue, go to Dask’s jobqueue documentation.\n\nfrom dask_jobqueue import SLURMCluster\nfrom distributed import Client\ncluster = SLURMCluster(\n    memory=\"128g\", processes=1, cores=16, job_extra_directives=[\"--gres=gpu:1\", \"--partition=BigCats\"]\n)\n\ncluster.scale(1)\nclient = Client(cluster)\n\nSince this code is executing remotely we won’t see our print statements\n\nclient.submit(client_test, \"input1\", \"input2\", test=True).result()\n\n('input1', 'input2')\n\n\nDask will raise any errors that the process triggers locally, even when executing remotely - but you may not get the full stack trace\n\nclient.submit(client_test, \"input1\", \"input2\", error=True).result()\n\nAssertionError: \n\n\nIf you’re working with any objects that are particularly memory intensive, you can consider using the client.scatter method to scatter large objects out to our workers ahead of time for more efficient execution.\n\nlarge_object = \"Let's pretend that this string is actually a really big object like your dataset\"\ninput1_future = client.scatter(large_object)\nclient.submit(client_test, input1_future, \"input2\").result()\n\n(\"Let's pretend that this string is actually a really big object like your dataset\",\n 'input2')\n\n\n\nclient.shutdown()\n\n2024-05-31 06:32:32,584 - distributed.scheduler - ERROR - Removing worker 'tcp://192.168.0.208:38481' caused the cluster to lose scattered data, which can't be recovered: {'str-aed0f69a5b2b8dbc59a28f905628b181'} (stimulus_id='handle-worker-cleanup-1717137152.584407')\n\n\nIf needed we can be more specific about the specific GPU type and QoS we need if we have more complex requirements.\n\ncluster = SLURMCluster(\n    memory=\"128g\", processes=1, cores=16, job_extra_directives=[\"--gres=gpu:3g.20gb:1\", \"--qos=lion\", \"--partition=BigCats\"]\n)\n\ncluster.scale(1)\nclient = Client(cluster)\n\n\nclient.submit(client_test, \"input1\", \"input2\", test=True).result()\n\n('input1', 'input2')"
  },
  {
    "objectID": "tutorials/4_submitit_pytorch.html",
    "href": "tutorials/4_submitit_pytorch.html",
    "title": "PyTorch and Submitit",
    "section": "",
    "text": "Defining models, datasets and functions\nIf you’re doing something relatively simple, Dask has integrations with Scikit-Learn and XGBoost. You can also pass PyTorch models into Scikit-Learn with Skorch and TensorFlow models with SciKeras.\nBut if you need to do something more complex, using SubmitIt to remotely execute code gives us the low level control to implement whatever bespoke algorithm we want and have it accelerated by remote GPUs.\nIn this example we’re going to write our own PyTorch functions to train a custom model on the CIFAR dataset. While we could do this with Skorch, we hope that this example gives you some idea of how Dask can be flexible enough for any applications that you need.\nContent adapted from the PyTorch CIFAR10 Tutorial\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.multiprocessing as mp\n\n# Define data transformations\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n# Define dataset and dataloader\nbatch_size = 1024\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\nvalidset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                        download=True, transform=transform)\n\n# Note that we need to set the multiprocessing context so that PyTorch doesn't get\n# PyTorch likes to use 'forking' while Dask uses 'spawn'\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=16, multiprocessing_context=mp.get_context(\"fork\"))\nvalidloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n                                          shuffle=True, num_workers=16, multiprocessing_context=mp.get_context(\"fork\"))\n\nFiles already downloaded and verified\nFiles already downloaded and verified\n\n\n/apps/mambaforge/envs/dsks_2024.06/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n\n\nNote that this cell may warn us that there is a mismatch between our requested resources and the number of worker processes. This is ok, as we have sized this DataLoader to match the Dask worker that we request later on.\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Define loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Define a simple conv net\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Convolutional layers\n        self.conv1 = nn.Conv2d(3, 16, 3, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(16, 16, 3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(16, 32, 3, stride=2, padding=1)\n        self.conv4 = nn.Conv2d(32, 32, 3, stride=1, padding=1)\n        self.conv5 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n        self.conv6 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(4 * 4 * 64, 4 * 64)\n        self.fc2 = nn.Linear(4 * 64, 64)\n        self.fc3 = nn.Linear(64, 10)\n\n    def forward(self, x):\n        # Pass through convolution layers\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = F.relu(self.conv5(x))\n        x = F.relu(self.conv6(x))\n\n        # Flatten all dimensions except batch\n        x = torch.flatten(x, 1)  \n\n        # Pass through fully connected layers\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nThis train function will load any saved state for the provided model, then train for a number of epochs. When its done it will then save the state and return the average loss of the last epoch.\n\nimport torch.optim as optim\nfrom tqdm.notebook import tqdm\n\n\n# loader: train dataloader\n# arch: model archetechture for training\n# path: model path for load and save\n# load: whether to load model from path\n# save: whether to save model to path\n# test: only run one batch for testing\n# error: throw an assertion error\n# return: average loss of epoch or loss of one batch if testing\ndef train(loader, arch=Net, path=\"./model\", epochs=1, load=False, save=True, test=False):\n    model = arch()\n    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n    device = \"cuda\" if torch.cuda.is_available() and not test else \"cpu\"\n    \n    # Load state from disk so that we can split up the job\n    if load: \n        state = torch.load(path, map_location=\"cpu\")\n        model.load_state_dict(state[\"model\"])\n        model.to(device)\n        optimizer.load_state_dict(state[\"optimizer\"])\n    else:\n        model.to(device)\n    \n    # A typical PyTorch training loop\n    model.train()\n    for _ in range(epochs):\n        running_loss = 0\n        \n        for i, (inputs, labels) in enumerate(loader):\n            # put the inputs on the device\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.detach().item()\n    \n    # Save model after each epoch\n    if save:\n        torch.save({\n            \"model\": model.state_dict(),\n            \"optimizer\": optimizer.state_dict()\n            }, path)\n    \n    return running_loss / len(loader) if not test else loss.detach().item()\n\nThis valid function will load the state of the model we’ve defined, then calculate the average loss and accuracy over the dataset.\n\n# loader: train dataloader\n# arch: model archetechture for validating\n# path: model path for load and save\n# return: average loss and accuracy of epoch\ndef valid(loader, arch=Net, path=\"./model\"):\n    # Initialise device\n    model = arch()\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    # Load state from disk so that we can split up the job\n    state = torch.load(path, map_location=\"cpu\")\n    model.load_state_dict(state[\"model\"])\n    model.to(device)\n    model.eval()\n    \n    # A typical PyTorch validation loop\n    running_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(loader):\n            # put the inputs on the device\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # forward\n            outputs = model(inputs)\n            \n            # loss\n            loss = criterion(outputs, labels)\n            running_loss += loss.detach().item()\n            \n            # accuracy\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    return running_loss / len(loader), correct / total\n\n\n\nTesting locally\n\ntrain(trainloader, test=True)\n\n2.065371513366699\n\n\n\n\nTraining with a SubmitIt\n\nimport submitit\n\n# Define where we'd like submitit to place our logs\nexecutor = submitit.AutoExecutor(folder='~/submitit_logs')\n\n# Define the parameters of our slurm job\n# Just like Dasks' job_extra_directives, additional_parameters allows us to specify things that submitit doesn't support directly\nexecutor.update_parameters(timeout_min=30, mem_gb=128, cpus_per_task=16, slurm_partition=\"BigCats\", slurm_additional_parameters={\"gres\": \"gpu:2g.10gb:1\"})\n\n\n# First test offloading before we run the full training loop\nexecutor.submit(train, trainloader, test=True).result()\n\n2.058852434158325\n\n\nFinally we can bring everything together and run our training loop.\n\n# Run the training loop\nepochs = 5\nwith tqdm(total=(epochs)) as pbar:\n    for epoch in range(epochs):\n        train_loss = executor.submit(train, trainloader, load=(epoch &gt; 0)).result()\n        valid_loss, accuracy = executor.submit(valid, validloader).result()\n        pbar.update()\n        pbar.set_postfix(loss=train_loss)\n        print( f\"epoch: {epoch}, train_loss: {train_loss : .3f}, valid_loss: {valid_loss : .3f}, accuracy: {accuracy : .3f}\")\n\n\n\n\nepoch: 0, train_loss:  2.273, valid_loss:  2.119, accuracy:  0.224\nepoch: 1, train_loss:  1.998, valid_loss:  1.928, accuracy:  0.294\nepoch: 2, train_loss:  1.872, valid_loss:  1.807, accuracy:  0.333\nepoch: 3, train_loss:  1.770, valid_loss:  1.720, accuracy:  0.365\nepoch: 4, train_loss:  1.702, valid_loss:  1.654, accuracy:  0.385\n\n\nNote how in this example we offload every epoch as its own function. If your model or dataset is large, you may find it more efficient to submit multiple epochs to be trained per batch. In doing so, consider specifying larger GPU sizes and using the lion qos if the 30 minute joblength for Cheetah is too short.\n\n\nMeasuring the offloading overhead\nOffloading tasks doesn’t come for free, there is an initial cost associated with sending the data to a remote device. Let’s compare the time it would take to train a Resnet18 on CIFAR for a range of epochs comparing a local GPU, a remote GPU using Dask and a remote GPU using Dask with a scattered dataset. For this expriment we will not bother saving the weights afterwards since this should be relatively constant between methods.\nNote that this test was run directly on the compute node to gain direct access to the GPUs to measure overheads. You will only be able to mimic our results for the final graph if you’re running with an inbuilt GPU (Tabby service) since it compares reserved GPUs with Dask driven GPU jobs. Running this cell in a lion service will likely freeze the notebook since you’d have no accelleration.\n\nfrom torchvision.models import resnet18\nfrom time import time\n\n# Store times in arrays\nlocal = []\nremote = []\nscatter = []\n\n# Test some number of epochs\nepoch_list = [1, 2, 3, 5, 10]\nwith tqdm(total=(len(epoch_list) * 3)) as pbar:\n    for num_epochs in epoch_list:\n        \n        # Local GPU\n        start = time()\n        train(trainloader, arch=resnet18, epochs=(num_epochs + 1), save=False)\n        local.append(time() - start)\n        pbar.update()\n        \n        # Remote GPU\n        start = time()\n        client.submit(train, trainloader, arch=resnet18, epochs=(num_epochs + 1), save=False).result()\n        remote.append(time() - start)\n        pbar.update()\n        \n        # Remote GPU with scatter\n        start = time()\n        trainloader_future = client.scatter(trainloader)\n        client.submit(train, trainloader_future, arch=resnet18, epochs=(num_epochs + 1), save=False).result()\n        scatter.append(time() - start)\n        pbar.update()\n\n\nimport matplotlib.pyplot as plt\nfrom itertools import chain\n\ndata = list(chain(*zip(local, remote, scatter)))\ncolumns = []\nfor num_epochs in epoch_list:\n    for test in [\"local\", \"remote\", \"scatter\"]:\n        columns.append(test + \" \" + str(num_epochs))\n\nplt.bar(range(len(data)), data, tick_label=columns)\nplt.xticks(rotation=90)\nplt.xlabel(\"Experiment\")\nplt.ylabel(\"Seconds\")\nplt.title(\"Runtime comparison for local, remote and scatter\")\nplt.show()\n\n\n\n\nFrom this experiment we can see that the cost associated with running code remotely is small, and the impact decreases with the size of the function that we submit. It also shows that it always makes sense to scatter large objects before computing, even for small jobs.\n\nclient.shutdown()"
  },
  {
    "objectID": "tutorials/1_dask_slurm.html",
    "href": "tutorials/1_dask_slurm.html",
    "title": "Dask SLURMClusters",
    "section": "",
    "text": "The MLeRP notebook environment uses Dask SLURMClusters to create a middle ground that has the interactivity of a notebook backed by the power of a GPU Cluster. This notebook shows how you can use the lion service to use a CPU based notebook session for your basic analysis and code development. Then, when you’re ready to run tests you will use Dask to submit your python functions to the SLURM queue.\nThis enables:\n\nFlexibility to experiment with your dataset interactively\nAbility to change compute requirements such as RAM, size of GPU, number of processes and so on… without ever leaving the notebook environment\nElastic scaling of compute\nEfficient utilisation of the hardware\nReleasing of resources when not in use\n\n\nfrom dask_jobqueue import SLURMCluster\nfrom distributed import Client, LocalCluster\nimport dask\n\n# Point Dask to the SLURM to use as it's back end\ncluster = SLURMCluster(\n    memory=\"64g\", processes=1, cores=8\n)\n\n# Scale out to 4 nodes\nnum_nodes = 4\ncluster.scale(num_nodes)\nclient = Client(cluster)\n\nDask will now spin our jobs up in anticipation for work to the scale that you specify.\nYou can check in on your jobs like you would with any other SLURM job with squeue.\n\n!squeue\n\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n               933   BigCats dask-wor mhar0048 PD       0:00      1 (None)\n               932   BigCats dask-wor mhar0048 PD       0:00      1 (None)\n               931   BigCats dask-wor mhar0048 PD       0:00      1 (None)\n               930   BigCats dask-wor mhar0048 PD       0:00      1 (None)\n               919   BigCats Jupyter  ramachap  R      51:44      1 mlerp-monash-node00\n               920   BigCats Jupyter  ramachap  R      47:22      1 mlerp-monash-node00\n               916   BigCats Jupyter    charla  R    5:02:19      1 mlerp-monash-node00\n\n\nYou can modify the output of squeue to work for you by passing in flags.\n\n!squeue --me --format \"%.8P %.15j %.8T %.10M %.12L %.4C %.7m %R %q\"\n\nPARTITIO            NAME    STATE       TIME    TIME_LEFT CPUS MIN_MEM NODELIST(REASON) QOS\n BigCats     dask-worker  RUNNING       0:00        30:00    8     60G mlerp-monash-node00 cheetah\n BigCats     dask-worker  RUNNING       0:00        30:00    8     60G mlerp-monash-node00 cheetah\n BigCats     dask-worker  RUNNING       0:00        30:00    8     60G mlerp-monash-node00 cheetah\n BigCats     dask-worker  RUNNING       0:00        30:00    8     60G mlerp-monash-node00 cheetah\n\n\nAlternatively, we can use the adapt method, which will let us scale out as we need the compute… and scale back when we’re idle letting others use the cluster.\nWe reccommend that you use the adapt method while you’re actively developing your code so that you don’t need to worry about cleaning up after yourself. The scale method can be used when you’re ready to run longer tests with higher utilisation.\n\ncluster.adapt(minimum=0, maximum=num_nodes)\n\n&lt;distributed.deploy.adaptive.Adaptive at 0x7fcf13681270&gt;\n\n\n\n# You may need to run this cell a few times while waiting for Dask to clean up\n!squeue\n\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n               919   BigCats Jupyter  ramachap  R      51:44      1 mlerp-monash-node00\n               920   BigCats Jupyter  ramachap  R      47:22      1 mlerp-monash-node00\n               930   BigCats dask-wor mhar0048  R       0:00      1 mlerp-monash-node00\n               931   BigCats dask-wor mhar0048  R       0:00      1 mlerp-monash-node00\n               932   BigCats dask-wor mhar0048  R       0:00      1 mlerp-monash-node00\n               933   BigCats dask-wor mhar0048  R       0:00      1 mlerp-monash-node00\n               916   BigCats Jupyter    charla  R    5:02:19      1 mlerp-monash-node00\n\n\nDask has a UI that will let you see how the tasks are being computed. You won’t be able to connect to this with your web browser but VSCode and Jupyter have extensions for you to connect to it.\nUse the loopback address: http://127.0.0.1:8787 (Adjust the port to the one listed when you make the client if needed)\nNow let’s define a dask array and perform some computation. Dask arrays are parallelised across your workers nodes so they can be greater than the size of one worker’s memory. Dask evaluates lazily, retuning ‘futures’ which record the tasks needed to be completed in the compute graph. They can be computed later for its value.\nDask also has parallelised implementations of dataframes and collections of objects (called bags). These are written to be as similar as possible to familiar libraries like numpy, pandas and pyspark. You can read more about arrays, dataframes and bags with Dask’s documentation.\n\nimport dask.array as da\nx = da.random.random((1000, 1000, 1000))\nx  # Note how the value of the array hasn't been computed yet\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n7.45 GiB\n126.51 MiB\n\n\nShape\n(1000, 1000, 1000)\n(255, 255, 255)\n\n\nDask graph\n64 chunks in 1 graph layer\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\n\n\nYou can check squeue while this is running to see the jobs dynamically spinning up to perform the computation.\n\nx[0][0][:10].compute()\n\narray([0.66750137, 0.25089681, 0.7443936 , 0.7159385 , 0.09395558,\n       0.86980697, 0.11161041, 0.28340384, 0.19653293, 0.69794351])\n\n\nFinally, we can shut down the SLURMCluster now that we’re done with it.\n\n# Shut down the cluster\nclient.shutdown()\n\n2023-11-23 05:05:33,925 - distributed.deploy.adaptive_core - INFO - Adaptive stop"
  },
  {
    "objectID": "release/notes008.html",
    "href": "release/notes008.html",
    "title": "Release Notes #8",
    "section": "",
    "text": "Hello MLeRP users,\nML4AU is planning a series of webinars for AI Month (14 Oct - 15 Nov). As a part of this, we would love to hear from some of you MLeRP Users! If you’re doing some exciting ML or AI work on our platform and would like to share it with the community, please reach out to us.\nOur first major change is that we have updated our old Terminal app. The new Terminal runs on xterm rather than hterm which hasn’t been updated recently. It also gives us some more flexibility in that we can we can pass it commands to run other apps - which we have taken advantage of to run our ‘View Log’ feature.\nWe’ve also used it to develop our new Ollama app, which you may have noticed crop up in your side bar. If you’re interested in playing around with large language models, but aren’t sure where to start, this could be a good way to experiment. For now we’ve preloaded the phi3, mistral, mixtral and two variants of llama3, but more models are available on request. Opening the app will give you a chat window with your model of choice for you to interact with directly.\nHowever, Ollama also supports interaction through a python API. We’ve put together a tutorial showcasing this which involves using a model to summarise Wikipedia articles. If you’re a more advanced user and want to experiment with Ollama more directly, you will be should be able to run the program directly which is installed at /apps/ollama/ollama. Note that doing so will use your home directory to store your model repository, but this can be reconfigured if you need to reroute it to use a project directory.\nAs always, we hope these changes will improve your experience, please let us know if you find any issues or ways that you think we can improve.\nRegards,\nMitchell Hargreaves"
  },
  {
    "objectID": "release/notes003.html",
    "href": "release/notes003.html",
    "title": "Release Notes #3",
    "section": "",
    "text": "Hello MLeRP users,\nWe’re pleased to announce that we now have a better UI solution to use conda environments with our new Jupyter Lab app. Now, rather than each app being tied to a given conda environment and requiring users to create a new app to support their own environments, we are using a dropdown which will allow you to select from any of the environments we provide, or any that you provide for yourself.\nThe dropdown is populated using your ~/.conda/environments.txt​ file which conda should maintain as you create new installations of miniconda or mamba. This means that the app should automatically pick up any new environments that you create with no input from yourself. If for whatever reason this doesn’t happen and you can’t find the environment that you’re looking for, you can manually append a new environment to the file with this command:\necho /path/to/your/environment &gt;&gt; ~/.conda/environments.txt​\nWe have also used this opportunity to come out with a new version of DSKS that addresses some of the shortcomings with the previous version. The environment now has more packages to support a wider range of data types and tools, for a full list visit the DSKS environment’s page.\nIf you still need to use the old version of DSKS, it’s still there just renamed. From now on, we will be versioning the environments that we release, tagging them with the year and month that they were built. The old version of DSKS that you are familiar with can now be accessed as dsks_2023.05, while the new version can be accessed as dsks_2023.10​. Similarly, the DSKS specific Jupyter App will point to this renamed environment. A full list of every environment that we support will be available on this new page of our documentation. There’s only 2 versions of DSKS there now, but we’re sure that the list will grow as we get more requests for packages and functionality. If you have a curated environment that you think would be suitable for other users, let us know and we’ll see what we can do.\nWe are also going to be deprecating the Base Jupyter Lab application. The Base Jupyter Lab application has always been in a weird place in that it simultaneously has too many packages to be representative of a basic python installation, but not enough for the kind of useful data science that we expect from users in the system. The app was originally written to work isolated within a singularity container, but as we move towards providing environments through our mambaforge installation continuing to maintain this unicorn environment seemed more trouble as it was worth, especially since the DSKS environments offer as a superset of it’s functionality and the base environment that is created in a mambaforge install is more suitable for minimal applications.\nPlease let us know how the new Jupyter Lab app works for you. If this experiment goes well, we’ll also deprecate the old DSKS specific Jupyter Lab since you can still reach that environment by selecting it in the environment dropdown.\nRegards,\nMitchell Hargreaves"
  },
  {
    "objectID": "release/notes007.html",
    "href": "release/notes007.html",
    "title": "Release Notes #7",
    "section": "",
    "text": "Hello MLeRP users,\nThe most important change that we’ve making is that we’re revising our policy on GPU reservations. After many requests we are now allowing 20GB Reservations through the Tabby QoS. Why now? The short answer is we realised that there are some packages, such some hugging face libraries, which are built in a way that makes Dask offloading very difficult. As a result we’re now repartitioning the HouseCats nodes into a total of 8 10GB slices and 4 20GB slices. We’ve also used this as an opportunity to rethink how we’d like to position the BigCats nodes, so now we are devoting 2 nodes to whole 40 GB GPUs for batch work, bringing us up to 4 whole GPUs in the pool.\nThe second most important change that we’ve made is that we’ve updated our version of SLURM. This is important because it patches some errant behaviour we’ve caught on some GPU interactions which would allow some users to use unallocated GPUs. If you were previously using this exploit, please make sure that you request a GPU reservation if you need to use one, or use Dask to offload your work to the SLURM queue. Similarly, if you were a user that needed to manually set the CUDA_VISIBLE_DEVICES environment variable, please note that you likely won’t need to anymore and doing so could negatively impact your job.\nTo acknowledge our most visible change, in the inbetween months you may have noticed a new app appear, VS Code Server. This app acts as yet one more way for users to log in to cluster. It gives users the ability to run an instance of Code Server on MLeRP and connect through their web browser without the need to manage an SSH connection or connect with their own VS Code instance.\nTo facilitate another common request that we’ve had, if you’d like to work with R as a part of your data science workflow, now you can do that on MLeRP too. While we don’t support R Studio as a part of Strudel2, VS Code has a robust R plugin ecosystem that can be used as your R development environment. We recommend maintaining your R virtual environment using the renv package so that you can ensure isolation, portability and reproducibility in your environments.\nWe’ve also been hard at work in refining our API to improve the web experience of Strudel2. Many of these changes are invisible to you all, but this change allows us to specify a tunnelid for each app, taking the guesswork out of which app to connect to. This should patch the bug where Strudel2 connects to the wrong log or app if you try and open multiple apps too close together. We hope that this change will make apps like the batch app much more usable.\nAs always, we hope these changes will improve your experience, please let us know if you find any issues or ways that you think we can improve.\nRegards,\nMitchell Hargreaves"
  },
  {
    "objectID": "release/notes005.html",
    "href": "release/notes005.html",
    "title": "Release Notes #5",
    "section": "",
    "text": "Hello MLeRP users,\nIn the weeks since launching the platform’s open beta, we have provisioned over 60 additional individual accounts for the system, bringing our total to almost 80 users which has certainly kept us busy! We have also provisioned 7 group allocations ranging in size from 2-6 members. As always, if you’d like to ammend your allocation’s quota or would like to consider a group allocation to collaborate with others, talk to us and we’ll see what we can do for you.\nSpeaking of the launch, if you missed our launch webinar, the event was recorded and is available here. In it we discussed the guiding principles that we used when designing MLeRP along with an overview of the services that we offer as a part of the platform.\nTo accommodate this increase in users we have expanded into a second file system, bringing our total file storage for user data up to 40 TB. As a part of this refactor, all users will have a link to their allocation from the /home directory, meaning that your code will not need to change depnding on where your allocation actually sits.\nWe also expanded our applications volume dramatically, now weighing in at 500 GB, to allow us to continue to bring you new installations of software. As a part of this migration we found that the original DSKS environment dsks_2023.05 could not be rebuilt due to some of the packages being deprecated. If you need it to rerun some legacy code, this environment is still accessible as a conda-pack at /apps/conda-packs/dsks_2023.05. Note that we haven’t found a way to make a conda-pack work with our Jupyter App yet so this will only support scripts. If you need to convert your notebook into a script, consider using nbconvert which is available in any of our DSKS environments.\nOne of the new offerings we’ve developed with one of our users is a new conda environment for our Jupyter App that features the Detectron2 and Segment Anything packages by Facebook Research. You can view the full environment definition and package list here.\nIf you’ve been working on an environment that you think will be useful to others in your field you want to share with others on the platform, we want to hear from you. Let us know and we’ll help you make it available to everyone.\nIf you’d like to work with software that we don’t currently have installed on the platform, that does not mean that we won’t be able to support you. It just means that you’ll need to be patient and willing to help blaze the path with us so that we can extend the functionality of the platform for you. You are also free to install anything into your allocation that only requires using user space. Sometimes this just means that rather than using apt or apt-get you will need to get the software from conda-forge.\nThe increase in scale has also come with a new set of challanges, especially regarding the Strudel2 API. We apologise for the instability that some of you will have experienced in this time. We have since rolled out a new version of Strudel2 which should be more performant and robust, as well as adding additional safeguards to prevent the whole system coming down if some users encounter unexpected states.\nIf you experience any unexpected behaviour from the file system, the Strudel2 web page or anywhere else on the system, do not hesitate to reach out to us and we will work with you to resolve the issue.\nRegards,\nMitchell Hargreaves"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Machine Learning eResearch Platform (MLeRP)",
    "section": "",
    "text": "Say we have a researcher who is a domain expert in a field and is just discovering that machine learning algorithms might be appropriate to accelerate their work.\n\n\n\n\nThey explore online for potential approaches and even find some tutorials that use interactive environments, but quickly discover that dealing with large datasets requires more compute than their laptop can handle so they need to move to a HPC system.\n\n\n\n\n\n\nWhile desktop sessions are available they might have prohibitively long queues and have low utilisation of the underlying hardware. They could submit a job to the HPC queue but this leads to long times between iterations. At this stage the researcher is still discovering things about their data, how to clean it and how to analyse it.\n\nThey need an interactive environment so they can develop and debug their algorithms and the algorithms, but still need access to high powered acceleration so they can process their dataset. At the same time we want to improve utilisation of the hardware so that we can serve more users and reduce wait times.\nThe MLeRP environment creates a middle ground that has the interactivity of a notebook with the power of a cluster environment that can share valuable resources between other users while code isn’t being executed.\nWe provide users with CPU based Jupyter notebook sessions capable of basic analysis, with the ability to interactively send jobs to a SLURM queue for GPU or parallelised CPU acceleration through Dask.\n\nNow our new researcher can easily import the same code that they were using on their laptops or with online notebook services straight into a cluster environment without the need to convert it first into a SBATCH script, wait in long cluster queues or load modules for dependencies.\n\n\n\nMLeRP is available to all Australian and New Zealand academic researchers. MLeRP supports authentication through AAF and Google. Tuakiri authentication is planned but not yet implemented.\n\n\n\nYou can apply for an allocation here.\n\n\n\nNotebooks attached directly to reserved GPU compute for 10 GB instances are available through the ‘Tabby’ service. This is ideal for data exploration, data visualisation or beginners who are just starting with clusters. Larger instances, such as 20 GB and 40 GB are only available through the SLURM queue either using batch submission through the ‘Lion’ Service or through Dask SLURMClusters through the ‘Cheetah’ Service.\nWe expect new users to start their projects with notebooks using direct GPU reservation, then move to notebooks backed by Dask SLURMClusters when they need the extra power. Finally, once they have finished writing their applications and are ready to train their models, they can submit their experiments to the SLURM queue.\nFor more information about MLeRP’s regions and compute, have a read of this page.\n\n\n\nDask has the ability to offload individual python functions to another device, once complete the result is then passed back to the parent notebook. Any errors that occur during the process will be forwarded to the notebook just like running things locally, making things more intuitive to debug than a submitted script. This allows the user to write asynchronous code that doesn’t tie up the main computing device and only access it when needed, allowing the platform to serve more users at once. This adds an overhead to the process - the offloading doesn’t happen for free, but it does allow greater flexibility in how the code is written.\nWe believe that this approach of submitting jobs through a python notebook environment will feel more familiar to researchers familiar with the python data science ecosystem given how Dask is designed as a light wrapper around common libraries like numpy, pandas and Scikit-Learn. Rather than needing to rework your code into a high performing batch script as on a traditional HPC system, the scale of your SLURM job can be the size of a python function.\nSome example use cases include:\n\nUsing a GPU job to develop and debug your model and train function interactively, while not tying up the GPU resources when not executing code\nUsing a short running GPU job to check the stability of your training functions, submitting each training epoch as a new job\nUsing a separate GPU job to run your evaluation function concurrently with the next training epoch\nUsing a larger number of low powered CPU jobs to preprocess your dataset by passing the individual samples as input, allowing your jobs to scale to the capacity of the cluster\n\nFor more information on offloading with Dask, have a read of this tutorial and have a look at Dask’s documentation.\n\n\n\nMLeRP is a HPC system. It has a permanent filesystem, letting you store your data and code base between experiments. This also enables collaboration between multiple researchers. If you would like to organise a shared project quota, please reach out.\nThis also allows us to maintain software environments for you to use and gives you the flexibility to maintain your own by installing things directly into your user directory. We provide a conda environment with many common data science packages that will allow you to get started right away, but we fully expect that users will at some point need to move on to maintaining their own conda install. User installed conda environments are fully compatible with our Jupyter Lab application provided they contain the necessary packages."
  },
  {
    "objectID": "about.html#what-is-mlerp",
    "href": "about.html#what-is-mlerp",
    "title": "Machine Learning eResearch Platform (MLeRP)",
    "section": "",
    "text": "Say we have a researcher who is a domain expert in a field and is just discovering that machine learning algorithms might be appropriate to accelerate their work.\n\n\n\n\nThey explore online for potential approaches and even find some tutorials that use interactive environments, but quickly discover that dealing with large datasets requires more compute than their laptop can handle so they need to move to a HPC system.\n\n\n\n\n\n\nWhile desktop sessions are available they might have prohibitively long queues and have low utilisation of the underlying hardware. They could submit a job to the HPC queue but this leads to long times between iterations. At this stage the researcher is still discovering things about their data, how to clean it and how to analyse it.\n\nThey need an interactive environment so they can develop and debug their algorithms and the algorithms, but still need access to high powered acceleration so they can process their dataset. At the same time we want to improve utilisation of the hardware so that we can serve more users and reduce wait times.\nThe MLeRP environment creates a middle ground that has the interactivity of a notebook with the power of a cluster environment that can share valuable resources between other users while code isn’t being executed.\nWe provide users with CPU based Jupyter notebook sessions capable of basic analysis, with the ability to interactively send jobs to a SLURM queue for GPU or parallelised CPU acceleration through Dask.\n\nNow our new researcher can easily import the same code that they were using on their laptops or with online notebook services straight into a cluster environment without the need to convert it first into a SBATCH script, wait in long cluster queues or load modules for dependencies.\n\n\n\nMLeRP is available to all Australian and New Zealand academic researchers. MLeRP supports authentication through AAF and Google. Tuakiri authentication is planned but not yet implemented.\n\n\n\nYou can apply for an allocation here.\n\n\n\nNotebooks attached directly to reserved GPU compute for 10 GB instances are available through the ‘Tabby’ service. This is ideal for data exploration, data visualisation or beginners who are just starting with clusters. Larger instances, such as 20 GB and 40 GB are only available through the SLURM queue either using batch submission through the ‘Lion’ Service or through Dask SLURMClusters through the ‘Cheetah’ Service.\nWe expect new users to start their projects with notebooks using direct GPU reservation, then move to notebooks backed by Dask SLURMClusters when they need the extra power. Finally, once they have finished writing their applications and are ready to train their models, they can submit their experiments to the SLURM queue.\nFor more information about MLeRP’s regions and compute, have a read of this page.\n\n\n\nDask has the ability to offload individual python functions to another device, once complete the result is then passed back to the parent notebook. Any errors that occur during the process will be forwarded to the notebook just like running things locally, making things more intuitive to debug than a submitted script. This allows the user to write asynchronous code that doesn’t tie up the main computing device and only access it when needed, allowing the platform to serve more users at once. This adds an overhead to the process - the offloading doesn’t happen for free, but it does allow greater flexibility in how the code is written.\nWe believe that this approach of submitting jobs through a python notebook environment will feel more familiar to researchers familiar with the python data science ecosystem given how Dask is designed as a light wrapper around common libraries like numpy, pandas and Scikit-Learn. Rather than needing to rework your code into a high performing batch script as on a traditional HPC system, the scale of your SLURM job can be the size of a python function.\nSome example use cases include:\n\nUsing a GPU job to develop and debug your model and train function interactively, while not tying up the GPU resources when not executing code\nUsing a short running GPU job to check the stability of your training functions, submitting each training epoch as a new job\nUsing a separate GPU job to run your evaluation function concurrently with the next training epoch\nUsing a larger number of low powered CPU jobs to preprocess your dataset by passing the individual samples as input, allowing your jobs to scale to the capacity of the cluster\n\nFor more information on offloading with Dask, have a read of this tutorial and have a look at Dask’s documentation.\n\n\n\nMLeRP is a HPC system. It has a permanent filesystem, letting you store your data and code base between experiments. This also enables collaboration between multiple researchers. If you would like to organise a shared project quota, please reach out.\nThis also allows us to maintain software environments for you to use and gives you the flexibility to maintain your own by installing things directly into your user directory. We provide a conda environment with many common data science packages that will allow you to get started right away, but we fully expect that users will at some point need to move on to maintaining their own conda install. User installed conda environments are fully compatible with our Jupyter Lab application provided they contain the necessary packages."
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "Troubleshooting",
    "section": "",
    "text": "Why do I still have to wait in queue?\nDirectly attaching GPU compute to notebooks leads to very low utilisation since the GPU sits idle while you’re debugging your code. By using a queue we are able to service more researchers at once with greater efficiency.\n\n\nIf I still have to wait in queue how is this better than using a traditional HPC environment?\nMLeRP is designed with the idea that a job’s size should be about the size of a cell in a jupyter notebook. With that in mind, the queue has been optimised for short jobs. The maximum wall time of jobs in the MLeRP cluster is 30 minutes. Executing a cell won’t always be immediate but your job should start up pretty quickly. If you need to run a job that runs longer than this, checkpoint your code and split it into multiple jobs. If your code is mature enough that it makes more sense to run a multi-hour or multi-day job, consider using a traditional HPC service. Contact us at mlerphelp@monash.edu if your jobs aren’t starting promptly or your usecase isn’t covered by our platform and you think it should be.\n\n\nWhy Dask?\nWe looked at a few different options for the MLeRP environment including Sagemaker, Spark and Ray. Ultimately we settled on Dask as the primary tool to interface with the queue because:\n\nSLURM jobs can be submitted with SLURMCluster whenever the GPU cluster is needed\nDebugging can be done locally first with LocalCluster with minimal code change\nIt has a familiar syntax as it’s designed as a light wrapper around common libraries like Numpy, Pandas and SciKit-Learn\nHigh level applications can be implemented easily with Scikit-Learn, XGBoost, Skorch, SciKeras\nDask can submit any python function to the SLURM queue allowing the flexibility for bespoke low level applications\nLazy evaluation of functions which allows for asynchronous code\n\n\n\nWill I need to change my code to work with MLeRP?\nYes. Dask unfortunately will not ‘just work’, you will have to do some code change to use it to interface with the cluster. You will also need to get a sense of how to request resources from the cluster with SLURM.\nThat said we believe that this approach of submitting jobs through a python notebook environment will feel more familiar to researchers familiar with the python datascience ecosystem given how Dask is designed as a light wrapper around common libraries like numpy, pandas and Scikit-Learn.\nYou will also be able to work with the cluster without needing to convert your experimental notebook code into a script and maintain the environment with modules like with a traditional cluster.\n\n\nWhy aren’t my print statements showing up in my jobs?\nPrint statements that are executed on remote machines won’t show up in your notebook. If you are using print statements for debugging, consider using a LocalCluster where they will behave as expected.\nIf you need to record information while code is executing remotely either pass the information back to the notebook when the function returns for it to be printed, or log the output to a file.\nFor more information about using SLURMCluster, visit Dask’s documentation.\n\n\nShould I use cluster.scale or cluster.adapt?\nWe recommend that you use the adapt method while you’re actively developing your code so that you don’t need to worry about cleaning up after yourself. The scale method can be used when you’re ready to run longer tests with higher utilisation.\n\n\nHow do I install my favourite python package?\nIf you want to control the python environment we recommend that you install and maintain a miniconda environment in your userdata directory.\n\n\nWhat is a daemonic process and why can’t I run one?\nA daemon is a process that runs as a background process. Dask prefers to control all processes so that it can manage them more gracefully if they fail. If you need to take control of the multiprocessing yourself, you can turn this off with LocalCluster(processes=False) and SLURMCluster(nanny=False)."
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "Getting Started",
    "section": "",
    "text": "Welcome to MLeRP!\nMost users will find that the easiest way to start using MLeRP will be through the Strudel2 Web Interface. Here you can find the Terminal and Jupyter Lab applications we have prepared for you.\nWe have provided some python environments for you so you can get started right away, until you eventually outgrow them and feel like you need more control over your packages. At this point, we can help you to transition to maintaining your own environment with whatever applications and packages you need.\nYour home directory will be set up with a quota based on what you told us you’ll need to do your research. You can use this space to maintain your datasets, programs and code base. Let us know if you need more space and we’ll see what we can do.\nRegardless of what compute you choose, in order to start your research here you will need to be able to import your data and code. If you’re working with relatively small files, then the simplest way could be to use the FTP clients built into Jupyter Lab or VS Code. Otherwise something like Rsync may be more appropriate.\nIf you are maintaining your code base through Git, then you will likely need to set up an ssh key and add it to your account before pulling down your repository. To use the right ssh key when using git you will need to set up an ssh config that will look something like this:\nHost github.com\n        User git\n        HostName github.com\n        IdentityFile ~/.ssh/github\nIf you are more comfortable using a Git GUI we reccommend connecting to MLeRP using VS Code and using it’s Git extensions.\nAll of our documentation is programmatically generated with Quarto and is available on GitHub. We encourage users to clone a copy and go through our tutorials at their own pace.\ngit clone git@github.com:mitchellshargreaves-monash/MLeRP-Documentation.git\nIf you feel that our documentation does not serve your use case well and could be improved, we welcome contributions through pull requests."
  },
  {
    "objectID": "usage/conda.html",
    "href": "usage/conda.html",
    "title": "Provided Conda Environments",
    "section": "",
    "text": "We maintain an installation of mambaforge. This environment can be accessed through Strudel2 or by activating the environment through a terminal or script with:\nsource /apps/mambaforge/bin/activate"
  },
  {
    "objectID": "usage/conda.html#introduction",
    "href": "usage/conda.html#introduction",
    "title": "Provided Conda Environments",
    "section": "",
    "text": "We maintain an installation of mambaforge. This environment can be accessed through Strudel2 or by activating the environment through a terminal or script with:\nsource /apps/mambaforge/bin/activate"
  },
  {
    "objectID": "usage/conda.html#strudel2-integration",
    "href": "usage/conda.html#strudel2-integration",
    "title": "Provided Conda Environments",
    "section": "Strudel2 integration",
    "text": "Strudel2 integration\nOur Jupyter Lab and Batch are built to integrate with the conda installations on the platform.\nTo change the environment loaded by the application, select your preferred choice in the ‘Conda Environment’ dropdown.\n\nEach element of the dropdown will be displayed in the format:\n&lt;Environment Name&gt; | &lt;/path/to/environment&gt;\nThe Batch app has the addition of the ‘system’ environment which does not load in any environment, using the system python instead.\nThe dropdown will also detect any new environments that you create in installations that you maintain as listed in your ~.conda/environments.txt file. This file is maintained by all variants of conda, adding new entries or removing them as environments are created and destroyed.\nIf the environment that you’re looking for is missing for whatever reason, such as if it was installed by another group member, you can append the path to your environment to the bottom of the file.\necho /path/to/your/environment &gt;&gt; ~/.conda/environments.txt\nSimilarly if the file becomes malformed, such as due to improper removal or moving of environments - you can edit the file directly to correct it with:\nnano ~/.conda/environments.txt"
  },
  {
    "objectID": "usage/conda.html#vs-code-integration",
    "href": "usage/conda.html#vs-code-integration",
    "title": "Provided Conda Environments",
    "section": "VS Code integration",
    "text": "VS Code integration\nA VS Code remote session will not pick up any of our provided environments automatically - even when attaching to a job that activates the environment. To use an environment other that system python you will need to add it as a python interpreter. See our VS Code documentation for more details."
  },
  {
    "objectID": "usage/conda.html#provided-environments",
    "href": "usage/conda.html#provided-environments",
    "title": "Provided Conda Environments",
    "section": "Provided environments",
    "text": "Provided environments\nYou can see the full list of environments that we provide and their details including full package lists here."
  },
  {
    "objectID": "usage/conda.html#custom-conda-environments",
    "href": "usage/conda.html#custom-conda-environments",
    "title": "Provided Conda Environments",
    "section": "Custom conda environments",
    "text": "Custom conda environments\nIf our conda environments don’t meet your needs, you can consider maintaining your own miniconda or miniforge installation in your user or group home directory. See our custom environment documentation for more details."
  },
  {
    "objectID": "usage/environments/custom.html",
    "href": "usage/environments/custom.html",
    "title": "Custom Template",
    "section": "",
    "text": "This environment template has the bare bones of the packages that you’ll need to create a conda environment compatible with Studel2’s Jupyter Lab app.\nSee our custom environment documentation for more details.\n\nEnvironment Definition\n\n\nCode\n!cat /apps/conda-envs/custom.yml\n\n\nname: custom\nchannels:\n  # Add channels as needed for your research packages from most specific to least specific\n  - conda-forge\n\ndependencies:\n  # Required libraries to launch Jupyter Lab jobs\n  - jupyter\n  - jupyterlab\n\n  # Required libraries to interface with the SLURM queue with Dask\n  - dask\n  - dask-jobqueue\n  \n  # Add libraries needed for your research here as required\n  \n  # If your package is only available through pip, as a git repo or needs to be compiled locally, uncomment this section\n  # - pip\n  # - pip:\n  #   - package_name\n  #   - git+https://URL/TO/GIT/REPO\n  #   - -e /PATH/TO/LOCAL/PACKAGE"
  },
  {
    "objectID": "usage/environments/dsks/dsks_2023.10.html",
    "href": "usage/environments/dsks/dsks_2023.10.html",
    "title": "Data Science Kitchen Sink",
    "section": "",
    "text": "The ‘Data Science Kitchen Sink (DSKS)’ is an environment with many typical packages for analysis and machine learning. It is intended as a starting point that users can start working with the service without needing to make your own. As their work matures and specialised packages are needed, this can be cloned to serve as a basis for the new environment.\n\nExecutable Path\n/apps/mambaforge/envs/dsks_2023.10/bin/python3 &lt;/path/to/script.py&gt;\n\n\nActivation Path\nsource /apps/mambaforge/envs/dsks_2023.10/bin/activate\n\n\nEnvironment Definition\n\n\nCode\n!cat /apps/conda-envs/dsks_2023.10.yml\n\n\nname: dsks_2023.10\nchannels:\n  - plotly\n  - huggingface\n  - fastchan\n  - rapidsai\n  - pytorch\n  - nvidia\n  - conda-forge\n\ndependencies:\n  # Interactivity\n  - jupyter\n  - jupyterlab\n  - dask\n  - dask-jobqueue\n  - autopep8\n  - tqdm\n  - matplotlib\n  - plotly\n  - seaborn\n  - wandb\n  - tensorboard\n  - pytest\n\n  # Data Types\n  - jinja2\n  - pillow\n  - pyyaml\n  - geopandas\n  - imutils\n  - opencv\n  - nltk\n  \n  # Data Science\n  - numpy\n  - scipy\n  - pandas\n  - rapids\n  - cupy\n  \n  # Machine Learning\n  - cudatoolkit\n  - tensorflow\n  - pytorch\n  - torchvision\n  - torchaudio\n  - lightning\n  - fastai\n  - transformers\n  - scikit-learn\n  - scikit-image\n  - py-xgboost-gpu\n  - gensim\n  - gym\n\n\n\n\n\n\nFull Package List\n\n\nCode\n!conda list\n\n\n# packages in environment at /apps/mambaforge/envs/dsks_2023.10:\n#\n# Name                    Version                   Build  Channel\n_libgcc_mutex             0.1                 conda_forge    fastchan\n_openmp_mutex             4.5                  2_kmp_llvm    fastchan\n_py-xgboost-mutex         2.0                       gpu_0    conda-forge\nabsl-py                   2.0.0              pyhd8ed1ab_0    conda-forge\naiohttp                   3.8.5           py310h2372a71_0    fastchan\naiosignal                 1.3.1              pyhd8ed1ab_0    fastchan\nalsa-lib                  1.2.9                hd590300_0    conda-forge\nanyio                     3.7.1              pyhd8ed1ab_0    fastchan\naom                       3.5.0                h27087fc_0    fastchan\nappdirs                   1.4.4              pyh9f0ad1d_0    fastchan\nargon2-cffi               21.3.0             pyhd8ed1ab_0    fastchan\nargon2-cffi-bindings      21.2.0          py310h5764c6d_2    fastchan\narrow                     1.3.0              pyhd8ed1ab_0    conda-forge\nasttokens                 2.4.0              pyhd8ed1ab_0    fastchan\nastunparse                1.6.3              pyhd8ed1ab_0    fastchan\nasync-lru                 2.0.4              pyhd8ed1ab_0    conda-forge\nasync-timeout             4.0.3              pyhd8ed1ab_0    fastchan\nattr                      2.5.1                h166bdaf_0    fastchan\nattrs                     23.1.0             pyh71513ae_0    fastchan\nautopep8                  2.0.4              pyhd8ed1ab_0    conda-forge\naws-c-auth                0.6.28               he57a670_2    fastchan\naws-c-cal                 0.5.27               hf85dbcb_0    fastchan\naws-c-common              0.8.20               hd590300_0    fastchan\naws-c-compression         0.2.17               h4b87b72_0    fastchan\naws-c-event-stream        0.3.0                hba2fca9_2    fastchan\naws-c-http                0.7.8                h29e0427_1    fastchan\naws-c-io                  0.13.22              h5116816_0    conda-forge\naws-c-mqtt                0.8.12               hb5295a0_0    conda-forge\naws-c-s3                  0.3.4                ha13a167_1    fastchan\naws-c-sdkutils            0.1.10               h4b87b72_0    fastchan\naws-checksums             0.1.15               h4b87b72_0    conda-forge\naws-crt-cpp               0.20.2               h5e6ac67_7    fastchan\naws-sdk-cpp               1.10.57             h8101662_14    conda-forge\nbabel                     2.13.0             pyhd8ed1ab_0    conda-forge\nbackcall                  0.2.0              pyh9f0ad1d_0    fastchan\nbackoff                   2.2.1              pyhd8ed1ab_0    conda-forge\nbackports                 1.0                        py_2    fastchan\nbackports.functools_lru_cache 1.6.5              pyhd8ed1ab_0    fastchan\nbeautifulsoup4            4.12.2             pyha770c72_0    fastchan\nbleach                    5.0.1              pyhd8ed1ab_0    fastchan\nblessed                   1.19.1             pyhe4f9e05_2    conda-forge\nblinker                   1.6.3              pyhd8ed1ab_0    conda-forge\nblosc                     1.21.5               h0f2a231_0    conda-forge\nbokeh                     3.3.0              pyhd8ed1ab_0    conda-forge\nboost-cpp                 1.78.0               h6582d0a_3    conda-forge\nbranca                    0.6.0              pyhd8ed1ab_0    conda-forge\nbrotli                    1.0.9                h9c3ff4c_4    fastchan\nbrotli-python             1.0.9           py310hd8f1fbe_9    fastchan\nbrunsli                   0.1                  h9c3ff4c_0    fastchan\nbzip2                     1.0.8                h7f98852_4    fastchan\nc-ares                    1.19.1               hd590300_0    fastchan\nc-blosc2                  2.10.5               hb4ffafa_0    conda-forge\nca-certificates           2023.7.22            hbcca054_0    conda-forge\ncachecontrol              0.13.1             pyhd8ed1ab_0    conda-forge\ncachecontrol-with-filecache 0.13.1             pyhd8ed1ab_0    conda-forge\ncached-property           1.5.2                hd8ed1ab_1    conda-forge\ncached_property           1.5.2              pyha770c72_1    conda-forge\ncachetools                5.3.1              pyhd8ed1ab_0    conda-forge\ncairo                     1.16.0            hbbf8b49_1016    conda-forge\ncatalogue                 2.0.10          py310hff52083_0    fastchan\ncertifi                   2023.7.22          pyhd8ed1ab_0    fastchan\ncffi                      1.15.1          py310h255011f_0    fastchan\ncfitsio                   4.3.0                hbdc6101_0    conda-forge\ncharls                    2.4.2                h59595ed_0    conda-forge\ncharset-normalizer        3.2.0              pyhd8ed1ab_0    fastchan\ncleo                      2.0.1              pyhd8ed1ab_0    conda-forge\nclick                     8.1.7           unix_pyh707e725_0    fastchan\nclick-plugins             1.1.1                      py_0    conda-forge\ncligj                     0.7.2              pyhd8ed1ab_1    conda-forge\ncloudpickle               2.2.1              pyhd8ed1ab_0    fastchan\ncolorama                  0.4.6              pyhd8ed1ab_0    fastchan\nconfection                0.1.3           py310h17c5347_0    fastchan\ncontourpy                 1.1.1           py310hd41b1e2_0    fastchan\ncrashtest                 0.4.1              pyhd8ed1ab_0    conda-forge\ncroniter                  1.4.1              pyhd8ed1ab_0    conda-forge\ncryptography              41.0.4          py310h75e40e8_0    fastchan\ncuda-cudart               11.8.89                       0    nvidia\ncuda-cupti                11.8.87                       0    nvidia\ncuda-libraries            11.8.0                        0    nvidia\ncuda-nvrtc                11.8.89                       0    nvidia\ncuda-nvtx                 11.8.86                       0    nvidia\ncuda-runtime              11.8.0                        0    nvidia\ncuda-version              11.8                 h70ddcb2_2    conda-forge\ncudatoolkit               11.8.0              h37601d7_10    fastchan\ncudnn                     8.8.0.121            h838ba91_3    conda-forge\ncupy                      12.2.0          py310h7b03888_3    conda-forge\ncycler                    0.11.0             pyhd8ed1ab_0    fastchan\ncymem                     2.0.8           py310hc6cd4ac_0    fastchan\ncython-blis               0.7.10          py310h278f3c1_1    fastchan\ncytoolz                   0.12.0          py310h5764c6d_0    fastchan\ndask                      2023.9.3           pyhd8ed1ab_0    conda-forge\ndask-core                 2023.9.3           pyhd8ed1ab_0    conda-forge\ndask-jobqueue             0.8.2              pyhd8ed1ab_0    conda-forge\ndataclasses               0.8                pyhc8e2a94_3    fastchan\ndatasets                  2.14.5                     py_0    huggingface\ndateutils                 0.6.12                     py_0    conda-forge\ndav1d                     1.2.1                hd590300_0    conda-forge\ndbus                      1.13.6               h5008d03_3    fastchan\ndebugpy                   1.6.3           py310hd8f1fbe_0    fastchan\ndecorator                 5.1.1              pyhd8ed1ab_0    fastchan\ndeepdiff                  6.6.0              pyhd8ed1ab_0    conda-forge\ndefusedxml                0.7.1              pyhd8ed1ab_0    fastchan\ndill                      0.3.7              pyhd8ed1ab_0    fastchan\ndistlib                   0.3.6              pyhd8ed1ab_0    fastchan\ndistributed               2023.9.3           pyhd8ed1ab_0    conda-forge\ndocker-pycreds            0.4.0                      py_0    conda-forge\ndulwich                   0.21.6          py310h2372a71_2    conda-forge\nentrypoints               0.4                pyhd8ed1ab_0    fastchan\nexceptiongroup            1.1.3              pyhd8ed1ab_0    fastchan\nexecuting                 1.2.0              pyhd8ed1ab_0    fastchan\nexpat                     2.5.0                h27087fc_0    fastchan\nfastai                    2.7.12                     py_0    fastchan\nfastapi                   0.103.2            pyhd8ed1ab_0    conda-forge\nfastcore                  1.5.29                     py_0    fastchan\nfastdownload              0.0.7                      py_0    fastchan\nfastprogress              1.0.3                      py_0    fastchan\nfastrlock                 0.8.2           py310hc6cd4ac_1    conda-forge\nffmpeg                    6.0.0           gpl_h14e97fc_104    conda-forge\nfilelock                  3.12.4             pyhd8ed1ab_0    fastchan\nfiona                     1.9.4           py310h111440e_0    conda-forge\nflatbuffers               23.5.26              h59595ed_1    conda-forge\nflit-core                 3.7.1              pyhd8ed1ab_0    fastchan\nfolium                    0.14.0             pyhd8ed1ab_0    conda-forge\nfont-ttf-dejavu-sans-mono 2.37                 hab24e00_0    fastchan\nfont-ttf-inconsolata      3.000                h77eed37_0    fastchan\nfont-ttf-source-code-pro  2.038                h77eed37_0    fastchan\nfont-ttf-ubuntu           0.83                 hab24e00_0    fastchan\nfontconfig                2.14.2               h14ed4e7_0    fastchan\nfonts-conda-ecosystem     1                             0    fastchan\nfonts-conda-forge         1                             0    fastchan\nfonttools                 4.42.1          py310h2372a71_0    fastchan\nfqdn                      1.5.1              pyhd8ed1ab_0    conda-forge\nfreeglut                  3.2.2                hac7e632_2    conda-forge\nfreetype                  2.12.1               hca18f0e_0    fastchan\nfreexl                    1.0.6                h166bdaf_1    conda-forge\nfribidi                   1.0.10               h36c2ea0_0    fastchan\nfrozenlist                1.4.0           py310h2372a71_0    fastchan\nfsspec                    2023.9.0           pyh1a96a4e_0    fastchan\ngast                      0.4.0              pyh9f0ad1d_0    conda-forge\ngdal                      3.7.1           py310h65bb550_6    conda-forge\ngensim                    4.3.2           py310hcc13569_0    conda-forge\ngeopandas                 0.14.0             pyhd8ed1ab_1    conda-forge\ngeopandas-base            0.14.0             pyha770c72_1    conda-forge\ngeos                      3.12.0               h59595ed_0    conda-forge\ngeotiff                   1.7.1               h22adcc9_11    conda-forge\ngettext                   0.21.1               h27087fc_0    fastchan\ngflags                    2.2.2             he1b5a44_1004    fastchan\ngiflib                    5.2.1                h36c2ea0_2    fastchan\ngitdb                     4.0.10             pyhd8ed1ab_0    conda-forge\ngitpython                 3.1.37             pyhd8ed1ab_0    conda-forge\nglib                      2.78.0               hfc55251_0    fastchan\nglib-tools                2.78.0               hfc55251_0    fastchan\nglog                      0.6.0                h6f12383_0    fastchan\ngmp                       6.2.1                h58526e2_0    fastchan\ngmpy2                     2.1.2           py310h3ec546c_1    fastchan\ngnutls                    3.7.8                hf3e180e_0    fastchan\ngoogle-auth               2.23.3             pyhca7485f_0    conda-forge\ngoogle-auth-oauthlib      1.0.0              pyhd8ed1ab_1    conda-forge\ngoogle-pasta              0.2.0              pyh8c360ce_0    conda-forge\ngraphite2                 1.3.13            h58526e2_1001    fastchan\ngrpcio                    1.54.3          py310heca2aa9_0    conda-forge\ngst-plugins-base          1.22.5               hf7dbed1_0    conda-forge\ngstreamer                 1.22.5               h98fc4e7_0    conda-forge\ngym                       0.26.1          py310hfdc917e_0    conda-forge\ngym-notices               0.0.8              pyhd8ed1ab_0    conda-forge\nh11                       0.14.0             pyhd8ed1ab_0    conda-forge\nh5py                      3.9.0           nompi_py310hcca72df_101    conda-forge\nharfbuzz                  7.3.0                hdb3a94d_0    fastchan\nhdf4                      4.2.15               h501b40f_6    conda-forge\nhdf5                      1.14.1          nompi_h4f84152_100    conda-forge\nhuggingface_hub           0.18.0                     py_0    huggingface\nhupper                    1.12               pyhd8ed1ab_0    conda-forge\nicu                       72.1                 hcb278e6_0    fastchan\nidna                      3.4                pyhd8ed1ab_0    fastchan\nimagecodecs               2023.8.12       py310hc929067_0    conda-forge\nimageio                   2.25.0             pyh24c5eb1_0    fastchan\nimportlib-metadata        6.8.0              pyha770c72_0    fastchan\nimportlib_metadata        6.8.0                hd8ed1ab_0    fastchan\nimportlib_resources       6.1.0              pyhd8ed1ab_0    fastchan\nimutils                   0.5.4           py310hff52083_3    conda-forge\niniconfig                 2.0.0              pyhd8ed1ab_0    conda-forge\ninquirer                  3.1.3              pyhd8ed1ab_0    conda-forge\nipykernel                 6.16.2             pyh210e3f2_0    fastchan\nipython                   8.15.0             pyh0d859eb_0    fastchan\nipython_genutils          0.2.0                      py_1    fastchan\nipywidgets                8.0.3              pyhd8ed1ab_0    fastchan\nisoduration               20.11.0            pyhd8ed1ab_0    conda-forge\nitsdangerous              2.1.2              pyhd8ed1ab_0    conda-forge\njaraco.classes            3.3.0              pyhd8ed1ab_0    conda-forge\njasper                    4.0.0                h32699f2_1    conda-forge\njax                       0.4.16             pyhd8ed1ab_0    conda-forge\njaxlib                    0.4.14          cpu_py310h67d73b5_1    conda-forge\njedi                      0.19.0             pyhd8ed1ab_0    fastchan\njeepney                   0.8.0              pyhd8ed1ab_0    conda-forge\njinja2                    3.1.2              pyhd8ed1ab_0    fastchan\njoblib                    1.3.2              pyhd8ed1ab_0    fastchan\njson-c                    0.17                 h7ab15ed_0    conda-forge\njson5                     0.9.14             pyhd8ed1ab_0    fastchan\njsonpointer               2.4             py310hff52083_2    fastchan\njsonschema                4.17.3             pyhd8ed1ab_0    fastchan\njsonschema-with-format-nongpl 4.17.3             pyhd8ed1ab_0    conda-forge\njupyter                   1.0.0           py310hff52083_7    fastchan\njupyter-lsp               2.2.0              pyhd8ed1ab_0    conda-forge\njupyter_client            7.4.8              pyhd8ed1ab_0    fastchan\njupyter_console           6.4.4              pyhd8ed1ab_0    fastchan\njupyter_core              5.3.1           py310hff52083_0    fastchan\njupyter_events            0.6.3              pyhd8ed1ab_1    conda-forge\njupyter_server            2.7.3              pyhd8ed1ab_1    conda-forge\njupyter_server_terminals  0.4.4              pyhd8ed1ab_1    conda-forge\njupyterlab                4.0.7              pyhd8ed1ab_0    conda-forge\njupyterlab_pygments       0.2.2              pyhd8ed1ab_0    fastchan\njupyterlab_server         2.24.0             pyhd8ed1ab_0    conda-forge\njupyterlab_widgets        3.0.9              pyhd8ed1ab_0    conda-forge\njxrlib                    1.1                  h7f98852_2    fastchan\nkealib                    1.5.1                h3e6883b_4    conda-forge\nkeras                     2.12.0             pyhd8ed1ab_0    conda-forge\nkeras-preprocessing       1.1.2              pyhd8ed1ab_0    conda-forge\nkeyring                   24.2.0          py310hff52083_1    conda-forge\nkeyutils                  1.6.1                h166bdaf_0    fastchan\nkiwisolver                1.4.5           py310hd41b1e2_0    fastchan\nkrb5                      1.21.2               h659d440_0    fastchan\nlame                      3.100             h7f98852_1001    fastchan\nlangcodes                 3.3.0              pyhd8ed1ab_0    fastchan\nlcms2                     2.15                 haa2dc70_1    fastchan\nld_impl_linux-64          2.40                 h41732ed_0    conda-forge\nlerc                      4.0.0                h27087fc_0    fastchan\nlibabseil                 20230125.3      cxx17_h59595ed_0    fastchan\nlibaec                    1.0.6                h9c3ff4c_0    fastchan\nlibarchive                3.6.2                h039dbb9_1    conda-forge\nlibarrow                  12.0.1           hc410076_0_cpu    fastchan\nlibass                    0.17.1               hc9aadba_0    conda-forge\nlibavif                   0.11.1               h8182462_2    conda-forge\nlibblas                   3.9.0           14_linux64_openblas    fastchan\nlibbrotlicommon           1.0.9                h166bdaf_9    conda-forge\nlibbrotlidec              1.0.9                h166bdaf_9    conda-forge\nlibbrotlienc              1.0.9                h166bdaf_9    conda-forge\nlibcap                    2.67                 he9d0100_0    fastchan\nlibcblas                  3.9.0           14_linux64_openblas    fastchan\nlibclang                  15.0.7          default_had23c3d_0    fastchan\nlibclang13                15.0.7          default_h3e3d535_0    fastchan\nlibcrc32c                 1.1.2                h9c3ff4c_0    fastchan\nlibcublas                 11.11.3.6                     0    nvidia\nlibcufft                  10.9.0.58                     0    nvidia\nlibcufile                 1.7.2.10                      0    nvidia\nlibcups                   2.3.3                h4637d8d_4    conda-forge\nlibcurand                 10.3.3.141                    0    nvidia\nlibcurl                   8.3.0                hca28451_0    fastchan\nlibcusolver               11.4.1.48                     0    nvidia\nlibcusparse               11.7.5.86                     0    nvidia\nlibdeflate                1.18                 h0b41bf4_0    fastchan\nlibdrm                    2.4.114              h166bdaf_0    fastchan\nlibedit                   3.1.20191231         he28a2e2_2    conda-forge\nlibev                     4.33                 h516909a_1    fastchan\nlibevent                  2.1.12               h3358134_0    fastchan\nlibexpat                  2.5.0                hcb278e6_1    fastchan\nlibffi                    3.4.2                h7f98852_5    conda-forge\nlibflac                   1.4.3                h59595ed_0    fastchan\nlibgcc-ng                 12.1.0              h8d9b700_16    fastchan\nlibgcrypt                 1.10.1               h166bdaf_0    fastchan\nlibgdal                   3.7.1                hd2ada2b_6    conda-forge\nlibgfortran-ng            13.2.0               h69a702a_0    fastchan\nlibgfortran5              13.2.0               ha4646dd_0    fastchan\nlibglib                   2.78.0               hebfc3b9_0    fastchan\nlibglu                    9.0.0             he1b5a44_1001    fastchan\nlibgoogle-cloud           2.12.0               hac9eb74_0    fastchan\nlibgpg-error              1.47                 h71f35ed_0    fastchan\nlibgrpc                   1.54.3               hb20ce57_0    conda-forge\nlibhwloc                  2.9.2           nocuda_h7313eea_1008    fastchan\nlibiconv                  1.17                 h166bdaf_0    fastchan\nlibidn2                   2.3.4                h166bdaf_0    fastchan\nlibjpeg-turbo             2.1.5.1              h0b41bf4_0    fastchan\nlibkml                    1.3.0             h01aab08_1016    conda-forge\nliblapack                 3.9.0           14_linux64_openblas    fastchan\nliblapacke                3.9.0           14_linux64_openblas    fastchan\nlibllvm15                 15.0.7               h5cf9203_3    conda-forge\nlibmagma                  2.7.1                hc72dce7_6    conda-forge\nlibmagma_sparse           2.7.1                h8354cda_6    conda-forge\nlibnetcdf                 4.9.2           nompi_h7e745eb_109    conda-forge\nlibnghttp2                1.52.0               h61bc06f_0    fastchan\nlibnpp                    11.8.0.86                     0    nvidia\nlibnsl                    2.0.0                hd590300_1    conda-forge\nlibnuma                   2.0.16               h0b41bf4_1    fastchan\nlibnvjpeg                 11.9.0.86                     0    nvidia\nlibogg                    1.3.4                h7f98852_1    fastchan\nlibopenblas               0.3.20          pthreads_h78a6416_1    conda-forge\nlibopencv                 4.7.0           py310h3e876cf_6    conda-forge\nlibopus                   1.3.1                h7f98852_1    fastchan\nlibpciaccess              0.17                 h166bdaf_0    fastchan\nlibpng                    1.6.39               h753d276_0    fastchan\nlibpq                     15.4                 hfc447b1_2    conda-forge\nlibprotobuf               3.21.12              h3eb15da_0    fastchan\nlibrttopo                 1.1.0               hb58d41b_14    conda-forge\nlibsndfile                1.2.2                hbc2eb40_0    fastchan\nlibsodium                 1.0.18               h36c2ea0_1    fastchan\nlibspatialindex           1.9.3                h9c3ff4c_4    conda-forge\nlibspatialite             5.0.1               h15f6e67_28    conda-forge\nlibsqlite                 3.43.2               h2797004_0    conda-forge\nlibssh2                   1.11.0               h0841786_0    fastchan\nlibstdcxx-ng              13.2.0               h7e041cc_0    fastchan\nlibsystemd0               253                  h8c4010b_1    fastchan\nlibtasn1                  4.19.0               h166bdaf_0    fastchan\nlibthrift                 0.18.1               h8fd135c_2    conda-forge\nlibtiff                   4.5.1                h8b53f26_0    fastchan\nlibunistring              0.9.10               h7f98852_0    fastchan\nlibutf8proc               2.8.0                h166bdaf_0    fastchan\nlibuuid                   2.38.1               h0b41bf4_0    fastchan\nlibva                     2.20.0               hd590300_0    conda-forge\nlibvorbis                 1.3.7                h9c3ff4c_0    fastchan\nlibvpx                    1.13.1               h59595ed_0    conda-forge\nlibwebp-base              1.3.2                hd590300_0    fastchan\nlibxcb                    1.15                 h0b41bf4_0    fastchan\nlibxgboost                1.7.6           cuda112h075c576_3    conda-forge\nlibxkbcommon              1.6.0                h5d7e998_0    conda-forge\nlibxml2                   2.11.5               h0d562d8_0    fastchan\nlibzip                    1.10.1               h2629f0a_3    conda-forge\nlibzlib                   1.2.13               hd590300_5    conda-forge\nlibzopfli                 1.0.3                h9c3ff4c_0    fastchan\nlightning                 2.0.9.post0        pyhd8ed1ab_0    conda-forge\nlightning-cloud           0.5.39             pyhd8ed1ab_0    conda-forge\nlightning-utilities       0.9.0              pyhd8ed1ab_0    conda-forge\nllvm-openmp               17.0.2               h4dfa4b3_0    conda-forge\nlocket                    1.0.0              pyhd8ed1ab_0    fastchan\nlz4                       4.3.2           py310h350c4a5_1    conda-forge\nlz4-c                     1.9.4                hcb278e6_0    fastchan\nlzo                       2.10              h516909a_1000    fastchan\nmagma                     2.7.1                ha770c72_6    conda-forge\nmapclassify               2.6.1              pyhd8ed1ab_0    conda-forge\nmarkdown                  3.5                pyhd8ed1ab_0    conda-forge\nmarkdown-it-py            3.0.0              pyhd8ed1ab_0    fastchan\nmarkupsafe                2.1.3           py310h2372a71_0    fastchan\nmatplotlib                3.8.0           py310hff52083_0    fastchan\nmatplotlib-base           3.8.0           py310h62c0568_0    fastchan\nmatplotlib-inline         0.1.6              pyhd8ed1ab_0    fastchan\nmdurl                     0.1.0              pyhd8ed1ab_0    fastchan\nmistune                   0.8.4           py310h6acc77f_1005    fastchan\nmkl                       2022.2.1         h84fe81f_16997    conda-forge\nml_dtypes                 0.3.1           py310hcc13569_1    conda-forge\nmore-itertools            10.1.0             pyhd8ed1ab_0    fastchan\nmpc                       1.3.1                hfe3b2da_0    fastchan\nmpfr                      4.2.0                hb012696_0    fastchan\nmpg123                    1.31.3               hcb278e6_0    fastchan\nmpmath                    1.3.0              pyhd8ed1ab_0    fastchan\nmsgpack-python            1.0.6           py310hd41b1e2_0    conda-forge\nmultidict                 6.0.4           py310h1fa729e_0    fastchan\nmultiprocess              0.70.15         py310h2372a71_0    fastchan\nmunch                     4.0.0              pyhd8ed1ab_0    conda-forge\nmunkres                   1.1.4              pyh9f0ad1d_0    fastchan\nmurmurhash                1.0.10          py310hc6cd4ac_0    fastchan\nmysql-common              8.0.33               hf1915f5_0    fastchan\nmysql-libs                8.0.33               hca2cd23_0    fastchan\nnbclient                  0.6.6              pyhd8ed1ab_0    fastchan\nnbconvert                 6.5.0              pyhd8ed1ab_0    fastchan\nnbconvert-core            6.5.0              pyhd8ed1ab_0    fastchan\nnbconvert-pandoc          6.5.0              pyhd8ed1ab_0    fastchan\nnbformat                  5.9.2              pyhd8ed1ab_0    fastchan\nnccl                      2.19.3.1             h6103f9b_0    conda-forge\nncurses                   6.4                  hcb278e6_0    conda-forge\nnest-asyncio              1.5.6              pyhd8ed1ab_0    fastchan\nnettle                    3.8.1                hc379101_1    fastchan\nnetworkx                  3.1                pyhd8ed1ab_0    fastchan\nnltk                      3.8.1              pyhd8ed1ab_0    conda-forge\nnotebook                  6.4.12             pyha770c72_0    fastchan\nnotebook-shim             0.2.3              pyhd8ed1ab_0    conda-forge\nnspr                      4.35                 h27087fc_0    fastchan\nnss                       3.92                 h1d7d5a4_0    fastchan\nnumpy                     1.26.0          py310ha4c1d20_0    fastchan\noauthlib                  3.2.2              pyhd8ed1ab_0    conda-forge\nopencv                    4.7.0           py310hff52083_6    conda-forge\nopenh264                  2.3.1                h27087fc_0    fastchan\nopenjpeg                  2.5.0                h7d73246_1    fastchan\nopenssl                   3.1.3                hd590300_0    conda-forge\nopt-einsum                3.3.0                hd8ed1ab_2    conda-forge\nopt_einsum                3.3.0              pyhc1e730c_2    conda-forge\norc                       1.8.4                h2f23424_0    fastchan\nordered-set               4.1.0              pyhd8ed1ab_0    conda-forge\norjson                    3.9.8           py310h1e2579a_0    conda-forge\noverrides                 7.4.0              pyhd8ed1ab_0    conda-forge\np11-kit                   0.24.1               hc5aa10d_0    fastchan\npackaging                 23.1               pyhd8ed1ab_0    fastchan\npandas                    2.1.1           py310hcc13569_0    fastchan\npandoc                    2.18                 ha770c72_0    fastchan\npandocfilters             1.5.0              pyhd8ed1ab_0    fastchan\nparso                     0.8.3              pyhd8ed1ab_0    fastchan\npartd                     1.3.0              pyhd8ed1ab_0    fastchan\npastedeploy               3.0.1              pyhd8ed1ab_0    conda-forge\npathtools                 0.1.2                      py_1    conda-forge\npathy                     0.10.2             pyhd8ed1ab_0    fastchan\npatsy                     0.5.3              pyhd8ed1ab_0    conda-forge\npcre2                     10.40                hc3806b6_0    fastchan\npexpect                   4.8.0              pyh9f0ad1d_2    fastchan\npickleshare               0.7.5                   py_1003    fastchan\npillow                    10.0.0          py310h582fbeb_0    fastchan\npip                       23.2.1             pyhd8ed1ab_0    conda-forge\npixman                    0.42.2               h59595ed_0    fastchan\npkginfo                   1.9.6              pyhd8ed1ab_0    fastchan\npkgutil-resolve-name      1.3.10             pyhd8ed1ab_0    fastchan\nplaster                   1.0                        py_0    conda-forge\nplaster_pastedeploy       0.7                        py_0    conda-forge\nplatformdirs              3.5.1              pyhd8ed1ab_0    conda-forge\nplotly                    5.17.0                     py_0    plotly\npluggy                    1.3.0              pyhd8ed1ab_0    fastchan\nply                       3.11                       py_1    fastchan\npoetry                    1.6.1           linux_pyha804496_0    conda-forge\npoetry-core               1.7.0              pyhd8ed1ab_0    conda-forge\npoetry-plugin-export      1.5.0              pyhd8ed1ab_0    conda-forge\npooch                     1.7.0              pyhd8ed1ab_0    fastchan\npoppler                   23.08.0              hd18248d_0    conda-forge\npoppler-data              0.4.12               hd8ed1ab_0    conda-forge\npostgresql                15.4                 h8972f4a_2    conda-forge\npreshed                   3.0.9           py310hc6cd4ac_1    fastchan\nproj                      9.2.1                ha643af7_0    conda-forge\nprometheus_client         0.14.1             pyhd8ed1ab_0    fastchan\nprompt-toolkit            3.0.39             pyha770c72_0    fastchan\nprompt_toolkit            3.0.39               hd8ed1ab_0    fastchan\nprotobuf                  4.21.12         py310heca2aa9_0    conda-forge\npsutil                    5.9.5           py310h1fa729e_0    fastchan\npthread-stubs             0.4               h36c2ea0_1001    fastchan\nptyprocess                0.7.0              pyhd3deb0d_0    fastchan\npulseaudio-client         16.1                 h5195f5e_3    fastchan\npure_eval                 0.2.2              pyhd8ed1ab_0    fastchan\npy-opencv                 4.7.0           py310hfdc917e_6    conda-forge\npy-xgboost                1.7.6           cuda112py310h9414535_3    conda-forge\npy-xgboost-gpu            1.7.6           py310hf9f7e87_3    conda-forge\npyarrow                   12.0.1          py310h0576679_0_cpu    fastchan\npyasn1                    0.5.0              pyhd8ed1ab_0    conda-forge\npyasn1-modules            0.3.0              pyhd8ed1ab_0    conda-forge\npycodestyle               2.11.0             pyhd8ed1ab_0    conda-forge\npycparser                 2.21               pyhd8ed1ab_0    fastchan\npydantic                  1.10.12         py310h2372a71_0    fastchan\npygments                  2.16.1             pyhd8ed1ab_0    fastchan\npyjwt                     2.8.0              pyhd8ed1ab_0    conda-forge\npyopenssl                 23.2.0             pyhd8ed1ab_1    fastchan\npyparsing                 3.1.1              pyhd8ed1ab_0    fastchan\npyproj                    3.6.1           py310h177c0e2_0    conda-forge\npyproject_hooks           1.0.0              pyhd8ed1ab_0    conda-forge\npyqt                      5.15.9          py310h04931ad_4    fastchan\npyqt5-sip                 12.12.2         py310hc6cd4ac_4    fastchan\npyramid                   2.0.2              pyhd8ed1ab_0    conda-forge\npyrsistent                0.19.3          py310h1fa729e_0    fastchan\npysocks                   1.7.1           py310hff52083_5    fastchan\npytest                    7.4.2              pyhd8ed1ab_0    conda-forge\npython                    3.10.8          h4a9ceb5_0_cpython    fastchan\npython-build              0.10.0             pyhd8ed1ab_1    conda-forge\npython-dateutil           2.8.2              pyhd8ed1ab_0    fastchan\npython-editor             1.0.4                      py_0    conda-forge\npython-fastjsonschema     2.18.0             pyhd8ed1ab_0    fastchan\npython-flatbuffers        23.5.26            pyhd8ed1ab_0    conda-forge\npython-installer          0.7.0              pyhd8ed1ab_0    conda-forge\npython-json-logger        2.0.7              pyhd8ed1ab_0    conda-forge\npython-multipart          0.0.6              pyhd8ed1ab_0    conda-forge\npython-tzdata             2023.3             pyhd8ed1ab_0    fastchan\npython-xxhash             3.3.0           py310h2372a71_0    fastchan\npython_abi                3.10                    2_cp310    fastchan\npytorch                   2.0.0           cuda112py310he33e0d6_200    fastchan\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-lightning         2.0.9              pyhd8ed1ab_0    conda-forge\npytorch-mutex             1.0                        cuda    fastchan\npytz                      2023.3.post1       pyhd8ed1ab_0    fastchan\npyu2f                     0.1.5              pyhd8ed1ab_0    conda-forge\npywavelets                1.4.1           py310h0a54255_0    fastchan\npyyaml                    6.0.1           py310h2372a71_0    fastchan\npyzmq                     24.0.1          py310h330234f_0    fastchan\nqt-main                   5.15.8              h7fe3ca9_15    conda-forge\nqtconsole                 5.3.1              pyhd8ed1ab_0    fastchan\nqtconsole-base            5.3.1              pyha770c72_0    fastchan\nqtpy                      2.1.0              pyhd8ed1ab_0    fastchan\nrapidfuzz                 2.15.2          py310hc6cd4ac_0    conda-forge\nrapids                    0.0.1              pyh9f0ad1d_0    conda-forge\nrdma-core                 28.9                 h59595ed_1    fastchan\nre2                       2023.03.02           h8c504da_0    fastchan\nreadchar                  4.0.5              pyhd8ed1ab_0    conda-forge\nreadline                  8.2                  h8228510_1    conda-forge\nregex                     2023.8.8        py310h2372a71_0    fastchan\nrequests                  2.31.0             pyhd8ed1ab_0    fastchan\nrequests-oauthlib         1.3.1              pyhd8ed1ab_0    conda-forge\nrequests-toolbelt         1.0.0              pyhd8ed1ab_0    fastchan\nrfc3339-validator         0.1.4              pyhd8ed1ab_0    conda-forge\nrfc3986-validator         0.1.1              pyh9f0ad1d_0    conda-forge\nrich                      13.5.3             pyhd8ed1ab_0    fastchan\nrocm-smi                  5.6.0                h59595ed_1    fastchan\nrsa                       4.9                pyhd8ed1ab_0    conda-forge\nrtree                     1.0.1           py310hbdcdc62_3    conda-forge\ns2n                       1.3.44               h06160fa_0    fastchan\nsacremoses                master                     py_0    huggingface\nsafetensors               0.3.3           py310hcb5633a_0    fastchan\nscikit-image              0.19.3          py310h769672d_0    fastchan\nscikit-learn              1.3.1           py310h1fdf081_0    fastchan\nscipy                     1.11.2          py310ha4c1d20_0    fastchan\nseaborn                   0.13.0               hd8ed1ab_0    conda-forge\nseaborn-base              0.13.0             pyhd8ed1ab_0    conda-forge\nsecretstorage             3.3.3           py310hff52083_2    conda-forge\nsend2trash                1.8.2              pyh41d4057_0    conda-forge\nsentry-sdk                1.32.0             pyhd8ed1ab_0    conda-forge\nsetproctitle              1.3.3           py310h2372a71_0    conda-forge\nsetuptools                65.6.3             pyhd8ed1ab_0    fastchan\nshapely                   2.0.1           py310h7dcad9a_3    conda-forge\nshellingham               1.5.3              pyhd8ed1ab_0    fastchan\nsip                       6.7.11          py310hc6cd4ac_0    fastchan\nsix                       1.16.0             pyh6c4a22f_0    fastchan\nsleef                     3.5.1                h9b69904_2    fastchan\nsmart_open                5.2.1              pyhd8ed1ab_0    fastchan\nsmmap                     3.0.5              pyh44b312d_0    conda-forge\nsnappy                    1.1.10               h9fff704_0    fastchan\nsniffio                   1.3.0              pyhd8ed1ab_0    fastchan\nsortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge\nsoupsieve                 2.5                pyhd8ed1ab_0    fastchan\nspacy                     3.6.1           py310hfb6f7a9_0    fastchan\nspacy-legacy              3.0.12             pyhd8ed1ab_0    fastchan\nspacy-loggers             1.0.5              pyhd8ed1ab_0    fastchan\nsqlite                    3.43.2               h2c6b66d_0    conda-forge\nsrsly                     2.4.8           py310hc6cd4ac_1    fastchan\nstack_data                0.6.2              pyhd8ed1ab_0    fastchan\nstarlette                 0.27.0             pyhd8ed1ab_0    conda-forge\nstarsessions              1.3.0              pyhd8ed1ab_0    conda-forge\nstatsmodels               0.14.0          py310h1f7b6fc_2    conda-forge\nsvt-av1                   1.7.0                h59595ed_0    conda-forge\nsympy                     1.12            pypyh9d50eac_103    fastchan\ntbb                       2021.10.0            h00ab1b0_0    fastchan\ntblib                     2.0.0              pyhd8ed1ab_0    conda-forge\ntenacity                  8.2.3              pyhd8ed1ab_0    conda-forge\ntensorboard               2.12.3             pyhd8ed1ab_0    conda-forge\ntensorboard-data-server   0.7.0           py310h75e40e8_1    conda-forge\ntensorflow                2.12.1          cuda112py310h457873b_0    conda-forge\ntensorflow-base           2.12.1          cuda112py310h622e808_0    conda-forge\ntensorflow-estimator      2.12.1          cuda112py310ha5e6de5_0    conda-forge\ntermcolor                 2.3.0              pyhd8ed1ab_0    conda-forge\nterminado                 0.15.0          py310hff52083_0    fastchan\nthinc                     8.1.12          py310hfb6f7a9_0    fastchan\nthreadpoolctl             3.2.0              pyha21a80b_0    fastchan\ntifffile                  2023.1.23.1        pyhd8ed1ab_0    fastchan\ntiledb                    2.16.3               hf0b6e87_3    conda-forge\ntinycss2                  1.1.1              pyhd8ed1ab_0    fastchan\ntk                        8.6.13               h2797004_0    conda-forge\ntokenizers                0.13.3          py310he1f1126_0    fastchan\ntoml                      0.10.2             pyhd8ed1ab_0    fastchan\ntomli                     2.0.1              pyhd8ed1ab_0    fastchan\ntomlkit                   0.12.1             pyha770c72_0    conda-forge\ntoolz                     0.12.0             pyhd8ed1ab_0    fastchan\ntorchaudio                2.0.0               py310_cu118    fastchan\ntorchmetrics              1.2.0              pyhd8ed1ab_0    conda-forge\ntorchvision               0.15.2          cuda112py310h0801bf5_1    conda-forge\ntornado                   6.3.3           py310h2372a71_0    fastchan\ntqdm                      4.66.1             pyhd8ed1ab_0    fastchan\ntraitlets                 5.10.1             pyhd8ed1ab_0    fastchan\ntransformers              4.33.2             pyhd8ed1ab_0    fastchan\ntranslationstring         1.4                pyh9f0ad1d_0    conda-forge\ntrove-classifiers         2023.9.19          pyhd8ed1ab_0    conda-forge\ntyper                     0.9.0              pyhd8ed1ab_0    fastchan\ntypes-python-dateutil     2.8.19.14          pyhd8ed1ab_0    conda-forge\ntyping-extensions         4.5.0                hd8ed1ab_0    fastchan\ntyping_extensions         4.5.0              pyha770c72_0    fastchan\ntyping_utils              0.1.0              pyhd8ed1ab_0    conda-forge\ntzcode                    2023c                h0b41bf4_0    conda-forge\ntzdata                    2023c                h71feb2d_0    conda-forge\nucx                       1.14.1               h4a2ce2d_1    fastchan\nunicodedata2              15.0.0          py310h5764c6d_0    fastchan\nuri-template              1.3.0              pyhd8ed1ab_0    conda-forge\nuriparser                 0.9.7                hcb278e6_1    conda-forge\nurllib3                   2.0.5              pyhd8ed1ab_0    fastchan\nuvicorn                   0.23.2          py310hff52083_1    conda-forge\nvenusian                  3.0.0                      py_0    conda-forge\nvirtualenv                20.24.1            pyhd8ed1ab_0    conda-forge\nwandb                     0.15.12            pyhd8ed1ab_0    conda-forge\nwasabi                    1.1.2           py310hff52083_0    fastchan\nwcwidth                   0.2.6              pyhd8ed1ab_0    fastchan\nwebcolors                 1.13               pyhd8ed1ab_0    conda-forge\nwebencodings              0.5.1                      py_1    fastchan\nwebob                     1.8.7              pyhd8ed1ab_0    conda-forge\nwebsocket-client          1.6.4              pyhd8ed1ab_0    conda-forge\nwebsockets                11.0.3          py310h2372a71_1    conda-forge\nwerkzeug                  3.0.0              pyhd8ed1ab_0    conda-forge\nwheel                     0.41.2             pyhd8ed1ab_0    conda-forge\nwidgetsnbextension        4.0.4              pyhd8ed1ab_0    fastchan\nwrapt                     1.15.0          py310h2372a71_1    conda-forge\nx264                      1!164.3095           h166bdaf_2    fastchan\nx265                      3.5                  h924138e_3    fastchan\nxcb-util                  0.4.0                h516909a_0    fastchan\nxcb-util-image            0.4.0                h8ee46fc_1    conda-forge\nxcb-util-keysyms          0.4.0                h516909a_0    fastchan\nxcb-util-renderutil       0.3.9                hd590300_1    conda-forge\nxcb-util-wm               0.4.1                h516909a_0    fastchan\nxerces-c                  3.2.4                h8d71039_2    conda-forge\nxkeyboard-config          2.39                 hd590300_0    fastchan\nxorg-fixesproto           5.0               h7f98852_1002    fastchan\nxorg-inputproto           2.3.2             h7f98852_1002    fastchan\nxorg-kbproto              1.0.7             h7f98852_1002    fastchan\nxorg-libice               1.1.1                hd590300_0    fastchan\nxorg-libsm                1.2.4                h7391055_0    fastchan\nxorg-libx11               1.8.6                h8ee46fc_0    fastchan\nxorg-libxau               1.0.11               hd590300_0    fastchan\nxorg-libxdmcp             1.1.3                h7f98852_0    fastchan\nxorg-libxext              1.3.4                h7f98852_1    fastchan\nxorg-libxfixes            5.0.3             h7f98852_1004    fastchan\nxorg-libxi                1.7.10               h7f98852_0    fastchan\nxorg-libxrender           0.9.11               hd590300_0    fastchan\nxorg-renderproto          0.11.1            h7f98852_1002    fastchan\nxorg-xextproto            7.3.0             h7f98852_1002    fastchan\nxorg-xf86vidmodeproto     2.3.1             h7f98852_1002    conda-forge\nxorg-xproto               7.0.31            h7f98852_1007    fastchan\nxxhash                    0.8.2                hd590300_0    fastchan\nxyzservices               2023.10.0          pyhd8ed1ab_0    conda-forge\nxz                        5.2.6                h166bdaf_0    conda-forge\nyaml                      0.2.5                h7f98852_2    fastchan\nyarl                      1.9.2           py310h2372a71_0    fastchan\nzeromq                    4.3.4                h9c3ff4c_1    fastchan\nzfp                       1.0.0                h27087fc_1    fastchan\nzict                      3.0.0              pyhd8ed1ab_0    conda-forge\nzipp                      3.17.0             pyhd8ed1ab_0    fastchan\nzlib                      1.2.13               hd590300_5    conda-forge\nzlib-ng                   2.0.7                h0b41bf4_0    conda-forge\nzope.deprecation          4.4.0                      py_0    conda-forge\nzope.interface            6.1             py310h2372a71_0    conda-forge\nzstd                      1.5.5                hfc55251_0    fastchan"
  },
  {
    "objectID": "usage/environments/detectron-sam.html",
    "href": "usage/environments/detectron-sam.html",
    "title": "Detectron and Segment Anything",
    "section": "",
    "text": "This environment has features the Detectron2 and Segment Anything packages by Facebook Research. For full details about their functionality, be sure to check out their documentation to see if they are right for you.\nIt is intended as an environment that users can use to test the suitability of these packages without having to find a combination of compatible versions of PyTorch, CUDA and other relevant dependencies.\nOnce satisfied that this is a good fit for your research, this can be cloned to serve as a basis for a new environment that you control to add any additional specialist packages that you need. Alternatively, these definitions and install scripts can be copied and tailored to your use case.\n\nExecutable Path\n/apps/mambaforge/envs/detectron-sam/bin/python3 &lt;/path/to/script.py&gt;\n\n\nActivation Path\nsource /apps/mambaforge/envs/detectron-sam/bin/activate\n\n\nEnvironment Definition\n\n\nCode\n!cat /apps/conda-envs/detectron-sam.yml\n\n\nname: detectron-sam\nchannels:\n  # Add channels as needed for your research packages from most specific to least specific\n  - conda-forge\n  - pytorch\n  - nvidia\n\ndependencies:\n  # Required libraries to launch Jupyter Lab jobs\n  - jupyter\n  - jupyterlab\n\n  # Required libraries to interface with the SLURM queue with Dask\n  - dask\n  - dask-jobqueue\n\n  # PyTorch\n  - pytorch=2.0\n  - torchvision=0.15\n  - pytorch-cuda=11.7\n\n  # Image Processing\n  - opencv\n  - pycocotools \n  - matplotlib \n  \n  # Compilers and Package managers\n  - ninja\n  - onnxruntime \n  - onnx\n  - pip\n\n\n\n\nEnvironment Install Script\n\n\nCode\n!cat /apps/conda-envs/install-detectron-sam.sh\n\n\nmamba env create -f detectron-sam.yml\nconda activate detectron-sam\nCC=gcc-10 CXX=g++-10 python -m pip install /apps/facebookresearch/detectron2\npip install /apps/facebookresearch/segment-anything\n\n\n\n\n\n\nFull Package List\n\n\nCode\n!pip list\n\n\nPackage                   Version\n------------------------- ------------------\nabsl-py                   2.1.0\nantlr4-python3-runtime    4.9.3\nanyio                     4.1.0\nargon2-cffi               23.1.0\nargon2-cffi-bindings      21.2.0\narrow                     1.3.0\nasttokens                 2.4.1\nasync-lru                 2.0.4\nattrs                     23.1.0\nBabel                     2.13.1\nbeautifulsoup4            4.12.2\nblack                     24.2.0\nbleach                    6.1.0\nbokeh                     3.3.1\nBrotli                    1.1.0\ncached-property           1.5.2\ncertifi                   2023.11.17\ncffi                      1.16.0\ncharset-normalizer        3.3.2\nclick                     8.1.7\ncloudpickle               3.0.0\ncoloredlogs               15.0.1\ncomm                      0.1.4\ncontourpy                 1.2.0\ncycler                    0.12.1\nCython                    3.0.6\ncytoolz                   0.12.2\ndask                      2023.11.0\ndask-jobqueue             0.8.2\ndebugpy                   1.8.0\ndecorator                 5.1.1\ndefusedxml                0.7.1\ndetectron2                0.6\ndistributed               2023.11.0\nentrypoints               0.4\nexceptiongroup            1.2.0\nexecuting                 2.0.1\nfastjsonschema            2.19.0\nfilelock                  3.13.1\nflatbuffers               23.5.26\nfonttools                 4.45.1\nfqdn                      1.5.1\nfsspec                    2023.10.0\nfvcore                    0.1.5.post20221221\ngmpy2                     2.1.2\ngrpcio                    1.62.0\nhumanfriendly             10.0\nhydra-core                1.3.2\nidna                      3.6\nimportlib-metadata        6.8.0\nimportlib-resources       6.1.1\niopath                    0.1.9\nipykernel                 6.26.0\nipython                   8.18.1\nipywidgets                8.1.1\nisoduration               20.11.0\njedi                      0.19.1\nJinja2                    3.1.2\njson5                     0.9.14\njsonpointer               2.4\njsonschema                4.20.0\njsonschema-specifications 2023.11.1\njupyter                   1.0.0\njupyter_client            8.6.0\njupyter-console           6.6.3\njupyter_core              5.5.0\njupyter-events            0.9.0\njupyter-lsp               2.2.1\njupyter_server            2.11.1\njupyter_server_terminals  0.4.4\njupyterlab                4.0.9\njupyterlab_pygments       0.3.0\njupyterlab_server         2.25.2\njupyterlab-widgets        3.0.9\nkiwisolver                1.4.5\nlocket                    1.0.0\nlz4                       4.3.2\nMarkdown                  3.5.2\nMarkupSafe                2.1.3\nmatplotlib                3.8.2\nmatplotlib-inline         0.1.6\nmistune                   3.0.2\nmpmath                    1.3.0\nmsgpack                   1.0.7\nmunkres                   1.1.4\nmypy-extensions           1.0.0\nnbclient                  0.8.0\nnbconvert                 7.11.0\nnbformat                  5.9.2\nnest-asyncio              1.5.8\nnetworkx                  3.2.1\nnotebook                  7.0.6\nnotebook_shim             0.2.3\nnumpy                     1.26.2\nomegaconf                 2.3.0\nonnx                      1.15.0\nonnxruntime               1.16.3\nopencv-python             4.8.1\noverrides                 7.4.0\npackaging                 23.2\npandas                    2.1.3\npandocfilters             1.5.0\nparso                     0.8.3\npartd                     1.4.1\npathspec                  0.12.1\npexpect                   4.8.0\npickleshare               0.7.5\nPillow                    10.1.0\npip                       23.3.1\npkgutil_resolve_name      1.3.10\nplatformdirs              4.0.0\nply                       3.11\nportalocker               2.8.2\nprometheus-client         0.19.0\nprompt-toolkit            3.0.41\nprotobuf                  4.24.4\npsutil                    5.9.5\nptyprocess                0.7.0\npure-eval                 0.2.2\npyarrow                   14.0.1\npyarrow-hotfix            0.6\npycocotools               2.0.6\npycparser                 2.21\nPygments                  2.17.2\npyparsing                 3.1.1\nPyQt5                     5.15.9\nPyQt5-sip                 12.12.2\nPySocks                   1.7.1\npython-dateutil           2.8.2\npython-json-logger        2.0.7\npytz                      2023.3.post1\nPyYAML                    6.0.1\npyzmq                     25.1.1\nqtconsole                 5.5.1\nQtPy                      2.4.1\nreferencing               0.31.1\nrequests                  2.31.0\nrfc3339-validator         0.1.4\nrfc3986-validator         0.1.1\nrpds-py                   0.13.2\nsegment-anything          1.0\nSend2Trash                1.8.2\nsetuptools                68.2.2\nsip                       6.7.12\nsix                       1.16.0\nsniffio                   1.3.0\nsortedcontainers          2.4.0\nsoupsieve                 2.5\nstack-data                0.6.2\nsympy                     1.12\ntabulate                  0.9.0\ntblib                     2.0.0\ntensorboard               2.16.2\ntensorboard-data-server   0.7.2\ntermcolor                 2.4.0\nterminado                 0.18.0\ntinycss2                  1.2.1\ntoml                      0.10.2\ntomli                     2.0.1\ntoolz                     0.12.0\ntorch                     2.0.0.post304\ntorchvision               0.15.2a0+ab7b3e6\ntornado                   6.3.3\ntqdm                      4.66.2\ntraitlets                 5.14.0\ntypes-python-dateutil     2.8.19.14\ntyping_extensions         4.8.0\ntyping-utils              0.1.0\ntzdata                    2023.3\nuri-template              1.3.0\nurllib3                   2.1.0\nwcwidth                   0.2.12\nwebcolors                 1.13\nwebencodings              0.5.1\nwebsocket-client          1.6.4\nWerkzeug                  3.0.1\nwheel                     0.42.0\nwidgetsnbextension        4.0.9\nxyzservices               2023.10.1\nyacs                      0.1.8\nzict                      3.0.0\nzipp                      3.17.0"
  },
  {
    "objectID": "usage/custom.html",
    "href": "usage/custom.html",
    "title": "Custom Conda Environments",
    "section": "",
    "text": "If our conda environments don’t meet your needs, you can consider maintaining your own miniconda or miniforge installation in your home directory.\nPlease BE CAREFUL when installing this environment and have a read of this page, even if you’ve worked with conda before.\nBy default, this will initialise conda and modify your ~/.bashrc to activate the environment by default, which can lead to unexpected behaviour in our Strudel2 apps and batch submissions.\nWe reccommend the Tabby QoS terminals for managing environments as both conda and mamba are memory intensive processes, furthermore, some packages such as py-xgboost-gpu require a GPU to be present during install.\n\n\nConda is often used as a standard for maintaining python datascience environments, but because of the complexity of the environments typically needed, the conda solver can be known to hang (for 20 minutes or longer) especially if trying to install into an existing complicated environment, only to report that it was unable to solve due to version conflicts.\nMamba is a parallelised C++ rewrite of the slowest parts of conda, though while much faster (similar environments can solve in a minute or so), it can be unstable at times leading to unexpected errors.\nSince a mamba installation comes compatible with conda and acts as a dropin replacement, we recommend that you start with a mambaforge installation and then fall back on conda commands whenever mamba fails. Simply replace the mamba keyword with conda.\nIn this tutorial we will cover installing a mamba environment."
  },
  {
    "objectID": "usage/custom.html#introduction",
    "href": "usage/custom.html#introduction",
    "title": "Custom Conda Environments",
    "section": "",
    "text": "If our conda environments don’t meet your needs, you can consider maintaining your own miniconda or miniforge installation in your home directory.\nPlease BE CAREFUL when installing this environment and have a read of this page, even if you’ve worked with conda before.\nBy default, this will initialise conda and modify your ~/.bashrc to activate the environment by default, which can lead to unexpected behaviour in our Strudel2 apps and batch submissions.\nWe reccommend the Tabby QoS terminals for managing environments as both conda and mamba are memory intensive processes, furthermore, some packages such as py-xgboost-gpu require a GPU to be present during install.\n\n\nConda is often used as a standard for maintaining python datascience environments, but because of the complexity of the environments typically needed, the conda solver can be known to hang (for 20 minutes or longer) especially if trying to install into an existing complicated environment, only to report that it was unable to solve due to version conflicts.\nMamba is a parallelised C++ rewrite of the slowest parts of conda, though while much faster (similar environments can solve in a minute or so), it can be unstable at times leading to unexpected errors.\nSince a mamba installation comes compatible with conda and acts as a dropin replacement, we recommend that you start with a mambaforge installation and then fall back on conda commands whenever mamba fails. Simply replace the mamba keyword with conda.\nIn this tutorial we will cover installing a mamba environment."
  },
  {
    "objectID": "usage/custom.html#installing-miniforge",
    "href": "usage/custom.html#installing-miniforge",
    "title": "Custom Conda Environments",
    "section": "1. Installing miniforge",
    "text": "1. Installing miniforge\n\nFollowing the recommendations on mamba’s installation page, we will be using the Miniforge distribution.\nFollowing the link through to the download page, copy the link for the following distribution:\n\nOS: Linux\nArchitecture: x86_64 (amd64)\n\nUsing the Strudel2 terminal application or your favourite terminal application using SSOSSH, log into the cluster.\nDownload the distribution to your home directory and run the installer\nwget &lt;https://.../Miniforge3-Linux-x86_64.sh&gt; # Replace this URL with the one you copied\nbash Miniforge3-Linux-x86_64.sh\nFollowing the prompts from the installer:\n\nAccept the license agreement\nChoose where you’d like your installation to be kept.\n(By default your home directory)\n\nThe installer will prompt you to initialise conda. This is NOT recommended.\nThis will edit your ~/.bashrc file so the environment will activate when you log in, which can lead to unexpected interactions with batch jobs on cluster like MLeRP.\nIf you have done so by accident you can remove the additions to your .bashrc file manually (this is located in your home directory).\nYou can now activate your environment using one of the following commands:\n# Absolute paths are preferred for batch jobs or config files\nsource /path/to/install/...miniforge/bin/activate\n\n# Relative paths may be more convenient in everyday usage\nsource ./miniforge3/bin/activate \n\n# `.` works as a shorthand for the source command\n. ./mambaforge/bin/activate"
  },
  {
    "objectID": "usage/custom.html#installing-your-packages",
    "href": "usage/custom.html#installing-your-packages",
    "title": "Custom Conda Environments",
    "section": "2. Installing your packages",
    "text": "2. Installing your packages\nBoth mamba and conda environments are intended to leave their base environments untouched, so when maintaining your environments it is good practice to create a new one before installing any packages.\nTo encourage reproducability it is recommended to use an environment.yml file to maintain your packages. If you’d like a reference, the recipes to our environments are stored in /apps/conda-envs.\nWe have created the custom.yml recipe for you to use as a minimal install that will be compatible with our Strudel2 apps. Alternatively, you could opt to use one of our other environments as a starting point.\n\nCopy your chosen environment file to your home directory and modify it to suit your requirements. Make sure to uncomment the pip section if you need pipto install packages.\ncp /apps/conda-envs/custom.yml ~/custom.yml\nnano ~/custom.yml\nThen create the environment off the file. If you didn’t change the envname in the last step, by default this will create an environment with the name ‘custom’.\nmamba env create -f ~/custom.yml\nYou can now activate the environment we’ve created whenever you need to work with your scripts.\n# List all available environments\nconda env list\n\n# Activate a selected environment\nconda activate &lt;environment_name&gt;\nYou can then install packages manually if you’re still experimenting with new packages, or update your install with the environment file.\nmamba install package_name\npip install package_name\nmamba env update -f custom.yml\n\nConda’s solver can result in different package versions if installing packages in a different order. Once you have confirmed which packages you need, it is good practice to work out an environment.yml that will build your environment in one command.\nAlternatively if your application requires multiple install stages, consider a script to build the environment so that your work is reproducible.\nFor more details about environment file syntax, have a look at conda’s documentation on managing environments."
  },
  {
    "objectID": "usage/custom.html#integrating-with-strudel2",
    "href": "usage/custom.html#integrating-with-strudel2",
    "title": "Custom Conda Environments",
    "section": "3. Integrating with Strudel2",
    "text": "3. Integrating with Strudel2\nOur Jupyter Lab application should recognise the conda environment that has just been created and you will be able to select it from the environment dropdown. If the environment that you’re looking for is missing, check that its path is included in your ~/.conda/environments.txt file in your home directory.\nIf it’s missing, append the path to your environment to the bottom of the file.\necho /path/to/your/environment &gt;&gt; ~/.conda/environments.txt"
  },
  {
    "objectID": "usage/data_management.html",
    "href": "usage/data_management.html",
    "title": "Data Management",
    "section": "",
    "text": "MLeRP does not have a dedicated data transfer node. We recommend that you use the login node when managing your files."
  },
  {
    "objectID": "usage/data_management.html#jupyter-lab",
    "href": "usage/data_management.html#jupyter-lab",
    "title": "Data Management",
    "section": "Jupyter Lab",
    "text": "Jupyter Lab\nThe easiest option to move files into the MLeRP environment is to use a Jupyter Lab job through Strudel2 since it requires no additional setup. You should be able to drag and drop files into the file tree on the left to move them into the direrectory you have open.\nYou can select multiple files and drag and drop all of them at once but Jupyter Lab does not support transferring folders. So you will need to either zip your files first or create your desired structure first and drop in the files one directory at a time. Files will be added to the directory you are currently viewing.\nJupyter Lab allows you to download files back to your device by right clicking on the file(s) in the file tree and selecting ‘Download’. You can download multiple files in this way by selecting multiple files first before right clicking, though downloading folders is not supported. If you are moving many files at once, you may want to consider zipping them up first with a terminal.\nzip archive.zip filename1 filename2"
  },
  {
    "objectID": "usage/data_management.html#vs-code",
    "href": "usage/data_management.html#vs-code",
    "title": "Data Management",
    "section": "VS Code",
    "text": "VS Code\nIf you have already gone through the steps to connect your VS Code you can drag and drop files into the file tree just like with Jupyter Lab, but VS Code will allow you to drop whole folders at once, including nested folders. You can control where the files and folders end up by hovering over the desired folder.\nVS Code allows you to download files back to your device by right clicking on the selected file(s) or folder(s) in the file tree and selecting ‘Download’."
  },
  {
    "objectID": "usage/data_management.html#wget",
    "href": "usage/data_management.html#wget",
    "title": "Data Management",
    "section": "Wget",
    "text": "Wget\nIf you’re looking for an application or dataset that is publicly available from the internet, you will be able to download the data directly into the MLeRP environment with a wget command:\nwget -o &lt;/path/to/destination&gt; &lt;http://example.com&gt;"
  },
  {
    "objectID": "usage/data_management.html#git",
    "href": "usage/data_management.html#git",
    "title": "Data Management",
    "section": "Git",
    "text": "Git\nIf you are using a git repo, using git’s inbuilt tools is the simplest way to get a copy of your code into your home directory. If you’re new to git not using git to maintain your code, now is a great time to start. This will allow you to sync your code between your local device and the cluster.\nStart a new repository on GitHub or GitLab or any other git hosting service, push up a copy of your code and clone your new repository onto the cluster."
  },
  {
    "objectID": "usage/data_management.html#rsync",
    "href": "usage/data_management.html#rsync",
    "title": "Data Management",
    "section": "Rsync",
    "text": "Rsync\nIf you’re familiar with the terminal you can use rsync to synchronise file systems and to transfer large amounts of files, with the ability to stop and restart the file transfers. rsync will replicate all files in a folder from one spot to another. It first analyses both file systems to find the difference and then transfers only the changes.\nTo use rsync you’ll need to generate some SSH credentials and set up your SSH config. A typical command that uses this config to synchronise files from a local folder to MLeRP is:\nrsync -auv -e ssh &lt;/path/to/source&gt; &lt;username&gt;_MLeRP_Monash:&lt;/path/to/destination&gt;\nrsync is very powerful and has many options to help transfer data. For example it can delete unwanted files with --delete, compress data before transfer -z or can you let you see what command options might do without actually executing them --dry-run. For more info on rsync try:\nman rsync"
  },
  {
    "objectID": "connecting/vscode.html",
    "href": "connecting/vscode.html",
    "title": "VS Code",
    "section": "",
    "text": "So you’d like to use Visual Studio Code, but you need access to MLeRP too - maybe your data is on the cluster, or you want to run code interactively on a GPU, or you just really love VS Code.\nNo problem. You want a VS Code remote server.\nPlease DO NOT follow the official VS Code documentation for remote servers.\nBy default, if you follow those instructions, you will end up running the VS Code remote server on the login node. Even if you’re just managing your files, but especially if you’re running a notebook or running scripts we’ll need to allocate a resource just for you.\nThis proxy command which will forward your connection to our compute nodes rather than the login node. This will connect to a Jupyter Lab job, or if one doesn’t exist, it will make one for you.\n# Linux and Mac\nProxyCommand=\"ssh &lt;username&gt;@monash-mlerp-login0.mlerp.cloud.edu.au /apps/strudel2/strudel_apps/sshnc.sh\"\n\n# Windows\nProxyCommand=\"ssh.exe &lt;username&gt;@monash-mlerp-login0.mlerp.cloud.edu.au /apps/strudel2/strudel_apps/sshnc.sh\"\nNote that you will need to authenticate with your ssh key/cert. You can then add it to your agent or provide it to the ssh command (and proxy command) with the -i flag.\nIf you’re not sure how to use a proxy command, read on and we’ll walk you through the steps."
  },
  {
    "objectID": "connecting/vscode.html#introduction",
    "href": "connecting/vscode.html#introduction",
    "title": "VS Code",
    "section": "",
    "text": "So you’d like to use Visual Studio Code, but you need access to MLeRP too - maybe your data is on the cluster, or you want to run code interactively on a GPU, or you just really love VS Code.\nNo problem. You want a VS Code remote server.\nPlease DO NOT follow the official VS Code documentation for remote servers.\nBy default, if you follow those instructions, you will end up running the VS Code remote server on the login node. Even if you’re just managing your files, but especially if you’re running a notebook or running scripts we’ll need to allocate a resource just for you.\nThis proxy command which will forward your connection to our compute nodes rather than the login node. This will connect to a Jupyter Lab job, or if one doesn’t exist, it will make one for you.\n# Linux and Mac\nProxyCommand=\"ssh &lt;username&gt;@monash-mlerp-login0.mlerp.cloud.edu.au /apps/strudel2/strudel_apps/sshnc.sh\"\n\n# Windows\nProxyCommand=\"ssh.exe &lt;username&gt;@monash-mlerp-login0.mlerp.cloud.edu.au /apps/strudel2/strudel_apps/sshnc.sh\"\nNote that you will need to authenticate with your ssh key/cert. You can then add it to your agent or provide it to the ssh command (and proxy command) with the -i flag.\nIf you’re not sure how to use a proxy command, read on and we’ll walk you through the steps."
  },
  {
    "objectID": "connecting/vscode.html#initial-set-up-instructions",
    "href": "connecting/vscode.html#initial-set-up-instructions",
    "title": "VS Code",
    "section": "Initial set-up instructions",
    "text": "Initial set-up instructions\n\n1. Prepare VS Code\n\nInstall Visual Studio Code\nInstall the Remote Development Extension Pack\nOpen Settings with Ctrl+, and search for Remote.SSH: Remote Server Listen On Socket. Select the checkbox. \n\n\n\n2. Generate an ssh key and certificate\n\nGenerate your credentials SSH credentials through Strudel2 or through SSOSSH\nIf you’re working in Windows, ensure OpenSSH is installed and enabled\nOptionally add the key to your ssh agent. Skip this step if you want to keep things simple.\n\n\n\n3. Configure VS Code\n\nFollow the instructions on our ssh page to configure your SSH Config. Note that your config will be different if you’re using keys added to the SSH agent.\nTest our configurations with:\nssh &lt;User&gt;_MLeRP_Monash # Use this only for testing as it will connect direct to the login node\nssh &lt;User&gt;_MLeRP_Monash_job # This is the one that we will use to connect to your allocated job\n\nThe first configuration will connect directly to the login node, perfect for testing the connection. The second configuration will use the ProxyCommand to connect to a Jupyter Lab or Terminal job that you start from the Strudel2 login portal. If a job does not exist yet, it will create a small Panther QoS resource for you."
  },
  {
    "objectID": "connecting/vscode.html#using-your-vs-code-remote-server",
    "href": "connecting/vscode.html#using-your-vs-code-remote-server",
    "title": "VS Code",
    "section": "Using your VS Code remote server",
    "text": "Using your VS Code remote server\n\n1. Start a job for the remote server\nUsing Strudel2 in your web browser, login and select Jupyter Lab or Terminal. Choose the resources you will need, including QoS, number of CPUs, amount of RAM and time. Click Launch and wait for the job to begin running under Pending/Running.\nIf you skip this step, we will create a default Panther QoS job for you.\n\n\n2. Start the remote server\nYour SSH configurations should be visible from the Remote Explorer tab in the side bar. You can now connect to the cluster by selecting the appropriate SSH configuration from the menu. Hovering over an entry will reveal options to connect in the current window or connect in a new window.\n\nYou will be prompted to provide the OS of the server, select Linux. If you are using a password on your SSH key, VS Code will ask twice (once to the connect to the login nodes, then again to connect to the node running the remote server).\nYou should now have an active connection to the cluster.\n\n\n3. Using the remote server\nUsing File &gt; Open File or File &gt; Open Folder will open files and projects on the cluster.\nThere are some extensions which will carry over to your remote server, but others, such as the Jupyter extension, will need to be installed to the remote server. You can do so from the extensions menu in the side bar just as normal.\n\n\n4. Adding your python interpreters\nA VS Code remote session will not pick up any of our provided environments automatically - even when attaching to a job that activates the environment. To use an environment other that system python you will need to add it as a python interpreter.\n\nOpen the command pallet with View &gt; Command Pallete\nSelect Python: Select Interpreter\nSelect Enter interpreter path and fill in the prompt\n\nThis environment will now be visible to the python debugger and Jupyter extension.\nIf you’d like to use one of our environments, you can find the path to their interpreter on its environment page. A full list of our environments can be found here. If you’d like to use an environment that you maintain yourself through conda or mamba, the interpreter is found at:\n# Base \n/path/to/conda/bin/python3\n\n# Virtual Environment\n/path/to/conda/envs/&lt;environment_name&gt;/bin/python3"
  },
  {
    "objectID": "connecting/vscode.html#faq",
    "href": "connecting/vscode.html#faq",
    "title": "VS Code",
    "section": "FAQ",
    "text": "FAQ\n\nI see a message about “Connection Reset by peer”.\nThis will happen if you fail to authenticate too many times - perhaps typing in your key passphrase incorrectly. Wait 10 minutes, and try again. If you still run into errors please contact the helpdesk at mlerphelp@monash.edu.\n\n\nI keep getting prompted for a password even though I’m using a key.\nCheck that your connection command includes the username everwhere you need it (it should be in there twice, once for the login node and once for the compute node). Also, ensure you added your keys to the ssh-agent to avoid typing your key passphrase every time. You will need to do this after every reboot.\n\n\nI got an error message about posix spawn.\nYou’re probably on Windows. Check that you used the Windows specific command line with ssh.exe instead of ssh.\n\n\nI tried to use the ssh-agent but it says “Permissions mykey are too open.\nPrivate keys should never be shared - ensure only you have read, write, and execute permissions on your private key. Linux/Mac user see this StackOverflow post. Windows Users, see this blog post"
  },
  {
    "objectID": "connecting/ssh.html",
    "href": "connecting/ssh.html",
    "title": "SSH Credentials",
    "section": "",
    "text": "The MLeRP platform does not use passwords in any way. This means that if you want to connect to the cluster in any way other than the Strudel2, such as through your favourite terminal application or IDE, you will need some SSH credentials.\nThis YouTube video does a good job of explaining why ssh keys are more secure than passwords, even if it is designed for an AWS user."
  },
  {
    "objectID": "connecting/ssh.html#strudel2-integration",
    "href": "connecting/ssh.html#strudel2-integration",
    "title": "SSH Credentials",
    "section": "Strudel2 Integration",
    "text": "Strudel2 Integration\nRather than requiring users to create and manage SSH keys themselves, users are able to download their SSH credentials right from within Strudel2. The ‘Download SSH Credentials’ button can be found at the bottom of your ‘Account Info’ page, below the dashboards.\nThis will give you an SSH key as well as a corresponding SSH certificate. These credentials will be valid for a period before expiring. When they expire, requiring you to redownload your credentials periodically. Only the path to the key needs to be specified in the SSH command, but the corresponding certificate will need to be placed in the same directory so that the tool can find.\nYou will need to rename the files you download to remove any extra numbers that may have been added if you’ve downloaded the files more than once, for example: strudel2_ssh_key (1) -&gt; strudel2_ssh_key.\nYou will also need to set the permissions of the key and certificate to 600 with chmod before connecting.\nchmod 600 /path/to/strudel2_ssh_key*\nNote that there is a known bug where this button breaks if Strudel2 has been refreshed. If this happens reopen the app in a new tab or log out and back in before redownloading your credentials.\n\nSSH config\nTo use these credentials, you will need to initialise your SSH config so knows to use them. Add these entries to your ~/.ssh/config file:\nHost &lt;User&gt;_MLeRP_monash\n    HostName monash-mlerp-login0.mlerp.cloud.edu.au\n    User &lt;User&gt;\n    IdentityFile &lt;/path/to/ssh/key&gt;\n\nHost &lt;User&gt;_MLeRP_monash_job\n    HostName VSCode\n    User &lt;User&gt;\n    IdentityFile &lt;/path/to/ssh/key&gt;\n    ProxyCommand &lt;ProxyCommand&gt;\nThe ProxyCommand you should use will be different between Windows and Mac/Linux:\n# Linux and Mac\nProxyCommand ssh -i &lt;/path/to/ssh/key&gt; &lt;username&gt;@monash-mlerp-login0.mlerp.cloud.edu.au /apps/strudel2/strudel_apps/sshnc.sh\n\n# Windows\nProxyCommand ssh.exe -i &lt;/path/to/ssh/key&gt; &lt;username&gt;@monash-mlerp-login0.mlerp.cloud.edu.au /apps/strudel2/strudel_apps/sshnc.sh\nThis will give you two configurations:\n\n&lt;User&gt;_MLeRP_Monash\nFor connecting directly to the login node for simple administrative tasks\n&lt;User&gt;_MLeRP_Monash_job\nFor connecting to a ‘Jupyter Lab’ or ‘Terminal’ job that you launch from Strudel2. If it can’t find one, it will create a 12 hour Panther QoS job with 4 VCPUs and 16 GB RAM.\n\nssh &lt;User&gt;_MLeRP_Monash\nssh &lt;User&gt;_MLeRP_Monash_job"
  },
  {
    "objectID": "connecting/ssh.html#ssossh",
    "href": "connecting/ssh.html#ssossh",
    "title": "SSH Credentials",
    "section": "SSOSSH",
    "text": "SSOSSH\nSSOSSH is a command line tool that brings single sign on to MLeRP. You can use it as an alternative to downloading your SSH credentials from Strudel2 if you are familiar with using a terminal.\nJust like the Strudel2 method, the tool generates an SSH Certificate. This is more secure than a permanent key since the certificate will only be valid for 24 hours, requiring you to go through your organisation’s single sign on again to renew the certificate.\n\n1. Setting up the configuration file\nSSOSSH uses a configuration file in your user’s home directory named ~/.authservers.json. This file should be a list of configs for the clusters you wish to connect to.\n[\n    {\n        \"authorise\": \"https://sshauthz.cloud.cvl.org.au/pysshauthz/oauth2/oauth/authorize/choose\",\n        \"base\": \"https://sshauthz.cloud.cvl.org.au/pysshauthz/oauth2/\",\n        \"cafingerprint\": \"SHA256:ywDDZvIbx7B2AxujVIsW433fd4Sl1aZ0wl4FFsCRX/E\",\n        \"client_id\": \"Q96kt2Vtw6S78dpORktM81DH\",\n        \"desc\": \"&lt;div&gt;MLeRP&lt;/div&gt;\",\n        \"icon\": null,\n        \"login\": \"monash-mlerp-login0.mlerp.cloud.edu.au\",\n        \"logout\": \"https://sshauthz.cloud.cvl.org.au/pysshauthz/oauth2/logout\",\n        \"name\": \"MLeRP_Monash\",\n        \"proxy\": \"/apps/strudel2/strudel_apps/sshnc.sh\",\n        \"scope\": \"user:email\",\n        \"sign\": \"https://sshauthz.cloud.cvl.org.au/pysshauthz/sign/mlerp_users/api/v1/sign_key\"\n    }\n]\n\n\n2. Installing SSOSSH\nYou can pip install SSOSSH with:\npip install git+https://github.com/HecticHPCSolutions/ssossh\nor if you want to test an experimental feature:\npip install git+https://github.com/HecticHPCSolutions/ssossh@branch-name\nAfter installation you should be able to run ssossh in your favourite terminal to run the program. By default it will create the SSH keys and certificates in your .ssh folder, but you can optionally change this path or have it add direct to your SSH Agent which you may find to be neater.\n\n\n3. Generating your SSH Config\nBefore connecting to the cluster you will need to initialise your SSH config. We recommend using the --setssh flag the first time you use SSOSSH to set up some default SSH configurations to connect to the login node and start up a Jupyter session. This will generate the config described in the section above.\nOpen up your ssh config file to confirm everything is as it should be. If you have accidentally run this command multiple times or with an improperly configured ~/.authservers.json file there may be duplicate or malformed entries that you will need to correct.\n\n\n4. Connecting to the cluster\nNow, each time you want to connect to the cluster you can simply rerun the ssossh program to refresh your certificates then use your SSH or VS Code remote session as per normal.\nssossh\nssh &lt;User&gt;_MLeRP_Monash\nssh &lt;User&gt;_MLeRP_Monash_job\nYou can read more about SSOSSH at its GitHub Repo."
  },
  {
    "objectID": "connecting/ssh.html#enabling-ssh-on-windows",
    "href": "connecting/ssh.html#enabling-ssh-on-windows",
    "title": "SSH Credentials",
    "section": "Enabling SSH on Windows",
    "text": "Enabling SSH on Windows\nIf you’re working in Windows, you will need OpenSSH to be installed and enabled:\n\nCheck OpenSSH installation:\n\nNavigate to Setting &gt; System &gt; Optional Features\nSelect Optional Features.\nCheck if OpenSSH Client is in the list. If it is, go to step 2.\nIf it isn’t, select the Add a feature button at the top of the page, then select OpenSSH Client, and Install. This will install the OpenSSH Client.\n\nStart the OpenSSH Client:\n\nUse the Windows search bar to search for and open Services.\nScroll through the list to find OpenSSH Authentication Agent\nDouble click OpenSSH Authentication Agent. Change the Startup type to Automatic and select OK.\nDouble click on OpenSSH Authentication Agent again and select Start.\n\n\nThe OpenSSH Agent will now start automatically in future."
  },
  {
    "objectID": "connecting/ssh.html#adding-your-key-to-the-ssh-agent",
    "href": "connecting/ssh.html#adding-your-key-to-the-ssh-agent",
    "title": "SSH Credentials",
    "section": "Adding your key to the SSH Agent",
    "text": "Adding your key to the SSH Agent\nRather than specifying the key path in your config, you could opt to load the SSH key into your agent. This is useful if you’ve added an SSH key to MLeRP manually with a password attached to it. This way you will only be prompted for the password once per reboot. You can do this with:\nssh-add &lt;/path/to/ssh/key&gt;\nIf you do, then your config will look and ProxyCommand will look like this:\nHost &lt;User&gt;_MLeRP_monash\n    HostName monash-mlerp-login0.mlerp.cloud.edu.au\n    User &lt;User&gt;\n\nHost &lt;User&gt;_MLeRP_monash_job\n    HostName VSCode\n    User &lt;User&gt;\n    ProxyCommand &lt;ProxyCommand&gt;\n# Linux and Mac\nProxyCommand ssh -i &lt;/path/to/ssh/key&gt; &lt;username&gt;@monash-mlerp-login0.mlerp.cloud.edu.au /apps/strudel2/strudel_apps/sshnc.sh\n\n# Windows\nProxyCommand ssh.exe -i &lt;/path/to/ssh/key&gt; &lt;username&gt;@monash-mlerp-login0.mlerp.cloud.edu.au /apps/strudel2/strudel_apps/sshnc.sh"
  },
  {
    "objectID": "usage/r.html",
    "href": "usage/r.html",
    "title": "R",
    "section": "",
    "text": "If you’d like to work with R as a part of your data science workflow, you can do that on MLeRP too.\nThe full path to the R executable is as below:\nFor a specific version: /apps/R-x.x.x\nFor the latest installed version:/apps/R\nWhile we don’t support R Studio as a part of Strudel2, VS Code has a robust R plugin ecosystem that can be used as your R development environment.\nWe recommend maintaining your R virtual environment using the renv package so that you can ensure isolation, portability and reproducibility in your environments."
  },
  {
    "objectID": "usage/strudel2.html",
    "href": "usage/strudel2.html",
    "title": "Strudel2",
    "section": "",
    "text": "Strudel2 is an interactive environment to develop supports two types of jobs. You will be able to reach it from https://mlerp.cloud.edu.au/.\nIt will allow you check the cluster’s usage and your disk quota. You will also be able to launch interactive jobs on the cluster. Strudel2 offers two kinds of interactive jobs: terminal and Jupyter Lab."
  },
  {
    "objectID": "usage/strudel2.html#terminal",
    "href": "usage/strudel2.html#terminal",
    "title": "Strudel2",
    "section": "Terminal",
    "text": "Terminal\nTerminal jobs give you some requested compute attached to a simple text UI. This is ideal if you need to clone repositories, create conda environments, organise your files or anything else that you can do with a linux shell that doesn’t require a GUI.\nYou can also launch the web terminal attached to the login node if you just need a quick terminal to manage your files, however this is a shared resource with limited compute."
  },
  {
    "objectID": "usage/strudel2.html#jupyter-lab",
    "href": "usage/strudel2.html#jupyter-lab",
    "title": "Strudel2",
    "section": "Jupyter Lab",
    "text": "Jupyter Lab\nJupyter Lab jobs give you some requested compute attached to a Jupyter Lab IDE. This is ideal if you prefer experimenting in python notebooks or visualising data with a GUI.\nIf you prefer using VS Code to the Jupyter Lab IDE you can also connect to this job with the Remote Development Extension Pack. For more details see our page on connecting via VS Code.\nYou can use this app will using one of our provided conda environments, or one that you provide. If you’re looking for an envionment that’s not listed here, check that its path is included in the ~/.conda/environments.txt file in your home directory.\nWe have provided the DSKS (Data Science Kitchen Sink) series of environments for you to explore the platform and get started right away. Each version of the environment is tagged with the month that it was compiled, so that as we update and add new packages you can continue to rely on older versions of the environment for reproducability in your experiments.\nIf our conda environments don’t meet your needs, you can consider maintaining your own miniconda or mambaforge installation in your home directory. For a custom conda environment to be compatible with this app, you will need to include jupyter and dask related packages during. See this page for more information about creating a conda environment to interface with our environment."
  },
  {
    "objectID": "usage/strudel2.html#batch",
    "href": "usage/strudel2.html#batch",
    "title": "Strudel2",
    "section": "Batch",
    "text": "Batch\nThe Batch app gives you the ability to submit jobs to be picked up by the SLURM queue. This allows you to continue to run your tests while you are away from the computer and check back in later when they’re done. The app currently supports python scripts as well as bash scripts.\nOf course if you’re comfortable with manually submitting to the queue you can do so if you need the extra control. Batch jobs are run in the Lion QoS meaning you can have up to 4 running at once.\nAny outputs to terminal will be captured and stored in the job’s log file for later viewing. Be sure to checkpoint your code and periodically save any trained models so that you can reload your desired model from any chosen point during training process. Checkpointing also enables you to train your model for longer than the 24 hour wall time, as long as you save everything you need to resume at the end of your job."
  },
  {
    "objectID": "usage/strudel2.html#vs-code-server",
    "href": "usage/strudel2.html#vs-code-server",
    "title": "Strudel2",
    "section": "VS Code Server",
    "text": "VS Code Server\nCode Server offers a simpler alternative to connecting your IDE to MLeRP over SSH. Just as you can customise your VS Code experience with the desktop app using plugins, you can install VS Code plugins while using Code Server. See the Code Server documentation for more information."
  },
  {
    "objectID": "usage/strudel2.html#ollama",
    "href": "usage/strudel2.html#ollama",
    "title": "Strudel2",
    "section": "Ollama",
    "text": "Ollama\nOllama offers a way to interact with open source large language models interactively. The app will give you a chat window similar to ChatGPT, allowing you to ‘talk’ with the model of your choice. We have installed a selection of models for you. For more information on the provided models, including any model licences, please have a look at the Ollama library. More models can be made available on request, please reach out if you would like more functionality.\nAn Ollama server can also be interfaced with programmatically through the Ollama python library. To do this we recommend splitting your window with Ctrl+b %, which will give you a terminal to run your python scripts with. You can switch between panes with Ctrl+b ;. Your new terminal will operate the same as the terminal app, but with access to the Ollama server that’s running in the background.\nTo get the exact names of the models available, you can run /apps/ollama/ollama list. With the model name, you can interface with the model through the python api. For example:\nollama.chat(model='&lt;model_name&gt;', messages=[{'role': 'user', 'content': 'Why is the sky blue?'}]).\nFor more details on usage, please view the Ollama python library docs. Note that you may want to use a second app, such as our VS Code Server app to edit your python script unless you’re familiar with a terminal editor like Vim or Nano."
  },
  {
    "objectID": "usage/strudel2.html#faq",
    "href": "usage/strudel2.html#faq",
    "title": "Strudel2",
    "section": "FAQ",
    "text": "FAQ\n\nWhy can’t I connect to Jupyter Lab?\nJupyter Lab needs to be able to create files to run properly. If your disk quota is completely full, it will create empty files that will confuse the system. To fix this, ssh into the cluster or use a terminal job to reduce your disk usage back under quota, then delete the empty files which will be found at /home/&lt;USERNAME&gt;/.local/share/jupyter/runtime.\nThere is also a known bug where Brave’s ‘shield’ feature will block the Strudel2 Jupyter application. To bypass this, you’ll need to turn off ‘shields’ for both the Strudel2 home page and the Strudel2 api.\n\n\nWhy is my VS Code not attaching to the remote session?\nThe SSH certificates that SSOSSH creates are only valid for 24 hours, this means that you’ll need to generate new certificates each day before you connect. VS Code also has a known bug where it can get confused if you have another SSH client (such as MobaXTerm) open when it tries to establish the connection."
  },
  {
    "objectID": "usage/environments/dsks/dsks_2023.05.html",
    "href": "usage/environments/dsks/dsks_2023.05.html",
    "title": "Data Science Kitchen Sink",
    "section": "",
    "text": "The ‘Data Science Kitchen Sink (DSKS)’ is an environment with many typical packages for analysis and machine learning. It is intended as a starting point that users can start working with the service without needing to make your own. As their work matures and specialised packages are needed, this can be cloned to serve as a basis for the new environment.\nNote that this version was been archived with conda-pack during a migration. The environment can still be used if needed to rerun experiments, but has limitations such as not being compatible with Strudel2. Consider using a later version of DSKS if possible.\n\nExecutable Path\n/apps/conda-packs/dsks_2023.05/bin/python3 &lt;/path/to/script.py&gt;\n\n\nActivation Path\nsource /apps/conda-packs/dsks_2023.05/bin/activate\n\n\nEnvironment Definition\n\n\nCode\ncat /apps/conda-envs/dsks_2023.05.yml\n\n\nname: dsks_2023.05\nchannels:\n  - plotly\n  - huggingface\n  - fastchan\n  - rapidsai\n  - pytorch\n  - nvidia\n  - conda-forge\n\ndependencies:\n  # Interactivity\n  - jupyter\n  - jupyterlab\n  - dask\n  - dask-jobqueue\n  - autopep8\n  - tqdm\n  - matplotlib\n  - plotly\n  - wandb\n  - tensorboard\n  \n  # Data Science\n  - numpy\n  - scipy\n  - pandas\n  - rapids\n  - cupy\n  \n  # Machine Learning\n  - cudatoolkit\n  - tensorflow\n  - pytorch\n  - torchvision\n  - torchaudio\n  - lightning\n  - fastai\n  - transformers\n  - scikit-learn\n  - py-xgboost-gpu\n  - gensim\n\n\n\n\n\n\nFull Package List\n\n\nCode\n!pip list\n\n\nPackage                       Version\n----------------------------- ----------------\nabsl-py                       1.4.0\naiohttp                       3.8.5\naiosignal                     1.3.1\nanyio                         3.7.1\nappdirs                       1.4.4\nargon2-cffi                   21.3.0\nargon2-cffi-bindings          21.2.0\narrow                         1.2.3\nasttokens                     2.2.1\nastunparse                    1.6.3\nasync-lru                     2.0.4\nasync-timeout                 4.0.2\nattrs                         23.1.0\nautopep8                      2.0.2\nBabel                         2.12.1\nbackcall                      0.2.0\nbackoff                       2.2.1\nbackports.cached-property     1.0.2\nbackports.functools-lru-cache 1.6.5\nbeautifulsoup4                4.12.2\nbleach                        5.0.1\nblessed                       1.19.1\nblinker                       1.6.2\nblis                          0.7.10\nbokeh                         3.2.1\nbrotlipy                      0.7.0\nbuild                         0.10.0\nCacheControl                  0.12.14\ncached-property               1.5.2\ncachetools                    5.3.1\ncatalogue                     2.0.9\ncertifi                       2023.11.17\ncffi                          1.15.1\ncharset-normalizer            3.2.0\ncleo                          2.0.1\nclick                         8.1.6\ncloudpickle                   2.2.1\ncolorama                      0.4.6\nconda-pack                    0.7.1\nconfection                    0.1.1\ncontourpy                     1.1.0\ncrashtest                     0.4.1\ncroniter                      1.4.1\ncryptography                  41.0.3\ncupy                          12.1.0\ncycler                        0.11.0\ncymem                         2.0.7\ncytoolz                       0.12.0\ndask                          2023.8.1\ndask-jobqueue                 0.8.2\ndataclasses                   0.8\ndatasets                      2.14.4\ndateutils                     0.6.12\ndebugpy                       1.6.3\ndecorator                     5.1.1\ndeepdiff                      6.3.1\ndefusedxml                    0.7.1\ndill                          0.3.7\ndistlib                       0.3.6\ndistributed                   2023.8.1\ndocker-pycreds                0.4.0\ndulwich                       0.21.5\nentrypoints                   0.4\nexceptiongroup                1.1.2\nexecuting                     1.2.0\nfastai                        2.7.12\nfastapi                       0.101.0\nfastcore                      1.5.29\nfastdownload                  0.0.7\nfastjsonschema                2.18.0\nfastprogress                  1.0.3\nfastrlock                     0.8\nfilelock                      3.12.2\nflatbuffers                   23.5.26\nflit_core                     3.7.1\nfonttools                     4.42.0\nfqdn                          1.5.1\nfrozenlist                    1.4.0\nfsspec                        2023.6.0\ngast                          0.4.0\ngensim                        4.3.1\ngitdb                         4.0.10\nGitPython                     3.1.32\ngmpy2                         2.1.2\ngoogle-auth                   2.22.0\ngoogle-auth-oauthlib          1.0.0\ngoogle-pasta                  0.2.0\ngrpcio                        1.54.3\nh11                           0.14.0\nh5py                          3.9.0\nhtml5lib                      1.1\nhuggingface-hub               0.16.4\nhupper                        1.12\nidna                          3.4\nimportlib-metadata            6.8.0\nimportlib-resources           6.0.1\ninquirer                      3.1.3\ninstaller                     0.7.0\nipykernel                     6.16.2\nipython                       8.14.0\nipython-genutils              0.2.0\nipywidgets                    8.0.3\nisoduration                   20.11.0\nitsdangerous                  2.1.2\njaraco.classes                3.3.0\njax                           0.4.14\njaxlib                        0.4.14\njedi                          0.19.0\njeepney                       0.8.0\nJinja2                        3.1.2\njoblib                        1.3.2\njson5                         0.9.14\njsonpointer                   2.0\njsonschema                    4.19.0\njsonschema-specifications     2023.7.1\njupyter                       1.0.0\njupyter_client                7.4.8\njupyter-console               6.4.4\njupyter_core                  5.3.1\njupyter-events                0.7.0\njupyter-lsp                   2.2.0\njupyter_server                2.7.0\njupyter-server-mathjax        0.2.6\njupyter_server_terminals      0.4.4\njupyterlab                    4.0.5\njupyterlab_git                0.50.0\njupyterlab-pygments           0.2.2\njupyterlab_server             2.24.0\njupyterlab-widgets            3.0.8\nkeras                         2.12.0\nKeras-Preprocessing           1.1.2\nkeyring                       23.13.1\nkiwisolver                    1.4.4\nlangcodes                     3.3.0\nlightning                     2.0.7\nlightning-cloud               0.5.37\nlightning-utilities           0.9.0\nlocket                        1.0.0\nlockfile                      0.12.2\nlz4                           4.3.2\nMarkdown                      3.4.4\nmarkdown-it-py                3.0.0\nMarkupSafe                    2.1.3\nmatplotlib                    3.7.2\nmatplotlib-inline             0.1.6\nmdurl                         0.1.0\nmistune                       0.8.4\nml-dtypes                     0.2.0\nmore-itertools                10.1.0\nmpmath                        1.3.0\nmsgpack                       1.0.5\nmultidict                     6.0.4\nmultiprocess                  0.70.15\nmunkres                       1.1.4\nmurmurhash                    1.0.9\nnbclient                      0.6.6\nnbconvert                     6.5.0\nnbdime                        4.0.1\nnbformat                      5.9.2\nnest-asyncio                  1.5.6\nnetworkx                      3.1\nnotebook                      6.4.12\nnotebook_shim                 0.2.3\nnumpy                         1.25.2\noauthlib                      3.2.2\nopt-einsum                    3.3.0\nordered-set                   4.1.0\norjson                        3.9.3\noverrides                     7.4.0\npackaging                     23.1\npandas                        2.0.3\npandocfilters                 1.5.0\nparso                         0.8.3\npartd                         1.3.0\nPasteDeploy                   3.0.1\npathtools                     0.1.2\npathy                         0.10.2\npexpect                       4.8.0\npickleshare                   0.7.5\nPillow                        10.0.0\npip                           23.2.1\npkginfo                       1.9.6\npkgutil_resolve_name          1.3.10\nplaster                       1.0\nplaster-pastedeploy           0.7\nplatformdirs                  3.5.1\nplotly                        5.16.1\nply                           3.11\npoetry                        1.5.1\npoetry-core                   1.6.1\npoetry-plugin-export          1.4.0\npooch                         1.7.0\npreshed                       3.0.8\nprometheus-client             0.14.1\nprompt-toolkit                3.0.39\nprotobuf                      4.21.12\npsutil                        5.9.5\nptyprocess                    0.7.0\npure-eval                     0.2.2\npyarrow                       12.0.1\npyasn1                        0.4.8\npyasn1-modules                0.2.7\npycodestyle                   2.11.0\npycparser                     2.21\npydantic                      1.10.12\nPygments                      2.16.1\nPyJWT                         2.8.0\npyOpenSSL                     23.2.0\npyparsing                     3.0.9\npyproject_hooks               1.0.0\nPyQt5                         5.15.9\nPyQt5-sip                     12.12.2\npyramid                       2.0.1\nPySocks                       1.7.1\npython-dateutil               2.8.2\npython-editor                 1.0.4\npython-json-logger            2.0.7\npython-multipart              0.0.6\npytorch-lightning             2.0.6\npytz                          2023.3\npyu2f                         0.1.5\nPyYAML                        6.0\npyzmq                         24.0.1\nqtconsole                     5.3.1\nQtPy                          2.1.0\nrapidfuzz                     2.15.1\nrapids                        0.0.1\nreadchar                      4.0.5.dev0\nreferencing                   0.30.2\nregex                         2023.8.8\nrequests                      2.31.0\nrequests-oauthlib             1.3.1\nrequests-toolbelt             1.0.0\nrfc3339-validator             0.1.4\nrfc3986-validator             0.1.1\nrich                          13.5.1\nrpds-py                       0.9.2\nrsa                           4.9\nsacremoses                    0.0.43\nsafetensors                   0.3.2\nscikit-learn                  1.3.0\nscipy                         1.11.2\nSecretStorage                 3.3.3\nSend2Trash                    1.8.0\nsentry-sdk                    1.29.2\nsetproctitle                  1.3.2\nsetuptools                    65.6.3\nshellingham                   1.5.1\nsip                           6.7.11\nsix                           1.16.0\nsmart-open                    5.2.1\nsmmap                         3.0.5\nsniffio                       1.3.0\nsortedcontainers              2.4.0\nsoupsieve                     2.3.2.post1\nspacy                         3.6.1\nspacy-legacy                  3.0.12\nspacy-loggers                 1.0.4\nsrsly                         2.4.7\nssossh                        0.0.4\nstack-data                    0.6.2\nstarlette                     0.27.0\nstarsessions                  1.3.0\nsympy                         1.12\ntblib                         1.7.0\ntenacity                      8.2.2\ntensorboard                   2.12.3\ntensorboard-data-server       0.7.0\ntensorflow                    2.12.1\ntensorflow-estimator          2.12.0\ntermcolor                     2.3.0\nterminado                     0.15.0\nthinc                         8.1.11\nthreadpoolctl                 3.2.0\ntinycss2                      1.1.1\ntokenizers                    0.13.3\ntoml                          0.10.2\ntomli                         2.0.1\ntomlkit                       0.12.1\ntoolz                         0.12.0\ntorch                         2.0.0.post200\ntorchaudio                    2.0.0\ntorchmetrics                  1.0.3\ntorchvision                   0.15.2a0+072ec57\ntornado                       6.3.2\ntqdm                          4.66.1\ntraitlets                     5.9.0\ntransformers                  4.31.0\ntranslationstring             1.4\ntrove-classifiers             2023.8.7\ntyper                         0.9.0\ntyping_extensions             4.5.0\ntyping-utils                  0.1.0\ntzdata                        2023.3\nunicodedata2                  15.0.0\nuri-template                  1.3.0\nurllib3                       1.26.15\nuvicorn                       0.23.2\nvenusian                      3.0.0\nvirtualenv                    20.24.1\nwandb                         0.15.8\nwasabi                        1.1.2\nwcwidth                       0.2.6\nwebcolors                     1.13\nwebencodings                  0.5.1\nWebOb                         1.8.7\nwebsocket-client              1.6.1\nwebsockets                    11.0.3\nWerkzeug                      2.3.6\nwheel                         0.41.1\nwidgetsnbextension            4.0.4\nwrapt                         1.15.0\nxgboost                       1.7.6\nxxhash                        0.0.0\nxyzservices                   2023.7.0\nyarl                          1.9.2\nzict                          3.0.0\nzipp                          3.16.2\nzope.deprecation              4.4.0\nzope.interface                6.0"
  },
  {
    "objectID": "usage/environments/dsks/dsks_2024.06.html",
    "href": "usage/environments/dsks/dsks_2024.06.html",
    "title": "Data Science Kitchen Sink",
    "section": "",
    "text": "The ‘Data Science Kitchen Sink (DSKS)’ is an environment with many typical packages for analysis and machine learning. It is intended as a starting point that users can start working with the service without needing to make your own. As their work matures and specialised packages are needed, this can be cloned to serve as a basis for the new environment.\n\nExecutable Path\n/apps/mambaforge/envs/dsks_2024.06/bin/python3 &lt;/path/to/script.py&gt;\n\n\nActivation Path\nsource /apps/mambaforge/envs/dsks_2024.06/bin/activate\n\n\nEnvironment Definition\n\n\nCode\n!cat /apps/conda-envs/dsks_2024.06.yml\n\n\nname: dsks_2024.06\nchannels:\n  - plotly\n  - huggingface\n  - fastchan\n  - rapidsai\n  - pytorch\n  - nvidia\n  - conda-forge\n\ndependencies:\n  # Interactivity\n  - jupyter\n  - jupyterlab\n  - dask\n  - dask-jobqueue\n  - autopep8\n  - tqdm\n  - matplotlib\n  - plotly\n  - seaborn\n  - wandb\n  - tensorboard\n  - pytest\n\n  # Data Types\n  - jinja2\n  - pillow\n  - pyyaml\n  - geopandas\n  - imutils\n  - opencv\n  - nltk\n  \n  # Data Science\n  - numpy\n  - scipy\n  - pandas\n  - rapids\n  - cupy\n  \n  # Machine Learning\n  - cudatoolkit\n  - tensorflow\n  - pytorch\n  - torchvision\n  - torchaudio\n  - lightning\n  - fastai\n  - transformers\n  - scikit-learn\n  - scikit-image\n  - py-xgboost-gpu\n  - gensim\n  - gym\n\n  # Pip packages\n  - pip\n  - pip:\n    - submitit\n    - tensorboard_plugin_profile\n\n\n\n\nFull Package List\n\n\nCode\n!conda list\n\n\n# packages in environment at /apps/mambaforge/envs/dsks_2024.06:\n#\n# Name                    Version                   Build  Channel\n_libgcc_mutex             0.1                 conda_forge    fastchan\n_openmp_mutex             4.5                  2_kmp_llvm    fastchan\n_py-xgboost-mutex         2.0                       gpu_0    conda-forge\nabsl-py                   2.1.0              pyhd8ed1ab_0    conda-forge\naiohttp                   3.8.5           py310h2372a71_0    fastchan\naiosignal                 1.3.1              pyhd8ed1ab_0    fastchan\nalsa-lib                  1.2.11               hd590300_1    conda-forge\nannotated-types           0.5.0              pyhd8ed1ab_0    fastchan\nanyio                     3.7.1              pyhd8ed1ab_0    fastchan\naom                       3.9.0                hac33072_0    conda-forge\nappdirs                   1.4.4              pyh9f0ad1d_0    fastchan\nargon2-cffi               21.3.0             pyhd8ed1ab_0    fastchan\nargon2-cffi-bindings      21.2.0          py310h5764c6d_2    fastchan\narrow                     1.3.0              pyhd8ed1ab_0    conda-forge\nasttokens                 2.4.0              pyhd8ed1ab_0    fastchan\nastunparse                1.6.3              pyhd8ed1ab_0    fastchan\nasync-lru                 2.0.4              pyhd8ed1ab_0    conda-forge\nasync-timeout             4.0.3              pyhd8ed1ab_0    fastchan\nattr                      2.5.1                h166bdaf_0    fastchan\nattrs                     23.1.0             pyh71513ae_0    fastchan\nautopep8                  2.2.0              pyhd8ed1ab_0    conda-forge\naws-c-auth                0.7.22               h96bc93b_2    conda-forge\naws-c-cal                 0.6.14               h88a6e22_1    conda-forge\naws-c-common              0.9.19               h4ab18f5_0    conda-forge\naws-c-compression         0.2.18               h83b837d_6    conda-forge\naws-c-event-stream        0.4.2               ha47c788_12    conda-forge\naws-c-http                0.8.1               h29d6fba_17    conda-forge\naws-c-io                  0.14.8               h21d4f22_5    conda-forge\naws-c-mqtt                0.10.4               h759edc4_4    conda-forge\naws-c-s3                  0.5.9                h594631b_3    conda-forge\naws-c-sdkutils            0.1.16               h83b837d_2    conda-forge\naws-checksums             0.1.18               h83b837d_6    conda-forge\naws-crt-cpp               0.26.9               he3a8b3b_0    conda-forge\naws-sdk-cpp               1.11.329             hba8bd5f_3    conda-forge\nazure-core-cpp            1.11.1               h91d86a7_1    conda-forge\nazure-identity-cpp        1.6.0                hf1915f5_1    conda-forge\nazure-storage-blobs-cpp   12.10.0              h00ab1b0_1    conda-forge\nazure-storage-common-cpp  12.5.0               h94269e2_4    conda-forge\nbabel                     2.14.0             pyhd8ed1ab_0    conda-forge\nbackcall                  0.2.0              pyh9f0ad1d_0    fastchan\nbackports                 1.0                        py_2    fastchan\nbackports.functools_lru_cache 1.6.5              pyhd8ed1ab_0    fastchan\nbeautifulsoup4            4.12.2             pyha770c72_0    fastchan\nblas                      2.114                       mkl    fastchan\nblas-devel                3.9.0            14_linux64_mkl    fastchan\nbleach                    5.0.1              pyhd8ed1ab_0    fastchan\nblosc                     1.21.5               hc2324a3_1    conda-forge\nbokeh                     3.4.1              pyhd8ed1ab_0    conda-forge\nbranca                    0.7.2              pyhd8ed1ab_0    conda-forge\nbrotli                    1.1.0                hd590300_0    fastchan\nbrotli-bin                1.1.0                hd590300_0    fastchan\nbrotli-python             1.1.0           py310hc6cd4ac_0    fastchan\nbrunsli                   0.1                  h9c3ff4c_0    fastchan\nbzip2                     1.0.8                h7f98852_4    fastchan\nc-ares                    1.28.1               hd590300_0    conda-forge\nc-blosc2                  2.14.4               hb4ffafa_1    conda-forge\nca-certificates           2024.6.2             hbcca054_0    conda-forge\ncached-property           1.5.2                hd8ed1ab_1    conda-forge\ncached_property           1.5.2              pyha770c72_1    conda-forge\ncairo                     1.18.0               h3faef2a_0    conda-forge\ncatalogue                 2.0.10          py310hff52083_0    fastchan\ncertifi                   2023.7.22          pyhd8ed1ab_0    fastchan\ncffi                      1.15.1          py310h255011f_0    fastchan\ncfitsio                   4.4.0                hbdc6101_1    conda-forge\ncharls                    2.4.2                h59595ed_0    conda-forge\ncharset-normalizer        3.2.0              pyhd8ed1ab_0    fastchan\nclick                     8.1.7           unix_pyh707e725_0    fastchan\nclick-plugins             1.1.1                      py_0    conda-forge\ncligj                     0.7.2              pyhd8ed1ab_1    conda-forge\ncloudpickle               2.2.1              pyhd8ed1ab_0    fastchan\ncolorama                  0.4.6              pyhd8ed1ab_0    fastchan\nconfection                0.1.3           py310h17c5347_0    fastchan\ncontourpy                 1.2.1           py310hd41b1e2_0    conda-forge\ncuda-cudart               12.1.105                      0    nvidia\ncuda-cupti                12.1.105                      0    nvidia\ncuda-libraries            12.1.0                        0    nvidia\ncuda-nvrtc                12.1.105                      0    nvidia\ncuda-nvtx                 12.1.105                      0    nvidia\ncuda-opencl               12.4.127                      0    nvidia\ncuda-runtime              12.1.0                        0    nvidia\ncuda-version              11.8                 h70ddcb2_3    conda-forge\ncudatoolkit               11.8.0              h37601d7_10    fastchan\ncupy                      13.1.0          py310h189a05f_4    conda-forge\ncupy-core                 13.1.0          py310h71e26cc_4    conda-forge\ncycler                    0.11.0             pyhd8ed1ab_0    fastchan\ncymem                     2.0.8           py310hc6cd4ac_0    fastchan\ncython-blis               0.7.10          py310h278f3c1_1    fastchan\ncytoolz                   0.12.0          py310h5764c6d_0    fastchan\ndask                      2024.5.2           pyhd8ed1ab_0    conda-forge\ndask-core                 2024.5.2           pyhd8ed1ab_0    conda-forge\ndask-expr                 1.1.2              pyhd8ed1ab_0    conda-forge\ndask-jobqueue             0.8.5              pyhd8ed1ab_0    conda-forge\ndataclasses               0.8                pyhc8e2a94_3    fastchan\ndatasets                  2.19.2                     py_0    huggingface\ndav1d                     1.2.1                hd590300_0    conda-forge\ndbus                      1.13.6               h5008d03_3    fastchan\ndebugpy                   1.6.3           py310hd8f1fbe_0    fastchan\ndecorator                 5.1.1              pyhd8ed1ab_0    fastchan\ndefusedxml                0.7.1              pyhd8ed1ab_0    fastchan\ndill                      0.3.7              pyhd8ed1ab_0    fastchan\ndistributed               2024.5.2           pyhd8ed1ab_0    conda-forge\ndm-tree                   0.1.8           py310ha8c1f0e_4    conda-forge\ndocker-pycreds            0.4.0                      py_0    conda-forge\ndouble-conversion         3.3.0                h59595ed_0    conda-forge\nentrypoints               0.4                pyhd8ed1ab_0    fastchan\nexceptiongroup            1.1.3              pyhd8ed1ab_0    fastchan\nexecuting                 1.2.0              pyhd8ed1ab_0    fastchan\nexpat                     2.6.2                h59595ed_0    conda-forge\nfastai                    2.1.10                     py_0    fastchan\nfastcore                  1.5.29                     py_0    fastchan\nfastprogress              1.0.3                      py_0    fastchan\nfastrlock                 0.8.2           py310hc6cd4ac_2    conda-forge\nffmpeg                    6.1.1           gpl_he44c6f3_112    conda-forge\nfilelock                  3.12.4             pyhd8ed1ab_0    fastchan\nfiona                     1.9.6           py310h033d26a_3    conda-forge\nflatbuffers               24.3.25              h59595ed_0    conda-forge\nflit-core                 3.7.1              pyhd8ed1ab_0    fastchan\nfmt                       10.2.1               h00ab1b0_0    conda-forge\nfolium                    0.16.0             pyhd8ed1ab_0    conda-forge\nfont-ttf-dejavu-sans-mono 2.37                 hab24e00_0    fastchan\nfont-ttf-inconsolata      3.000                h77eed37_0    fastchan\nfont-ttf-source-code-pro  2.038                h77eed37_0    fastchan\nfont-ttf-ubuntu           0.83                 hab24e00_0    fastchan\nfontconfig                2.14.2               h14ed4e7_0    conda-forge\nfonts-conda-ecosystem     1                             0    fastchan\nfonts-conda-forge         1                             0    fastchan\nfonttools                 4.42.1          py310h2372a71_0    fastchan\nfqdn                      1.5.1              pyhd8ed1ab_0    conda-forge\nfreeglut                  3.2.2                hac7e632_2    conda-forge\nfreetype                  2.12.1               h267a509_2    conda-forge\nfreexl                    2.0.0                h743c826_0    conda-forge\nfribidi                   1.0.10               h36c2ea0_0    fastchan\nfrozenlist                1.4.0           py310h2372a71_0    fastchan\nfsspec                    2023.9.0           pyh1a96a4e_0    fastchan\ngast                      0.5.4              pyhd8ed1ab_0    conda-forge\ngdal                      3.9.0           py310hb8ea937_5    conda-forge\ngensim                    4.3.2           py310hcc13569_1    conda-forge\ngeopandas                 0.14.4             pyhd8ed1ab_0    conda-forge\ngeopandas-base            0.14.4             pyha770c72_0    conda-forge\ngeos                      3.12.1               h59595ed_0    conda-forge\ngeotiff                   1.7.3                h928be8b_0    conda-forge\ngettext                   0.21.1               h27087fc_0    fastchan\ngflags                    2.2.2             he1b5a44_1004    fastchan\ngiflib                    5.2.2                hd590300_0    conda-forge\ngitdb                     4.0.11             pyhd8ed1ab_0    conda-forge\ngitpython                 3.1.43             pyhd8ed1ab_0    conda-forge\nglib                      2.80.2               hf974151_0    conda-forge\nglib-tools                2.80.2               hb6ce0ca_0    conda-forge\nglog                      0.7.0                hed5481d_0    conda-forge\ngmp                       6.3.0                h59595ed_1    conda-forge\ngmpy2                     2.1.2           py310h3ec546c_1    fastchan\ngnutls                    3.7.9                hb077bed_0    conda-forge\ngoogle-pasta              0.2.0              pyh8c360ce_0    conda-forge\ngraphite2                 1.3.13            h58526e2_1001    fastchan\ngrpcio                    1.62.2          py310h1b8f574_0    conda-forge\ngst-plugins-base          1.24.4               h9ad1361_0    conda-forge\ngstreamer                 1.24.4               haf2f30d_0    conda-forge\ngviz-api                  1.10.0                   pypi_0    pypi\ngym                       0.26.1          py310hfdc917e_0    conda-forge\ngym-notices               0.0.8              pyhd8ed1ab_0    conda-forge\nh11                       0.14.0             pyhd8ed1ab_0    conda-forge\nh2                        4.1.0              pyhd8ed1ab_0    conda-forge\nh5py                      3.11.0          nompi_py310hf054cd7_101    conda-forge\nharfbuzz                  8.5.0                hfac3d4d_0    conda-forge\nhdf4                      4.2.15               h2a13503_7    conda-forge\nhdf5                      1.14.3          nompi_hdf9ad27_104    conda-forge\nhpack                     4.0.0              pyh9f0ad1d_0    conda-forge\nhttpcore                  1.0.5              pyhd8ed1ab_0    conda-forge\nhttpx                     0.27.0             pyhd8ed1ab_0    conda-forge\nhuggingface_hub           0.23.2                     py_0    huggingface\nhupper                    1.12.1             pyhd8ed1ab_0    conda-forge\nhyperframe                6.0.1              pyhd8ed1ab_0    conda-forge\nicu                       73.2                 h59595ed_0    fastchan\nidna                      3.4                pyhd8ed1ab_0    fastchan\nimagecodecs               2024.6.1        py310h6158a3f_0    conda-forge\nimageio                   2.25.0             pyh24c5eb1_0    fastchan\nimath                     3.1.11               hfc55251_0    conda-forge\nimportlib-metadata        6.8.0              pyha770c72_0    fastchan\nimportlib_metadata        6.8.0                hd8ed1ab_0    fastchan\nimportlib_resources       6.1.0              pyhd8ed1ab_0    fastchan\nimutils                   0.5.4           py310hff52083_4    conda-forge\niniconfig                 2.0.0              pyhd8ed1ab_0    conda-forge\nipykernel                 6.16.2             pyh210e3f2_0    fastchan\nipython                   8.15.0             pyh0d859eb_0    fastchan\nipython_genutils          0.2.0                      py_1    fastchan\nipywidgets                8.0.3              pyhd8ed1ab_0    fastchan\nisoduration               20.11.0            pyhd8ed1ab_0    conda-forge\njasper                    4.2.4                h536e39c_0    conda-forge\njedi                      0.19.0             pyhd8ed1ab_0    fastchan\njinja2                    3.1.2              pyhd8ed1ab_0    fastchan\njoblib                    1.3.2              pyhd8ed1ab_0    fastchan\njson-c                    0.17                 h7ab15ed_0    conda-forge\njson5                     0.9.14             pyhd8ed1ab_0    fastchan\njsonpointer               2.4             py310hff52083_2    fastchan\njsonschema                4.22.0             pyhd8ed1ab_0    conda-forge\njsonschema-specifications 2023.7.1           pyhd8ed1ab_0    fastchan\njsonschema-with-format-nongpl 4.22.0             pyhd8ed1ab_0    conda-forge\njupyter                   1.0.0           py310hff52083_7    fastchan\njupyter-lsp               2.2.5              pyhd8ed1ab_0    conda-forge\njupyter_client            7.4.8              pyhd8ed1ab_0    fastchan\njupyter_console           6.4.4              pyhd8ed1ab_0    fastchan\njupyter_core              5.3.1           py310hff52083_0    fastchan\njupyter_events            0.10.0             pyhd8ed1ab_0    conda-forge\njupyter_server            2.14.1             pyhd8ed1ab_0    conda-forge\njupyter_server_terminals  0.5.3              pyhd8ed1ab_0    conda-forge\njupyterlab                4.2.1              pyhd8ed1ab_0    conda-forge\njupyterlab_pygments       0.2.2              pyhd8ed1ab_0    fastchan\njupyterlab_server         2.27.2             pyhd8ed1ab_0    conda-forge\njupyterlab_widgets        3.0.11             pyhd8ed1ab_0    conda-forge\njxrlib                    1.1                  h7f98852_2    fastchan\nkealib                    1.5.3                hee9dde6_1    conda-forge\nkeras                     3.1.0              pyhd8ed1ab_0    conda-forge\nkeyutils                  1.6.1                h166bdaf_0    fastchan\nkiwisolver                1.4.5           py310hd41b1e2_0    fastchan\nkrb5                      1.21.2               h659d440_0    fastchan\nlame                      3.100             h7f98852_1001    fastchan\nlangcodes                 3.3.0              pyhd8ed1ab_0    fastchan\nlcms2                     2.16                 hb7c19ff_0    conda-forge\nld_impl_linux-64          2.40                 hf3520f5_2    conda-forge\nlerc                      4.0.0                h27087fc_0    fastchan\nlibabseil                 20240116.2      cxx17_h59595ed_0    conda-forge\nlibaec                    1.1.3                h59595ed_0    conda-forge\nlibarchive                3.7.4                hfca40fe_0    conda-forge\nlibarrow                  16.1.0           hcb6531f_6_cpu    conda-forge\nlibarrow-acero            16.1.0           hac33072_6_cpu    conda-forge\nlibarrow-dataset          16.1.0           hac33072_6_cpu    conda-forge\nlibarrow-substrait        16.1.0           h7e0c224_6_cpu    conda-forge\nlibasprintf               0.22.5               h661eb56_2    conda-forge\nlibass                    0.17.1               h8fe9dca_1    conda-forge\nlibavif16                 1.0.4                hd2f8ffe_4    conda-forge\nlibblas                   3.9.0            14_linux64_mkl    fastchan\nlibboost-headers          1.85.0               ha770c72_1    conda-forge\nlibbrotlicommon           1.1.0                hd590300_0    fastchan\nlibbrotlidec              1.1.0                hd590300_0    fastchan\nlibbrotlienc              1.1.0                hd590300_0    fastchan\nlibcap                    2.69                 h0f662aa_0    conda-forge\nlibcblas                  3.9.0            14_linux64_mkl    fastchan\nlibclang-cpp15            15.0.7          default_h127d8a8_5    conda-forge\nlibclang-cpp18.1          18.1.6          default_h127d8a8_0    conda-forge\nlibclang13                18.1.6          default_h5d6823c_0    conda-forge\nlibcrc32c                 1.1.2                h9c3ff4c_0    fastchan\nlibcublas                 12.1.0.26                     0    nvidia\nlibcufft                  11.0.2.4                      0    nvidia\nlibcufile                 1.9.1.3                       0    nvidia\nlibcups                   2.3.3                h4637d8d_4    conda-forge\nlibcurand                 10.3.5.147                    0    nvidia\nlibcurl                   8.8.0                hca28451_0    conda-forge\nlibcusolver               11.4.4.55                     0    nvidia\nlibcusparse               12.0.2.55                     0    nvidia\nlibdeflate                1.20                 hd590300_0    conda-forge\nlibdrm                    2.4.120              hd590300_0    conda-forge\nlibedit                   3.1.20191231         he28a2e2_2    conda-forge\nlibev                     4.33                 h516909a_1    fastchan\nlibevent                  2.1.12               h3358134_0    fastchan\nlibexpat                  2.6.2                h59595ed_0    conda-forge\nlibffi                    3.4.2                h7f98852_5    conda-forge\nlibflac                   1.4.3                h59595ed_0    fastchan\nlibgcc-ng                 12.1.0              h8d9b700_16    fastchan\nlibgcrypt                 1.10.3               hd590300_0    conda-forge\nlibgdal                   3.9.0                h77540a9_5    conda-forge\nlibgettextpo              0.22.5               h59595ed_2    conda-forge\nlibgfortran-ng            13.2.0               h69a702a_0    fastchan\nlibgfortran5              13.2.0               ha4646dd_0    fastchan\nlibglib                   2.80.2               hf974151_0    conda-forge\nlibglu                    9.0.0             he1b5a44_1001    fastchan\nlibgoogle-cloud           2.24.0               h2736e30_0    conda-forge\nlibgoogle-cloud-storage   2.24.0               h3d9a0c8_0    conda-forge\nlibgpg-error              1.47                 h71f35ed_0    fastchan\nlibgrpc                   1.62.2               h15f2491_0    conda-forge\nlibhwloc                  2.10.0          default_h5622ce7_1001    conda-forge\nlibhwy                    1.1.0                h00ab1b0_0    conda-forge\nlibiconv                  1.17                 h166bdaf_0    fastchan\nlibidn2                   2.3.4                h166bdaf_0    fastchan\nlibjpeg-turbo             3.0.0                hd590300_1    conda-forge\nlibjxl                    0.10.2               hcae5a98_0    conda-forge\nlibkml                    1.3.0             h01aab08_1018    conda-forge\nliblapack                 3.9.0            14_linux64_mkl    fastchan\nliblapacke                3.9.0            14_linux64_mkl    fastchan\nlibllvm15                 15.0.7               hb3ce162_4    conda-forge\nlibllvm18                 18.1.6               hb77312f_0    conda-forge\nlibnetcdf                 4.9.2           nompi_h9612171_113    conda-forge\nlibnghttp2                1.58.0               h47da74e_1    conda-forge\nlibnpp                    12.0.2.50                     0    nvidia\nlibnsl                    2.0.1                hd590300_0    conda-forge\nlibnvjitlink              12.1.105                      0    nvidia\nlibnvjpeg                 12.1.1.14                     0    nvidia\nlibogg                    1.3.4                h7f98852_1    fastchan\nlibopencv                 4.9.0           qt6_py310h744f6db_615    conda-forge\nlibopenvino               2024.1.0             h2da1b83_7    conda-forge\nlibopenvino-auto-batch-plugin 2024.1.0             hb045406_7    conda-forge\nlibopenvino-auto-plugin   2024.1.0             hb045406_7    conda-forge\nlibopenvino-hetero-plugin 2024.1.0             h5c03a75_7    conda-forge\nlibopenvino-intel-cpu-plugin 2024.1.0             h2da1b83_7    conda-forge\nlibopenvino-intel-gpu-plugin 2024.1.0             h2da1b83_7    conda-forge\nlibopenvino-intel-npu-plugin 2024.1.0             he02047a_7    conda-forge\nlibopenvino-ir-frontend   2024.1.0             h5c03a75_7    conda-forge\nlibopenvino-onnx-frontend 2024.1.0             h07e8aee_7    conda-forge\nlibopenvino-paddle-frontend 2024.1.0             h07e8aee_7    conda-forge\nlibopenvino-pytorch-frontend 2024.1.0             he02047a_7    conda-forge\nlibopenvino-tensorflow-frontend 2024.1.0             h39126c6_7    conda-forge\nlibopenvino-tensorflow-lite-frontend 2024.1.0             he02047a_7    conda-forge\nlibopus                   1.3.1                h7f98852_1    fastchan\nlibparquet                16.1.0           h6a7eafb_6_cpu    conda-forge\nlibpciaccess              0.18                 hd590300_0    conda-forge\nlibpng                    1.6.43               h2797004_0    conda-forge\nlibpq                     16.3                 ha72fbe1_0    conda-forge\nlibprotobuf               4.25.3               h08a7969_0    conda-forge\nlibre2-11                 2023.09.01           h5a48ba9_2    conda-forge\nlibrttopo                 1.1.0               h8917695_15    conda-forge\nlibsndfile                1.2.2                hbc2eb40_0    fastchan\nlibsodium                 1.0.18               h36c2ea0_1    fastchan\nlibspatialindex           1.9.3                he02047a_5    conda-forge\nlibspatialite             5.1.0                h5539517_6    conda-forge\nlibsqlite                 3.45.3               h2797004_0    conda-forge\nlibssh2                   1.11.0               h0841786_0    conda-forge\nlibstdcxx-ng              13.2.0               h7e041cc_0    fastchan\nlibsystemd0               255                  h3516f8a_1    conda-forge\nlibtasn1                  4.19.0               h166bdaf_0    fastchan\nlibthrift                 0.19.0               hb90f79a_1    conda-forge\nlibtiff                   4.6.0                h1dd3fc0_3    conda-forge\nlibunistring              0.9.10               h7f98852_0    fastchan\nlibutf8proc               2.8.0                h166bdaf_0    fastchan\nlibuuid                   2.38.1               h0b41bf4_0    fastchan\nlibva                     2.21.0               hd590300_0    conda-forge\nlibvorbis                 1.3.7                h9c3ff4c_0    fastchan\nlibvpx                    1.14.0               h59595ed_0    conda-forge\nlibwebp-base              1.4.0                hd590300_0    conda-forge\nlibxcb                    1.15                 h0b41bf4_0    fastchan\nlibxcrypt                 4.4.36               hd590300_1    conda-forge\nlibxgboost                2.0.3           rapidsai_hc9586f8_2    rapidsai\nlibxkbcommon              1.7.0                h662e7e4_0    conda-forge\nlibxml2                   2.12.7               hc051c1a_1    conda-forge\nlibzip                    1.10.1               h2629f0a_3    conda-forge\nlibzlib                   1.3.1                h4ab18f5_1    conda-forge\nlibzopfli                 1.0.3                h9c3ff4c_0    fastchan\nlightning                 2.2.5              pyhd8ed1ab_0    conda-forge\nlightning-utilities       0.11.2             pyhd8ed1ab_0    conda-forge\nllvm-openmp               15.0.7               h0cdce71_0    conda-forge\nlocket                    1.0.0              pyhd8ed1ab_0    fastchan\nlz4                       4.3.3           py310h350c4a5_0    conda-forge\nlz4-c                     1.9.4                hcb278e6_0    fastchan\nlzo                       2.10              h516909a_1000    fastchan\nmapclassify               2.6.1              pyhd8ed1ab_0    conda-forge\nmarkdown                  3.6                pyhd8ed1ab_0    conda-forge\nmarkdown-it-py            3.0.0              pyhd8ed1ab_0    fastchan\nmarkupsafe                2.1.3           py310h2372a71_0    fastchan\nmatplotlib                3.8.0           py310hff52083_0    fastchan\nmatplotlib-base           3.8.0           py310h62c0568_0    fastchan\nmatplotlib-inline         0.1.6              pyhd8ed1ab_0    fastchan\nmdurl                     0.1.0              pyhd8ed1ab_0    fastchan\nminizip                   4.0.6                h9d307f2_0    conda-forge\nmistune                   0.8.4           py310h6acc77f_1005    fastchan\nmkl                       2022.0.1           h8d4b97c_803    fastchan\nmkl-devel                 2022.0.1           ha770c72_804    fastchan\nmkl-include               2022.0.1           h8d4b97c_803    fastchan\nml_dtypes                 0.3.2           py310hcc13569_0    conda-forge\nmpc                       1.3.1                hfe3b2da_0    fastchan\nmpfr                      4.2.0                hb012696_0    fastchan\nmpg123                    1.31.3               hcb278e6_0    fastchan\nmpmath                    1.3.0              pyhd8ed1ab_0    fastchan\nmsgpack-python            1.0.8           py310h25c7140_0    conda-forge\nmultidict                 6.0.4           py310h1fa729e_0    fastchan\nmultiprocess              0.70.15         py310h2372a71_0    fastchan\nmunkres                   1.1.4              pyh9f0ad1d_0    fastchan\nmurmurhash                1.0.10          py310hc6cd4ac_0    fastchan\nmysql-common              8.3.0                hf1915f5_4    conda-forge\nmysql-libs                8.3.0                hca2cd23_4    conda-forge\nnamex                     0.0.8              pyhd8ed1ab_0    conda-forge\nnbclient                  0.6.6              pyhd8ed1ab_0    fastchan\nnbconvert                 6.5.0              pyhd8ed1ab_0    fastchan\nnbconvert-core            6.5.0              pyhd8ed1ab_0    fastchan\nnbconvert-pandoc          6.5.0              pyhd8ed1ab_0    fastchan\nnbformat                  5.9.2              pyhd8ed1ab_0    fastchan\nnccl                      2.21.5.1             h6103f9b_0    conda-forge\nncurses                   6.5                  h59595ed_0    conda-forge\nnest-asyncio              1.5.6              pyhd8ed1ab_0    fastchan\nnettle                    3.9.1                h7ab15ed_0    conda-forge\nnetworkx                  3.1                pyhd8ed1ab_0    fastchan\nnltk                      3.8.1              pyhd8ed1ab_0    conda-forge\nnotebook                  6.4.12             pyha770c72_0    fastchan\nnotebook-shim             0.2.4              pyhd8ed1ab_0    conda-forge\nnspr                      4.35                 h27087fc_0    fastchan\nnss                       3.100                hca3bf56_0    conda-forge\nnumpy                     1.26.0          py310ha4c1d20_0    fastchan\nocl-icd                   2.3.2                hd590300_1    conda-forge\nopencv                    4.9.0           qt6_py310h681cb09_615    conda-forge\nopenexr                   3.2.2                haf962dd_1    conda-forge\nopenh264                  2.4.1                h59595ed_0    conda-forge\nopenjpeg                  2.5.2                h488ebb8_0    conda-forge\nopenssl                   3.3.1                h4ab18f5_0    conda-forge\nopt_einsum                3.3.0              pyhc1e730c_2    conda-forge\norc                       2.0.1                h17fec99_1    conda-forge\noverrides                 7.7.0              pyhd8ed1ab_0    conda-forge\np11-kit                   0.24.1               hc5aa10d_0    fastchan\npackaging                 23.1               pyhd8ed1ab_0    fastchan\npandas                    2.1.1           py310hcc13569_0    fastchan\npandoc                    2.18                 ha770c72_0    fastchan\npandocfilters             1.5.0              pyhd8ed1ab_0    fastchan\nparso                     0.8.3              pyhd8ed1ab_0    fastchan\npartd                     1.3.0              pyhd8ed1ab_0    fastchan\npastedeploy               3.1.0              pyhd8ed1ab_0    conda-forge\npathtools                 0.1.2                      py_1    conda-forge\npathy                     0.10.2             pyhd8ed1ab_0    fastchan\npatsy                     0.5.6              pyhd8ed1ab_0    conda-forge\npcre2                     10.43                hcad00b1_0    conda-forge\npexpect                   4.8.0              pyh9f0ad1d_2    fastchan\npickleshare               0.7.5                   py_1003    fastchan\npillow                    10.3.0          py310hf73ecf8_0    conda-forge\npip                       24.0               pyhd8ed1ab_0    conda-forge\npixman                    0.42.2               h59595ed_0    fastchan\npkgutil-resolve-name      1.3.10             pyhd8ed1ab_0    fastchan\nplaster                   1.0                        py_0    conda-forge\nplaster_pastedeploy       0.7                        py_0    conda-forge\nplatformdirs              4.2.2              pyhd8ed1ab_0    conda-forge\nplotly                    5.22.0                     py_0    plotly\npluggy                    1.5.0              pyhd8ed1ab_0    conda-forge\nply                       3.11                       py_1    fastchan\npooch                     1.7.0              pyhd8ed1ab_0    fastchan\npoppler                   24.04.0              hb6cd0d7_0    conda-forge\npoppler-data              0.4.12               hd8ed1ab_0    conda-forge\npostgresql                16.3                 h8e811e2_0    conda-forge\npreshed                   3.0.9           py310hc6cd4ac_1    fastchan\nproj                      9.4.0                h1d62c97_1    conda-forge\nprometheus_client         0.14.1             pyhd8ed1ab_0    fastchan\nprompt-toolkit            3.0.39             pyha770c72_0    fastchan\nprompt_toolkit            3.0.39               hd8ed1ab_0    fastchan\nprotobuf                  4.25.3          py310ha8c1f0e_0    conda-forge\npsutil                    5.9.5           py310h1fa729e_0    fastchan\npthread-stubs             0.4               h36c2ea0_1001    fastchan\nptyprocess                0.7.0              pyhd3deb0d_0    fastchan\npugixml                   1.14                 h59595ed_0    conda-forge\npulseaudio-client         17.0                 hb77b528_0    conda-forge\npure_eval                 0.2.2              pyhd8ed1ab_0    fastchan\npy-opencv                 4.9.0           qt6_py310hfbaaabc_615    conda-forge\npy-xgboost                2.0.3           cuda120_pyh3ef1b53_4    conda-forge\npy-xgboost-gpu            2.0.3              pyh68bd8d9_4    conda-forge\npyarrow                   16.1.0          py310h17c5347_1    conda-forge\npyarrow-core              16.1.0          py310h6f79a3a_1_cpu    conda-forge\npyarrow-hotfix            0.6                pyhd8ed1ab_0    conda-forge\npycodestyle               2.11.1             pyhd8ed1ab_0    conda-forge\npycparser                 2.21               pyhd8ed1ab_0    fastchan\npydantic                  2.3.0              pyhd8ed1ab_0    fastchan\npydantic-core             2.6.3           py310hcb5633a_0    fastchan\npygments                  2.16.1             pyhd8ed1ab_0    fastchan\npyparsing                 3.1.1              pyhd8ed1ab_0    fastchan\npyproj                    3.6.1           py310h7677b6e_6    conda-forge\npyqt                      5.15.9          py310h04931ad_4    fastchan\npyqt5-sip                 12.12.2         py310hc6cd4ac_4    fastchan\npyramid                   2.0.2              pyhd8ed1ab_0    conda-forge\npysocks                   1.7.1           py310hff52083_5    fastchan\npytest                    8.2.2              pyhd8ed1ab_0    conda-forge\npython                    3.10.14         hd12c33a_0_cpython    conda-forge\npython-dateutil           2.8.2              pyhd8ed1ab_0    fastchan\npython-fastjsonschema     2.18.0             pyhd8ed1ab_0    fastchan\npython-flatbuffers        24.3.25            pyh59ac667_0    conda-forge\npython-json-logger        2.0.7              pyhd8ed1ab_0    conda-forge\npython-tzdata             2023.3             pyhd8ed1ab_0    fastchan\npython-xxhash             3.3.0           py310h2372a71_0    fastchan\npython_abi                3.10                    2_cp310    fastchan\npytorch                   2.3.1           py3.10_cuda12.1_cudnn8.9.2_0    pytorch\npytorch-cuda              12.1                 ha16c6d3_5    pytorch\npytorch-lightning         2.2.2              pyhd8ed1ab_0    conda-forge\npytorch-mutex             1.0                        cuda    fastchan\npytz                      2023.3.post1       pyhd8ed1ab_0    fastchan\npywavelets                1.4.1           py310h0a54255_0    fastchan\npyyaml                    6.0.1           py310h2372a71_0    fastchan\npyzmq                     24.0.1          py310h330234f_0    fastchan\nqt-main                   5.15.8              hc9dc06e_21    conda-forge\nqt6-main                  6.7.1                h2471661_2    conda-forge\nqtconsole                 5.3.1              pyhd8ed1ab_0    fastchan\nqtconsole-base            5.3.1              pyha770c72_0    fastchan\nqtpy                      2.1.0              pyhd8ed1ab_0    fastchan\nrapids                    0.0.1              pyh9f0ad1d_0    conda-forge\nrav1e                     0.6.6                he8a937b_2    conda-forge\nre2                       2023.09.01           h7f4b329_2    conda-forge\nreadline                  8.2                  h8228510_1    conda-forge\nreferencing               0.30.2             pyhd8ed1ab_0    fastchan\nregex                     2023.8.8        py310h2372a71_0    fastchan\nrequests                  2.31.0             pyhd8ed1ab_0    fastchan\nrfc3339-validator         0.1.4              pyhd8ed1ab_0    conda-forge\nrfc3986-validator         0.1.1              pyh9f0ad1d_0    conda-forge\nrich                      13.5.3             pyhd8ed1ab_0    fastchan\nrpds-py                   0.10.3          py310hcb5633a_0    fastchan\nrtree                     1.2.0           py310hbdcdc62_0    conda-forge\ns2n                       1.4.15               he19d79f_0    conda-forge\nsacremoses                master                     py_0    huggingface\nsafetensors               0.3.3           py310hcb5633a_0    fastchan\nscikit-image              0.19.3          py310h769672d_0    fastchan\nscikit-learn              1.3.1           py310h1fdf081_0    fastchan\nscipy                     1.11.2          py310ha4c1d20_0    fastchan\nseaborn                   0.13.2               hd8ed1ab_2    conda-forge\nseaborn-base              0.13.2             pyhd8ed1ab_2    conda-forge\nsend2trash                1.8.3              pyh0d859eb_0    conda-forge\nsentry-sdk                2.4.0              pyhd8ed1ab_0    conda-forge\nsetproctitle              1.3.3           py310h2372a71_0    conda-forge\nsetuptools                65.6.3             pyhd8ed1ab_0    fastchan\nshapely                   2.0.4           py310hec8f0c1_1    conda-forge\nshellingham               1.5.3              pyhd8ed1ab_0    fastchan\nsip                       6.7.11          py310hc6cd4ac_0    fastchan\nsix                       1.16.0             pyh6c4a22f_0    fastchan\nsmart_open                5.2.1              pyhd8ed1ab_0    fastchan\nsmmap                     5.0.0              pyhd8ed1ab_0    conda-forge\nsnappy                    1.2.0                hdb0a2a9_1    conda-forge\nsniffio                   1.3.0              pyhd8ed1ab_0    fastchan\nsortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge\nsoupsieve                 2.5                pyhd8ed1ab_0    fastchan\nspacy                     3.6.1           py310hfb6f7a9_0    fastchan\nspacy-legacy              3.0.12             pyhd8ed1ab_0    fastchan\nspacy-loggers             1.0.5              pyhd8ed1ab_0    fastchan\nspdlog                    1.13.0               hd2e6256_0    conda-forge\nsqlite                    3.45.3               h2c6b66d_0    conda-forge\nsrsly                     2.4.8           py310hc6cd4ac_1    fastchan\nstack_data                0.6.2              pyhd8ed1ab_0    fastchan\nstatsmodels               0.14.2          py310h261611a_0    conda-forge\nsubmitit                  1.5.1                    pypi_0    pypi\nsvt-av1                   2.1.0                hac33072_0    conda-forge\nsympy                     1.12            pypyh9d50eac_103    fastchan\ntbb                       2021.12.0            h297d8ca_1    conda-forge\ntblib                     3.0.0              pyhd8ed1ab_0    conda-forge\ntenacity                  8.3.0              pyhd8ed1ab_0    conda-forge\ntensorboard               2.16.2             pyhd8ed1ab_0    conda-forge\ntensorboard-data-server   0.7.0           py310h75e40e8_1    conda-forge\ntensorboard-plugin-profile 2.15.1                   pypi_0    pypi\ntensorflow                2.16.1          cpu_py310h49b650b_0    conda-forge\ntensorflow-base           2.16.1          cpu_py310h224022f_0    conda-forge\ntensorflow-estimator      2.16.1          cpu_py310hc6dcfef_0    conda-forge\ntermcolor                 2.4.0              pyhd8ed1ab_0    conda-forge\nterminado                 0.15.0          py310hff52083_0    fastchan\nthinc                     8.1.12          py310hfb6f7a9_0    fastchan\nthreadpoolctl             3.2.0              pyha21a80b_0    fastchan\ntifffile                  2023.1.23.1        pyhd8ed1ab_0    fastchan\ntiledb                    2.23.0               hfa691db_2    conda-forge\ntinycss2                  1.1.1              pyhd8ed1ab_0    fastchan\ntk                        8.6.13          noxft_h4845f30_101    conda-forge\ntokenizers                0.13.3          py310he1f1126_0    fastchan\ntoml                      0.10.2             pyhd8ed1ab_0    fastchan\ntomli                     2.0.1              pyhd8ed1ab_0    fastchan\ntoolz                     0.12.0             pyhd8ed1ab_0    fastchan\ntorchaudio                2.3.1               py310_cu121    pytorch\ntorchmetrics              1.4.0.post0        pyhd8ed1ab_0    conda-forge\ntorchtriton               2.3.1                     py310    pytorch\ntorchvision               0.18.1              py310_cu121    pytorch\ntornado                   6.3.3           py310h2372a71_0    fastchan\ntqdm                      4.66.1             pyhd8ed1ab_0    fastchan\ntraitlets                 5.10.1             pyhd8ed1ab_0    fastchan\ntransformers              4.33.2             pyhd8ed1ab_0    fastchan\ntranslationstring         1.4                pyh9f0ad1d_0    conda-forge\ntyper                     0.9.0              pyhd8ed1ab_0    fastchan\ntypes-python-dateutil     2.9.0.20240316     pyhd8ed1ab_0    conda-forge\ntyping-extensions         4.8.0                hd8ed1ab_0    fastchan\ntyping_extensions         4.8.0              pyha770c72_0    fastchan\ntyping_utils              0.1.0              pyhd8ed1ab_0    conda-forge\ntzcode                    2024a                h3f72095_0    conda-forge\ntzdata                    2024a                h0c530f3_0    conda-forge\nunicodedata2              15.0.0          py310h5764c6d_0    fastchan\nuri-template              1.3.0              pyhd8ed1ab_0    conda-forge\nuriparser                 0.9.8                hac33072_0    conda-forge\nurllib3                   2.0.5              pyhd8ed1ab_0    fastchan\nvenusian                  3.1.0              pyhd8ed1ab_0    conda-forge\nwandb                     0.16.5             pyhd8ed1ab_0    conda-forge\nwasabi                    1.1.2           py310hff52083_0    fastchan\nwayland                   1.23.0               h5291e77_0    conda-forge\nwcwidth                   0.2.6              pyhd8ed1ab_0    fastchan\nwebcolors                 1.13               pyhd8ed1ab_0    conda-forge\nwebencodings              0.5.1                      py_1    fastchan\nwebob                     1.8.7              pyhd8ed1ab_0    conda-forge\nwebsocket-client          1.8.0              pyhd8ed1ab_0    conda-forge\nwerkzeug                  3.0.3              pyhd8ed1ab_0    conda-forge\nwheel                     0.43.0             pyhd8ed1ab_1    conda-forge\nwidgetsnbextension        4.0.4              pyhd8ed1ab_0    fastchan\nwrapt                     1.16.0          py310h2372a71_0    conda-forge\nx264                      1!164.3095           h166bdaf_2    fastchan\nx265                      3.5                  h924138e_3    fastchan\nxcb-util                  0.4.0                h516909a_0    fastchan\nxcb-util-cursor           0.1.4                hd590300_1    conda-forge\nxcb-util-image            0.4.0                h8ee46fc_1    conda-forge\nxcb-util-keysyms          0.4.0                h516909a_0    fastchan\nxcb-util-renderutil       0.3.9                hd590300_1    conda-forge\nxcb-util-wm               0.4.1                h516909a_0    fastchan\nxerces-c                  3.2.5                hac6953d_0    conda-forge\nxkeyboard-config          2.39                 hd590300_0    fastchan\nxorg-fixesproto           5.0               h7f98852_1002    fastchan\nxorg-inputproto           2.3.2             h7f98852_1002    fastchan\nxorg-kbproto              1.0.7             h7f98852_1002    fastchan\nxorg-libice               1.1.1                hd590300_0    fastchan\nxorg-libsm                1.2.4                h7391055_0    fastchan\nxorg-libx11               1.8.9                h8ee46fc_0    conda-forge\nxorg-libxau               1.0.11               hd590300_0    fastchan\nxorg-libxdmcp             1.1.3                h7f98852_0    fastchan\nxorg-libxext              1.3.4                h7f98852_1    fastchan\nxorg-libxfixes            5.0.3             h7f98852_1004    fastchan\nxorg-libxi                1.7.10               h7f98852_0    fastchan\nxorg-libxrender           0.9.11               hd590300_0    fastchan\nxorg-renderproto          0.11.1            h7f98852_1002    fastchan\nxorg-xextproto            7.3.0             h7f98852_1002    fastchan\nxorg-xf86vidmodeproto     2.3.1             h7f98852_1002    conda-forge\nxorg-xproto               7.0.31            h7f98852_1007    fastchan\nxxhash                    0.8.2                hd590300_0    fastchan\nxyzservices               2024.4.0           pyhd8ed1ab_0    conda-forge\nxz                        5.2.6                h166bdaf_0    conda-forge\nyaml                      0.2.5                h7f98852_2    fastchan\nyarl                      1.9.2           py310h2372a71_0    fastchan\nzeromq                    4.3.4                h9c3ff4c_1    fastchan\nzfp                       1.0.1                h59595ed_0    conda-forge\nzict                      3.0.0              pyhd8ed1ab_0    conda-forge\nzipp                      3.17.0             pyhd8ed1ab_0    fastchan\nzlib                      1.3.1                h4ab18f5_1    conda-forge\nzlib-ng                   2.0.7                h0b41bf4_0    conda-forge\nzope.deprecation          4.4.0                      py_0    conda-forge\nzope.interface            6.4.post2       py310hc51659f_0    conda-forge\nzstd                      1.5.6                ha6fb4c9_0    conda-forge"
  },
  {
    "objectID": "usage/environments.html",
    "href": "usage/environments.html",
    "title": "Environment List",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nVersion\n\n\nDate\n\n\n\n\n\n\nData Science Kitchen Sink\n\n\ndsks_2024.06\n\n\nJun 2024\n\n\n\n\nCustom Template\n\n\ncustom\n\n\nDec 2023\n\n\n\n\nDetectron and Segment Anything\n\n\ndetectron-sam\n\n\nNov 2023\n\n\n\n\nData Science Kitchen Sink\n\n\ndsks_2023.10\n\n\nOct 2023\n\n\n\n\nData Science Kitchen Sink\n\n\ndsks_2023.05\n\n\nMay 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "usage/documentation.html",
    "href": "usage/documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "All of our documentation is generated using Quarto and publicly available on GitHub. If you feel like our documentation is lacking, we encourage you to submit Issues and Pull Requests to help us make it better for all of you. Even if you’re not contributing, cloning the repository is a great way to get easy access to our notebook tutorials to explore the functionality of the cluster.\nAn instance of this repository is available at /apps/MLeRP-Documentation for your reference.\nWe have an installation of Quarto on the MLeRP Monash to generate our documentation in our environment, which is available at /apps/quarto.\nThe full path to the Quarto CLI executable is:\n/apps/quarto/opt/quarto/bin/quarto"
  },
  {
    "objectID": "usage/documentation.html#vs-code-extension",
    "href": "usage/documentation.html#vs-code-extension",
    "title": "Documentation",
    "section": "VS Code Extension",
    "text": "VS Code Extension\nTo use the Quarto VS Code extension you will need to set the path of the executable in your settings:"
  },
  {
    "objectID": "hardware.html",
    "href": "hardware.html",
    "title": "Partitions and Qualities of Service",
    "section": "",
    "text": "MLeRP workloads are able to make use of the attached NVME on the compute nodes by writing to /tmp. These files will remain accessible for the course of your job.\nMLeRP is designed to be flexible. It is split into two partitions: HouseCats and BigCats.\n\nThe HouseCats is optimised for user friendliness, featuring GPU reservations. However, reservations are in limited supply, and restricted to the smallest sizes of GPUs. Once users become more comforatble with the platform and are ready to scale up their work, we encourage users to move to the BigCats partition which features larger GPU sizes and more flexible and powerful ways to interact with the cluster.\n\nHouseCats Partition\nTabby QoS\nThe is where we expect most users to start their journey with us. The Tabby service is optimised for user friendliness by giving a GPU reservation which gives an experience similar to running a notebook on your own desktop or on Google Collab.\nWe reccommend the Tabby QoS terminals for managing environments as both conda and mamba are memory intensive processes, furthermore, some packages such as py-xgboost-gpu require a GPU to be present during install.\n\nJob type: GPU Reservations\nWalltime: 24 hours\nJob limit: 1\nStrudel flavour:\n\n6 VCPUs\n56 GB RAM\n10 GB VRAM GPU\n\n\nIdeal for:\n\nNotebook based development\nData exploration\nData visualization\nNew users who just want to get started with minimal setup\nRunning terminal applications which need GPU access\nInstalling packages which require a GPU to be detectable\n\n\n\nBigCats Partition\n\nPanther QoS\nThe Panther QoS is restricted to CPU only work but features the longest walltime of any QoS on the MLeRP platform. This makes it a perfect choice as the host for a jupyter notebook that sends larger workloads out to Dask workers. It is also well suited towards any low compute work such as file system management.\n\nJob type: CPU only notebooks or terminals\nWalltime: 7 days\nJob limit: 4\nStrudel flavour:\n\n4 VCPUs\n8 GB RAM\n\n\nIdeal for:\n\nNotebooks supported by Dask workers\nData processing\nRapid and flexible iteration during development\nExperimenting with techniques\nFile management\n\nSee our tutorials for more details and this FAQ for advice on requesting resources through the Dask scheduler.\n\n\nCheetah QoS\nThe Cheetah QoS is optimised for work that can be split into many smaller jobs. Dask workers will default to using this queue allowing them to spin up quickly as its much easier to clear the resources for smaller short jobs than larger ones. The small walltime allows Cheetah jobs to be taken on by the cluster whenever there is room, allowing your workload to scale up and down and adapt to the ‘weather’ of the cluster.\nThis service is also suitable for any pre or post processing jobs which can be done on individual samples by batching your work to be handled in chunks rather than clearing the resources needed to process everything at once.\nSince Cheetah QoS jobs are intended to be short lived, ensure that you are checkpointing your work periodically so that in the event that your worker needs to be restarted you can resume your work with minimal interuption.\n\nJob type: Short running dask workers or batch jobs\nWalltime: 30 minutes\nJob limit: 20\nStrudel flavour:\n\nN/A\n\n\nIdeal for:\n\nDask workers\nData processing\n\n\n\nLion QoS\nThe Lion QoS is for our power users. If you need to perform CPU intensive data processing, or if you need access to GPUs larger than what’s available through the Tabby QoS, this service is for you.\nThis service is ideal for batch processing such as model training or hyperparamter sweeps. Alternatively, if you’re working with large models, such as transformers, consider consider using this QoS to back your Dask workers instead to allow for longer lived jobs.\nIf you would like to run a process that runs for more than the maximum walltime, checkpoint your work and submit multiple successive jobs.\n\nJob type: Batch submission or CPU intensive work\nWalltime: 24 hours\nJob limit: 4\nStrudel flavour:\n\n8 VCPUs\n64 GB RAM\n\n\nIdeal for:\n\nDask workers for larger models (eg transformers)\nModel training\nHeavy duty processing\nHyperparameter sweeps\n\n\n\n\nEstimating your job requirements\nBy default, when submitting a job outside of Strudel, such as with a Dask SLURMCluster or through SBATCH submission, our cluster will provide you with 12 CPUs / GPU and 8 GB RAM / CPU. If unspecified, jobs will be submitted to the Cheetah QoS with a walltime of 30 minutes.\nEvery research problem has its own demands and constraints, so you’ll need to adapt your cluster to suit your use case. If your work is primarily CPU bound, Dask allows as many tasks as you have CPU cores, but if you are using GPUs you may want to dramatically limit this. One process per GPU could be a good place to start.\n\nConfiguring your Dask SLURMCluster\nDask SLURMClusters give you the ability to send individual cells of your notebook to be evaluated by the SLURM queue, which gives you access to the full power of the cluster from the convenience of your notebook.\nYou can start a Dask SLURMCluster from your notebook with this code snippet:\nfrom dask_jobqueue import SLURMCluster\nfrom distributed import Client\n\n# Point Dask to the SLURM to use as it's back end\ncluster = SLURMCluster(\n    &lt;cluster configurations&gt;\n)\n\ncluster.adapt(&lt;number of workers&gt;)\nclient = Client(cluster)\nThe cluster.adapt method allows your SLURMCluster to grow and shrink to your notebook’s demands. This is perfect while you’re still developing your code since the resources can be released back into the pool while you’re editing your code and requested again once you’re ready to run.\nThe cluster.scale method can be used instead to keep your SLURMCluster at a fixed size instead. If you have finished developing your code and want to run your model’s training consider switching to this instead as it will lead to a more stable experience.\ncluster.scale(&lt;number of workers&gt;)\nclient = Client(cluster)\nHere are some example cluster configurations for you to consider:\n# Small GPU\nSLURMCluster(memory=\"48g\", processes=1, cores=6, job_extra_directives=[\"--gres=gpu:2g.10gb:1\"])\n\n# Multi GPU\nSLURMCluster(memory=\"96g\", processes=1, cores=12, job_extra_directives=[\"--gres=gpu:2g.10gb:2\"])\n\n# Medium GPU\nSLURMCluster(memory=\"96g\", processes=1, cores=12, job_extra_directives=[\"--gres=gpu:3g.20gb:1\"])\n\n# Half Node:\n# * Lion QoS as the backend as we'll need longer lived jobs to work with this scale of compute\nSLURMCluster(memory=\"192\", processes=1, cores=24, job_extra_directives=[\"--gres=gpu:40gb:1\", \"--qos=lion\"])  \n\n# Large CPU\nSLURMCluster(memory=\"64g\", processes=16, cores=16)\n\n# CPU multiprocessing\nSLURMCluster(memory=\"4g\", processes=1, cores=1)  \nPlease have a read of our tutorials for more info on Dask SLURMClusters in the MLeRP environment.\n\n\n\nBatch submission\nIf you have finished developing the code for your model and you are ready to train, batch submission may be more appropriate than notebook development as the execution of your training will not be dependent on your browser’s connection.\nThis will involve submitting an sbatch script such as the one below:\n#!/bin/bash\n#SBATCH --job-name=&lt;job name&gt;\n#SBATCH --account=&lt;your MLeRP username&gt;\n#SBATCH --time=&lt;walltime (max 24:00:00)&gt;\n#SBATCH --ntasks=&lt;number of processes&gt;\n#SBATCH --cpus-per-task=1\n#SBATCH --gres=gpu:&lt;size of gpu&gt;:&lt;number of gpus&gt;\n#SBATCH --partition=BigCats\n#SBATCH --qos=lion\n\n. /path/to/conda/environment/bin/activate\npython script.py\nNow, you can submit this job to the cluster:\nsbatch &lt;options&gt; /path/to/sbatch/script\nIf you submit a job by mistake, or would like to terminate it early, you can cancel a job:\nscancel jobid"
  },
  {
    "objectID": "release.html",
    "href": "release.html",
    "title": "Release Notes",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nSep 30, 2024\n\n\nRelease Notes #8\n\n\nMitchell Hargreaves\n\n\n\n\nJul 2, 2024\n\n\nRelease Notes #7\n\n\nMitchell Hargreaves\n\n\n\n\nFeb 21, 2024\n\n\nRelease Notes #6\n\n\nMitchell Hargreaves\n\n\n\n\nDec 15, 2023\n\n\nRelease Notes #5\n\n\nMitchell Hargreaves\n\n\n\n\nNov 10, 2023\n\n\nRelease Notes #4\n\n\nMitchell Hargreaves\n\n\n\n\nOct 13, 2023\n\n\nRelease Notes #3\n\n\nMitchell Hargreaves\n\n\n\n\nSep 22, 2023\n\n\nRelease Notes #2\n\n\nMitchell Hargreaves\n\n\n\n\nSep 5, 2023\n\n\nRelease Notes #1\n\n\nMitchell Hargreaves\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to MLeRP",
    "section": "",
    "text": "Artwork by Kiowa Scott-Hurley\n\n\nThe Machine Learning eResearch Platform (MLeRP) creates a middle ground that has the interactivity of a notebook with the power of a GPU Cluster environment that can share valuable resources between other users while code isn’t being executed.\nWe provide users with CPU based Jupyter notebook sessions capable of basic analysis, with the ability to interactively send jobs to a SLURM queue for GPU or parallelised CPU acceleration through Dask.\nBe sure to check out the Jupyter, SLURM and Dask documentation for more information.\nMLeRP is available through open beta to all Australian and New Zealand researchers working with machine learning. You can sign up with your institutional email address through the button below to gain access to the MLeRP platform or join our mailing list for updates.\n\n\nLog in\n\n\nSign up\n\n\n\nContact us\nWant to get in touch with the developers? You can reach us at mlerphelp@monash.edu.\nOur user community is shared with the ML4AU CoP and is hosted on Zulip. The space is open publicly for anyone to join! We’d love to see you there.\n\n\nJoin Zulip\n\n\n\n\nAcknowledgements\nMLeRP is a collaboration between Monash University, University of Queensland and QCIF. MLeRP received investment (https://doi.org/10.47486/NML01) from the Australian Research Data Commons (ARDC). The ARDC is funded by the National Collaborative Research Infrastructure Strategy (NCRIS)."
  },
  {
    "objectID": "release/notes001.html",
    "href": "release/notes001.html",
    "title": "Release Notes #1",
    "section": "",
    "text": "Hello MLeRP users,\nI hope you are all doing well.\nI have received a message from a user asking about getting help with provisioning, so I wanted to clear up that I provisioned all accounts according to your requested usernames and dataset sizes before the launch event. Meaning that you can all log in and test things right now through the login portal. I apologise if that wasn’t communicated clearly. The cluster has been very quiet recently, making now a great time to test the system without any wait time. If you’re not sure where to start, have a look at this tutorial or have a look at our documentation on connecting through the web portal.\nSpeaking of, we have just improved our documentation on alternative methods for connecting to the cluster through SSH or VS Code remote sessions. If this sounds like something that’s interesting to you, we’d love to get some feedback on this.\nSince we last spoke at the launch event we’ve been working behind the scenes on some of your requested features. We’ve updated the user permissions of the home directory to 700 rather than 755. This means that privacy is now the default rather than collaboration. You still have the flexibility to change the permissions on your files if you’d like to do so.\nWe’ve also been having a think about the best way to implement the requested multiday low resource CPU notebooks (which we’ve been tentatively calling the Panther QoS internally). This is likely going to require changing the way we structure the cluster’s partitions under the hood, so we’ve hold off on implementing things so far but it’s on our radar. We’ll be in touch with more details when we have something for you all to try out.\nKind regards,\nMitchell Hargreaves"
  },
  {
    "objectID": "release/notes002.html",
    "href": "release/notes002.html",
    "title": "Release Notes #2",
    "section": "",
    "text": "Hello MLeRP users,\nOver the last two weeks we’ve been addressing some of the initial feedback regarding onboarding to the service to try and smooth things out where we can.\nWe’ve had some users be confused about the difference between the QCIF and Monash regions. The two regions have different compute hardware and different file systems. As you all have been given file quota in the Monash region, you’ll need to select the Monash region in the ‘site selector’ on the left to launch your jobs. To help make this clearer to you all we’ve added a message in the ‘Account Info’ tab which will warn you if you’re trying to access the wrong region. You can read more about the differences between the regions here.\nWhile we were at it, we also added a new dashboard to the Monash region which will display what compute resources are available for you to request so that . In the future we’d also like to have it break down GPU slices by type like we have but we had some difficulty with the implementation due to differences in SLURM version giving us different output formats so we will revisit this at a later date.\nQCIF: \nMonash: \nWe have also had feedback that DSKS is missing a few key packages for some use cases, such as NLP. We will be addressing this with the next version of DSKS coming soon, but before we implement this we want to work out a better way of displaying different conda environments as our current implementation would require us to have a new app for every version which could get cluttered really quickly. We don’t want to get in the habit of changing the environment under people’s feet, potentially breaking code so we will be putting this change off so we will be putting off this change until we have a good UI solution - which is the next feature we’ll be working on.\nAt the first user meeting there was a suggestion to support an environment which hosted similar packages to Google Colab’s default packages. We had a go at exporting the package list and trying to build this environment, but we were unable to get this environment to solve. Rather than iteratively trying to remove the problem packages until it builds, we believe we will be able to offer similar functionality through DSKS by adding the key packages that you all want from Colab’s environment into the next version, so if there is something you want, please tell us which packages are missing that you’d like.\nIn the meantime, if our environments don’t suit your purposes, at this stage you’re unfortunately going to have to maintain your own conda or mamba environment. The definitions of all of our environments can be found in the folder: /apps/conda-envs/. At this time, this includes DSKS as well as a template which has the minimum packages that you need to be compatible with our Strudel apps which you can use as a basis for your environment. To help with this process we’ve written a tutorial for installing one on our system. If there is anything that isn’t clear in this tutorial, please let us know so that we can help you. If you’re comfortable with making your environment, we still recommend that you have a look through the tutorial since it also covers how to point Strudel at your environment so that you can run Jupyter Lab sessions with it.\nAll of our documentation is publicly available on GitHub. If you feel like our documentation is lacking, we encourage you to submit Issues and Pull Requests to help us make it better for all of you. Even if you’re not contributing, cloning the repository is a great way to get easy access to our notebook tutorials to explore the functionality of the cluster.\nUntil next time,\nKind Regards,\nMitchell"
  },
  {
    "objectID": "release/notes004.html",
    "href": "release/notes004.html",
    "title": "Release Notes #4",
    "section": "",
    "text": "Hello MLeRP users,\nMLeRP is now in open beta!\nFor all of you who participated in the closed beta, thank you for your feedback and continued support of the platform. For those of you who are just joining us, welcome! You can read ARDC’s article about our service here.\nWe will be running a webinar hosted by the Machine Learning Community of Practice for Australia (ML4AU) on the 28th of November to support the launch of the open beta program. We will be introducing the platform’s capabilities and demonstrating some example use cases. If you’ve been wondering how you can better take advantage of the platform or are interested in knowing more about MLeRP before signing up, this webinar is for you. You can register for the webinar here.\nIn preperation for the launch we’ve been making some updates to the documentation. We have added a new section of the documentation archiving these release notes. We have also made these release notes available over RSS, so if like me you prefer to get your news through a feed aggregator rather than email you can now do that. We also updated our home page to better acknowledge our collaborators and our about page to better introduce the platform and what makes it different from other HPC offerings.\nWe had some feedback that the Dask PyTorch tutorial was a too full on for users new to machine learning. We’ve now seperated out the Dask components into its own tutorial from the PyTorch adaptation tutorial to hopefully seperate out the concepts for easier onboarding. Please contact us if there are any aspects of the platform which could be better explained and we will work with you to develop new tutorials and documentation to support these usecases.\nWe also made some updates to Strudel2 updated the app descriptions in Strudel2 and added a link back to the compute page to make it clearer the difference between the compute flavours. There is also a link through to the documentation in the footer now.\nThe old DSKS specific Jupyter Lab has now been deprecated. If you haven’t migrated to the new Jupyter Lab app yet, you’ll need to do that now. Through the app’s Conda Environment dropdown, you will be able to access the DSKS environments, any other environments that we provide in the future, along with any environments you’ve created in conda or mamba installations that you maintain.\nRegards,\nMitchell Hargreaves"
  },
  {
    "objectID": "release/notes006.html",
    "href": "release/notes006.html",
    "title": "Release Notes #6",
    "section": "",
    "text": "Hello MLeRP users,\nSince we last had an update we’ve been hard at work refactoring some of the software we use to maintain cluster to prepare it for any growth to come.\nOur main focus has been on the way that our provisioning code handles quotas. We had some reports from users with group allocations that the code used to meter disk usage wasn’t behaving as expected. To resolve this, we have moved away from the ‘user’ and ‘group’ quota system that we used to have and implemented ‘project’ quotas.\nIn this new implementation, ‘user’ and ‘group’ allocations are both metered through the disk usage in their allocated directory, rather than attempting to count usage based on file ownership. We hope that this should be less confusing and address the reports we’ve been getting of some files being counted towards multiple allocations. As before, you will still be able to check the disk usage of all your allocations from your ‘Account Info’ app. If you continue to experience anomalies with your allocated quota, please let us know so we can work through things with you.\nSpeaking of the ‘Account Info’ page, we’ve added a new feature there that will allow you to download your SSH credentials. This will generate and download an SSH key as well as an SSH certificate that you can use to connect to our cluster using any tool of your choice. These credentials have a limited lifespan and will be cycled periodically, requiring you to log back in and redownload them to refresh your access. The main way we expect users to use this feature is to enable Remote Development through IDEs like VS Code. Previously, the only way to do this was through using our commandline tool, SSOSSH, or to generate your own keys using our terminal app. We hope that this will help remove friction associated with using your favourite tools with our service. If this experimental feature proves stable and useful, we’ll update our documentation to recommend this as the primary method to remotely access our services.\nWe’ve started a rework of our documentation to address some of the common stumbling blocks we’ve noticed users regularly asking us about. This will include new tutorials covering things like ‘checkpointing’, and refining our existing ones of Dask usage which some have found to be counter intuitive. If there’s a specific section of the documentation that you believe needs attention and you have ideas on how we can clarify it, please let us know.\nOur first update to the docs has been to rewrite our outdated Hardware page (formerly the Compute page) to better reflect the current architecture and usage advice. The biggest change you might notice is a description of each QoS that we offer, how they differ, and what they’re each optimised for… which includes the addition of our new QoS Panther! The Panther QoS is restricted to CPU only jobs, which lets us be much more lenient with the wall time (7 days!). This makes it the perfect choice as the host for a jupyter notebook that sends larger workloads out to Dask workers. This lets us reserve the Lion QoS for big workloads such as memory intensive data visualisation or batch processing.\nWhich leads us into our new experimental Strudel2 app - the Batch Job app! This application, which will be backed by the Lion QoS, will allow you to queue scripts that you’ve delveoped to be picked up by the SLURM scheduler without ever having to use the sbatch command. The application will allow you to select any compute requirements from a web form, such as number of CPUs, RAM, GPU number and flavour, and run a script from a path that you specify. At present we support python and bash scripts, but in the future we also hope to support automatically converting the ipython notebooks you’ve been working on in our Jupyter Lab app through nbconvert. We’d also like to support a method for our power users to paste their SBATCH scripts into a text box in the form for full control. Once we’ve solidified the app’s functionality and ironed out any bugs, we will finalise its documentation along with the other documentation work we’re doing.\nTo support this app, we thought it was important to be able to view the results of your jobs from the Strudel2 web application. We’ve now added a View log button to all job records, running or completed. This feature will be available for all Strudel2 applications, not just the Batch Job app. To keep things a little tidier, Strudel2 logs will now be placed in a dedicated folder rather than filling up your home directory: ~/.strudel2/logs/. Note that this will not apply to any logs generated by Dask jobs since they are not spawned by Strudel2 - if you’d like to control where these land you can specify with the log_directory paramater.\nAnother big change is that we’ve now deprecated the MLeRP-QCIF region, leaving only the MLeRP-Monash region which will serve all users going forward. If you are an inactive MLeRP-QCIF user, we have taken a copy of the data which is now hosted in the Monash region. If you’d like to revisit the MLeRP service now that it is more mature, we can make your old qcif data available to you as a part of the provisioning process on request.\nFinally, the last change that we want to tell you about is an administrative one. Going forwards, we’re going to be changing our help email to mlerphelp@monash.edu. This move away from our Gmail address is largely to help deal with some issues we’ve had with our user communications, such as account provision notifications, being caught by university spam filters. Any mail that is sent to our old address should be forwarded on to the new address, so we shouldn’t miss anything in the transition.\nAs always, we hope these changes will make the experience on our platform a smoother one as we continue to develop features to enable your research.\nRegards,\nMitchell Hargreaves"
  },
  {
    "objectID": "tutorials/3_submitit_offloading.html",
    "href": "tutorials/3_submitit_offloading.html",
    "title": "SubmitIt Offloading",
    "section": "",
    "text": "SubmitIt is a lower level library than Dask which you can also use to offload parts of your notebook to the SLURM queue. Rather than managing a cluster, you will instead directly be submitting python functions to the SLURM queue giving you more control. For more information, have a read of their PyPi page.\nimport submitit\n\n# Define where we'd like submitit to place our logs\nexecutor = submitit.AutoExecutor(folder='~/submitit_logs')\n\n# Define the parameters of our slurm job\n# Just like Dasks' job_extra_directives, additional_parameters allows us to specify things that submitit doesn't support directly\nexecutor.update_parameters(timeout_min=30, mem_gb=128, cpus_per_task=16, slurm_partition=\"BigCats\", slurm_additional_parameters={\"gres\": \"gpu:1\"})\nWe can submit our function to the cluster with the executor.submit method. This will return a future which can be unpacked with its result using future.result() just like when we were working with Dask. Because we are offloading to the SLURM queue print statements will not be visible, just like with Dask SLURMClusters. However, the full stack trace is still visible when an error or assertion is raised within the function.\ndef client_test(input1, input2, error=False, test=False):\n    # Force an error\n    if error:\n        assert 0 == 1\n    \n    # Stop after one batch when testing        \n    if test: \n        print(\"When running in a local cluster you can see print statements!\")\n\n    return input1, input2\nfuture = executor.submit(client_test, \"input1\", \"input2\", test=True)\nfuture.result()\n\n('input1', 'input2')\nfuture = executor.submit(client_test, \"input1\", \"input2\", error=True)\nfuture.result()\n\nFailedJobError: Job (task=0) failed during processing with trace:\n----------------------\nTraceback (most recent call last):\n  File \"/apps/mambaforge/envs/dsks_2024.06/lib/python3.10/site-packages/submitit/core/submission.py\", line 55, in process_job\n    result = delayed.result()\n  File \"/apps/mambaforge/envs/dsks_2024.06/lib/python3.10/site-packages/submitit/core/utils.py\", line 133, in result\n    self._result = self.function(*self.args, **self.kwargs)\n  File \"/tmp/ipykernel_1235436/858968069.py\", line 4, in client_test\nAssertionError\n\n----------------------\nYou can check full logs with 'job.stderr(0)' and 'job.stdout(0)'or at paths:\n  - /home/mhar0048/submitit_logs/6952_0_log.err\n  - /home/mhar0048/submitit_logs/6952_0_log.out\nNote that since we are interacting directly with the queue, we don’t need to clean up and shut down our cluster when using SubmitIt.\nIf needed we can be more specific about the specific GPU type and QoS we need if we have more complex requirements.\nexecutor.update_parameters(timeout_min=30, mem_gb=128, cpus_per_task=16, slurm_partition=\"BigCats\", slurm_additional_parameters={\"gres\": \"gpu:3g.20gb:1\", \"partition\": \"BigCats\"})\nexecutor.submit(client_test, \"input1\", \"input2\", test=True).result()\n\n/apps/mambaforge/envs/dsks_2024.06/lib/python3.10/site-packages/submitit/auto/auto.py:23: UserWarning: Setting 'additional_parameters' is deprecated. Use 'slurm_additional_parameters' instead.\n  warnings.warn(f\"Setting '{arg}' is deprecated. Use '{new_arg}' instead.\")\n\n\n('input1', 'input2')"
  },
  {
    "objectID": "tutorials/3_submitit_offloading.html#comparison-with-dask",
    "href": "tutorials/3_submitit_offloading.html#comparison-with-dask",
    "title": "SubmitIt Offloading",
    "section": "Comparison with Dask",
    "text": "Comparison with Dask\nAs you can see, we’ve implemented the same use case with both Dask and SubmitIt. Which begs the question - which should you use for your research?\nBoth packages have pros and cons, but on the whole, Dask is much better suited towards tasks which can benefit from being broken into many small tasks - like when preprocessing your data. SubmitIt on the other hand is much better suited for use cases where you are looking to offload one larger job at a time, like when you are training.\nOf the two, Dask is the more mature package with more flexibility and complete documentation - but if you are looking for a simple offloading package it is often far more complexity than you need."
  },
  {
    "objectID": "tutorials/5_ollama.html",
    "href": "tutorials/5_ollama.html",
    "title": "Ollama Python",
    "section": "",
    "text": "Ollama offers a way to interact with open source large language models interactively. The easiest way to do that is with the Ollama Chatbot app in Strudel2, but if you need more power, you can use the Ollama python library.\nIn this example we are going to use Ollama to summarise Wikipedia articles from the Wikitext 2 dataset."
  },
  {
    "objectID": "tutorials/5_ollama.html#preparing-the-dataset",
    "href": "tutorials/5_ollama.html#preparing-the-dataset",
    "title": "Ollama Python",
    "section": "Preparing the dataset",
    "text": "Preparing the dataset\nThe Wikitext 2 dataset is easily available through the Hugging Face library ‘datasets’, but rather than splitting the dataset by article like we need the data is split by paragraph. This means we’ll need to reprocess the dataset back into articles for our example.\n\nfrom datasets import load_dataset\nds = load_dataset(\"Salesforce/wikitext\", \"wikitext-2-raw-v1\")\nds[\"test\"][\"text\"][:10]\n\n['',\n ' = Robert Boulter = \\n',\n '',\n ' Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . He had a guest role in the television series Judge John Deed in 2002 . In 2004 Boulter landed a role as \" Craig \" in the episode \" Teddy \\'s Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi . He was cast in the 2005 theatre productions of the Philip Ridley play Mercury Fur , which was performed at the Drum Theatre in Plymouth and the Menier Chocolate Factory in London . He was directed by John Tiffany and starred alongside Ben Whishaw , Shane Zaza , Harry Kent , Fraser Ayres , Sophie Stanton and Dominic Hall . \\n',\n ' In 2006 , Boulter starred alongside Whishaw in the play Citizenship written by Mark Ravenhill . He appeared on a 2006 episode of the television series , Doctors , followed by a role in the 2007 theatre production of How to Curse directed by Josie Rourke . How to Curse was performed at Bush Theatre in the London Borough of Hammersmith and Fulham . Boulter starred in two films in 2008 , Daylight Robbery by filmmaker Paris Leonti , and Donkey Punch directed by Olly Blackburn . In May 2008 , Boulter made a guest appearance on a two @-@ part episode arc of the television series Waking the Dead , followed by an appearance on the television series Survivors in November 2008 . He had a recurring role in ten episodes of the television series Casualty in 2010 , as \" Kieron Fletcher \" . Boulter starred in the 2011 film Mercenaries directed by Paris Leonti . \\n',\n '',\n ' = = Career = = \\n',\n '',\n '',\n ' = = = 2000 – 2005 = = = \\n']\n\n\nWe can identify the split between articles by looking out for the article headings. In this dataset:\n- Headers have the format: \" = &lt;HEADING&gt; = \\n\"\n- Subheadings have the format: \" = = &lt;SUBHEADING&gt; = = \\n\"\n- Subsubheadings have the format: \" = = = &lt;SUBSUBHEADING&gt; = = = \\n\"\n\narticles = []\n\n# Drop the 0th line as its empty\nfor line in ds[\"test\"][\"text\"][1:]:\n    # Identify headings, but exclude subheadings and subsubheadings\n    if line[:3] == \" = \" and line[3] != \"=\":\n        articles.append(line)\n    else:\n        articles[-1] += line\n\n\n# Check the first 100 characters of the first 5 articles to make sure we split the dataset correctly\nfor article in articles[:5]:\n    print(article[:100])\n\n = Robert Boulter = \n Robert Boulter is an English film , television and theatre actor . He had a gu\n = Du Fu = \n Du Fu ( Wade – Giles : Tu Fu ; Chinese : 杜甫 ; 712 – 770 ) was a prominent Chinese poet \n = Kiss You ( One Direction song ) = \n \" Kiss You \" is a song recorded by English @-@ Irish boy band\n = Ise @-@ class battleship = \n The Ise @-@ class battleships ( 伊勢型戦艦 , Ise @-@ gata senkan ) were a\n = Dick Rifenburg = \n Richard Gale \" Dick \" Rifenburg ( August 21 , 1926 – December 5 , 1994 ) was a"
  },
  {
    "objectID": "tutorials/5_ollama.html#passing-the-articles-through-to-ollama",
    "href": "tutorials/5_ollama.html#passing-the-articles-through-to-ollama",
    "title": "Ollama Python",
    "section": "Passing the articles through to Ollama",
    "text": "Passing the articles through to Ollama\nTo use the ollama library we need to start an ollama server in the background inside of our SLURM job. We can do this by running the commands below in a Jupyter Lab terminal. This is not the same as launching a terminal app as that will launch a new SLURM job instead. Instead, select ‘Terminal’ from the Launcher after clicking on the ‘+’ button in the top left corner of your Jupyter Lab application.\nWe also need to point Ollama towards our shared model repository in order to be able to import the models that we’ve downloaded for you. Alternatively if you’d like to experiment with models on your own, feel free to modify that path to a directory that you control. Note that LLMs are big and they will count towards your disk quota.\nexport OLLAMA_MODELS=\"/apps/ollama/models/\"\n/apps/ollama/ollama serve\n\nimport ollama\nresponse = ollama.chat(model='llama3', messages=[\n  {\n    'role': 'user',\n    'content': 'Why is the sky blue?',\n  },\n])\nprint(response)\n\n{'model': 'llama3', 'created_at': '2024-08-14T05:34:36.062060907Z', 'message': {'role': 'assistant', 'content': \"What a great question!\\n\\nThe sky appears blue because of a phenomenon called Rayleigh scattering. This is when short (blue) wavelengths of light are scattered more than longer (red) wavelengths by tiny molecules of gases in the atmosphere, such as nitrogen and oxygen.\\n\\nHere's what happens:\\n\\n1. When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases like nitrogen (N2) and oxygen (O2).\\n2. These molecules scatter the light in all directions.\\n3. The shorter blue wavelengths are scattered more than longer red wavelengths because they have a higher energy and interact more strongly with the gas molecules.\\n4. As a result, our eyes perceive the scattered blue light as a blue color, making the sky appear blue.\\n\\nThis scattering effect is most pronounced when the sun is overhead (at an angle of about 90 degrees), which is why the sky often appears more vibrant blue during midday. As the sun sets or rises lower in the sky, the light has to travel longer distances through the atmosphere, which means more of the shorter wavelengths are scattered away, making the sky appear more orange or red due to the dominance of the longer wavelengths.\\n\\nSo, to summarize: the sky appears blue because of the scattering of short blue wavelengths by tiny gas molecules in the atmosphere!\\n\\n(P.S. There are other factors that can affect the apparent color of the sky, such as dust particles, water vapor, and pollution. But Rayleigh scattering is the primary reason for the sky's blue hue.)\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 6096306797, 'load_duration': 2782395, 'prompt_eval_count': 11, 'prompt_eval_duration': 234876000, 'eval_count': 301, 'eval_duration': 5719801000}\n\n\nWe can then formulate our request to the LLM using the articles from our dataset and ask for it’s summary\n\nresponse = ollama.chat(model='llama3', messages=[\n  {\n    'role': 'user',\n    'content': \"Please summarise this article:\\n\\n\\n\" + articles[0],\n  },\n])\nprint(response['message']['content'])\n\nThe article is about the career of Robert Boulter, an English actor. Here's a summary:\n\n**Early Career (2000-2005)**\n\n* Guest starred in TV series \"The Bill\" (2000)\n* Starred in play \"Herons\" at Royal Court Theatre (2001)\n* Appeared in TV series \"Judge John Deed\" (2002) and \"The Bill\" (2003)\n* Had recurring role on \"The Bill\" (2003)\n\n**Middle Career (2006-Present)**\n\n* Starred in play \"Citizenship\" at National Theatre (2006)\n* Appeared in TV series \"Doctors\" (2006)\n* Starred in play \"How to Curse\" at Bush Theatre (2007)\n* Starred in two films: \"Daylight Robbery\" and \"Donkey Punch\" (2008)\n* Guest starred on TV series \"Waking the Dead\" (2008) and \"Survivors\" (2008)\n* Had recurring role on TV series \"Casualty\" (2010)\n* Starred in film \"Mercenaries\" (2011)\n\n**Theatre Credits**\n\n* \"Mercury Fur\" at Drum Theatre and Menier Chocolate Factory (2005)\n* \"How to Curse\" at Bush Theatre (2007)\n\nOverall, Robert Boulter has had a diverse career, appearing in TV shows, films, and theatre productions. He has worked with various directors and actors, including Ben Whishaw, Derek Jacobi, and Josie Rourke.\n\n\n\n# And finally we can automate \nresponses = []\nfor article in articles:\n    response = ollama.chat(model='llama3', messages=[\n        {\n            'role': 'user',\n            'content': \"Please summarise this article:\\n\\n\\n\" + article,\n        },\n    ])\n    responses.append(response['message']['content'])\n\n\n# Print the first 5 summaries\nfor response in responses[:5]:\n    print(response)\n    print(\"======================\")\n\nThe article is a biography of English actor Robert Boulter. Here's a summary:\n\n**Early Career (2000-2005)**\n\n* Guest star role on TV series \"The Bill\" in 2000\n* Starred in play \"Herons\" by Simon Stephens at Royal Court Theatre in 2001\n* Appeared in TV series \"Judge John Deed\" in 2002 as \"Addem Armitage\"\n* Had recurring role on TV series \"The Bill\" in 2003 and 2004\n\n**Mid-Career (2006-2010)**\n\n* Starred in play \"Citizenship\" by Mark Ravenhill at National Theatre in 2006\n* Appeared in TV series \"Doctors\" in 2006 as \"Jason Tyler\"\n* Starred in play \"How to Curse\" directed by Josie Rourke at Bush Theatre in 2007\n* Starred in two films: \"Daylight Robbery\" (2008) and \"Donkey Punch\" (2008)\n* Guest-starred on TV series \"Waking the Dead\" in 2008 as \"Jimmy Dearden\"\n* Appeared on TV series \"Survivors\" in 2008 as \"Neil\"\n\n**Recent Career (2010-Present)**\n\n* Had recurring role on TV series \"Casualty\" in 2010 as \"Kieron Fletcher\", playing an emergency physician\n* Starred in film \"Mercenaries\" directed by Paris Leonti in 2011\n\nOverall, the article provides a chronological overview of Robert Boulter's acting career, highlighting his roles in various films, television shows, and theatre productions.\n======================\nThe article discusses the impact and influence of ancient Chinese poet Du Fu (712-770 CE) on Japanese literature and poets. Du Fu's work was highly regarded in Japan, particularly during the Muromachi period (1336-1573 CE). His poetry had a profound impact on Japanese haiku master Matsuo Bashō (1644-1694 CE), who often cited Du Fu's poems in his own works.\n\nIn Japan, Du Fu's poetry was widely studied and admired. During the Edo period (1603-1868 CE), a commentary on Du Fu's poetry by Shào Chuán of the Ming Dynasty gained popularity among Confucian scholars and townspeople. This commentary established Du Fu as the greatest poet in history.\n\nThe article also touches on the challenges of translating Du Fu's work into English. Various translators have approached this task with different styles, ranging from free translations to literal translations that preserve the original poetic forms. Some translators, like Kenneth Rexroth, have taken a more flexible approach, while others, like Burton Watson, have prioritized conveying the formal constraints and allusions of Du Fu's poetry.\n\nOverall, the article highlights the enduring influence of Du Fu on Japanese literature and poets, as well as the challenges and nuances involved in translating his work into English.\n======================\nThe article is about the song \"Kiss You\" by One Direction. Here's a summary:\n\n**Critical Reception**: The song was well-received by music critics, who praised its production quality and catchy melody.\n\n**Commercial Performance**: The single debuted at number 24 on the Irish Singles Chart and peaked at number 7. It also reached the top 10 in the UK Singles Chart and the US Billboard Hot 100. The song was certified gold by the RIAA and platinum by the ARIA (Australian Recording Industry Association) and RIANZ (Recording Industry Association of New Zealand).\n\n**Music Video**: The music video, directed by Vaughan Arnell, features the band shooting different scenes via a green screen, dressed as sailors, surfers, skiers, and jailers. It was characterized as \"bigger than anything we've done before\" and \"a lot of fun\" by the band members.\n\n**Live Performances**: One Direction performed the song on televised programs, including The Today Show and The X Factor UK and USA. They also included it in their set list during their Take Me Home Tour (2013), Where We Are Tour (2014), and On the Road Again Tour (2015).\n\n**Track Listing**: The CD single features \"Kiss You\" and \"Little Things\".\n\n**Credits and Personnel**: The song was written by Carl Falk, Kristoffer Fogelmark, Niall Horan, Savan Kotecha, Kristian Lundin, Albin Nedler, Shellback, and Rami Yacoub. It was produced by Carl Falk and Rami Yacoub.\n\nI hope that helps! Let me know if you have any further questions.\n======================\nThe article describes the career of two Japanese battleships, Ise and Hyūga, during World War II. Here is a summary:\n\n* In May 1943, Ise was converted into a hybrid carrier from a battleship.\n* After completing sea trials, Ise was attached to the Imperial Japanese Naval Academy at Etajima and ferried troops and munitions to Truk in October.\n* In November, Ise began working up with Hyūga, which had also been converted into a carrier. Both ships joined the 2nd Battleship Division.\n* In May 1944, the sisters were transferred to Rear Admiral Matsuda Chiaki's reformed Fourth Carrier Division of the 3rd Fleet.\n\nThe article then describes the Battle of Cape Engaño:\n\n* The Japanese plan was to use the surviving carriers, including Ise and Hyūga, to lure American carrier forces away from the invasion area.\n* On October 24, the sisters launched aircraft to attack American carriers. Although they inflicted no damage, they caused the Americans to search in the direction from which they had attacked.\n* The next day, the Americans found the Japanese carriers and launched multiple airstrikes. Ise claimed to have shot down five attacking dive bombers and was lightly damaged by near misses.\n* Hyūga was successfully attacked by an American submarine on October 25.\n\nAfter the battle, the sisters continued to serve in various roles:\n\n* In early November, their catapults were removed, and they loaded troops and munitions. They then sailed for Lingga Island and eventually became flagship of the 5th Fleet.\n* In December, Hyūga became flagship of the fleet at Cam Ranh Bay.\n* In January 1945, the sisters sailed to Singapore and then to Lingga Island.\n\nThe article concludes with a description of the final days of Ise and Hyūga:\n\n* After being struck off the Navy List in November, both ships were scrapped after the war.\n======================\nThe article is about the life of Dick Rifenburg, an American football player and sportscaster. Here's a summary:\n\n* Rifenburg played football at the University of Michigan, leading the team to consecutive undefeated national championships in 1947 and 1948.\n* He was known for his practical jokes on the field and was a consensus All-American selection as a senior.\n* Despite being one of the greatest Wolverine players of the 1940s, Rifenburg did not finish among the top eight Heisman Trophy voters in 1948 due to perceived bias against Michigan teams.\n* After graduating from Michigan, Rifenburg was drafted by the Philadelphia Eagles and played for the Detroit Lions before retiring from professional football.\n* He went on to become a sportscaster, hosting a popular panel show called \"Let's Talk Sports\" and pioneering an early morning exercise program in Buffalo, New York.\n* Rifenburg worked at WBEN radio station for many years, hosting various programs and serving as the play-by-play announcer for Buffalo Bills games.\n* He also taught communications at Medaille College and sold ads for a local newspaper.\n* After 30 years with WBEN, Rifenburg's show was replaced, but he continued to work in broadcasting until his eventual retirement.\n* Rifenburg passed away in 1994, leaving behind a legacy as a pioneering figure in sports broadcasting. He was posthumously inducted into the Buffalo Broadcasters Hall of Fame in 2007.\n======================"
  }
]