<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>MLeRP User Guide Documentation</title>
<link>https://docs.mlerp.cloud.edu.au/release.html</link>
<atom:link href="https://docs.mlerp.cloud.edu.au/release.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Wed, 21 Feb 2024 00:00:00 GMT</lastBuildDate>
<item>
  <title>Release Notes #6</title>
  <dc:creator>Mitchell Hargreaves</dc:creator>
  <link>https://docs.mlerp.cloud.edu.au/release/notes006.html</link>
  <description><![CDATA[ 



<p>Hello MLeRP users,</p>
<p>Since we last had an update we’ve been hard at work refactoring some of the software we use to maintain cluster to prepare it for any growth to come.</p>
<p>Our main focus has been on the way that our provisioning code handles quotas. We had some reports from users with group allocations that the code used to meter disk usage wasn’t behaving as expected. To resolve this, we have moved away from the ‘user’ and ‘group’ quota system that we used to have and implemented ‘project’ quotas.</p>
<p>In this new implementation, ‘user’ and ‘group’ allocations are both metered through the disk usage in their allocated directory, rather than attempting to count usage based on file ownership. We hope that this should be less confusing and address the reports we’ve been getting of some files being counted towards multiple allocations. As before, you will still be able to check the disk usage of all your allocations from your ‘Account Info’ app. If you continue to experience anomalies with your allocated quota, please let us know so we can work through things with you.</p>
<p>Speaking of the ‘Account Info’ page, we’ve added a new feature there that will allow you to download your SSH credentials. This will generate and download an SSH key as well as an SSH certificate that you can use to connect to our cluster using any tool of your choice. These credentials have a limited lifespan and will be cycled periodically, requiring you to log back in and redownload them to refresh your access. The main way we expect users to use this feature is to enable Remote Development through IDEs like <a href="../connecting/vscode.html">VS Code</a>. Previously, the only way to do this was through using our commandline tool, <a href="../connecting/ssossh.html">SSOSSH</a>, or to generate your own keys using our <a href="../applications/strudel2.html#terminal-jobs">terminal app</a>. We hope that this will help remove friction associated with using your favourite tools with our service. If this experimental feature proves stable and useful, we’ll update our documentation to recommend this as the primary method to remotely access our services.</p>
<p>We’ve started a rework of our documentation to address some of the common stumbling blocks we’ve noticed users regularly asking us about. This will include new tutorials covering things like ‘checkpointing’, and refining our existing ones of Dask usage which some have found to be counter intuitive. If there’s a specific section of the documentation that you believe needs attention and you have ideas on how we can clarify it, please let us know.</p>
<p>Our first update to the docs has been to rewrite our outdated <a href="../hardware.html">Hardware</a> page (formerly the Compute page) to better reflect the current architecture and usage advice. The biggest change you might notice is a description of each QoS that we offer, how they differ, and what they’re each optimised for… which includes the addition of our new QoS <a href="../hardware.html#panther-qos">Panther</a>! The Panther QoS is restricted to CPU only jobs, which lets us be much more lenient with the wall time (7 days!). This makes it the perfect choice as the host for a jupyter notebook that sends larger workloads out to Dask workers. This lets us reserve the Lion QoS for big workloads such as memory intensive data visualisation or batch processing.</p>
<p>Which leads us into our new experimental Strudel2 app - the Batch Job app! This application, which will be backed by the Lion QoS, will allow you to queue scripts that you’ve delveoped to be picked up by the SLURM scheduler without ever having to use the <code>sbatch</code> command. The application will allow you to select any compute requirements from a web form, such as number of CPUs, RAM, GPU number and flavour, and run a script from a path that you specify. At present we support python and bash scripts, but in the future we also hope to support automatically converting the ipython notebooks you’ve been working on in our Jupyter Lab app through <code>nbconvert</code>. We’d also like to support a method for our power users to paste their <code>SBATCH</code> scripts into a text box in the form for full control. Once we’ve solidified the app’s functionality and ironed out any bugs, we will finalise its documentation along with the other documentation work we’re doing.</p>
<p>To support this app, we thought it was important to be able to view the results of your jobs from the Strudel2 web application. We’ve now added a <code>View log</code> button to all job records, running or completed. This feature will be available for all Strudel2 applications, not just the Batch Job app. To keep things a little tidier, Strudel2 logs will now be placed in a dedicated folder rather than filling up your home directory: <code>~/.strudel2/logs/</code>. Note that this will not apply to any logs generated by Dask jobs since they are not spawned by Strudel2 - if you’d like to control where these land you can specify with the <code>log_directory</code> paramater.</p>
<p>Another big change is that we’ve now deprecated the MLeRP-QCIF region, leaving only the MLeRP-Monash region which will serve all users going forward. If you are an inactive MLeRP-QCIF user, we have taken a copy of the data which is now hosted in the Monash region. If you’d like to revisit the MLeRP service now that it is more mature, we can make your old qcif data available to you as a part of the provisioning process on request.</p>
<p>Finally, the last change that we want to tell you about is an administrative one. Going forwards, we’re going to be changing our help email to <code>mlerphelp@monash.edu</code>. This move away from our Gmail address is largely to help deal with some issues we’ve had with our user communications, such as account provision notifications, being caught by university spam filters. Any mail that is sent to our old address should be forwarded on to the new address, so we shouldn’t miss anything in the transition.</p>
<p>As always, we hope these changes will make the experience on our platform a smoother one as we continue to develop features to enable your research.</p>
<p>Regards,<br>
Mitchell Hargreaves</p>



 ]]></description>
  <guid>https://docs.mlerp.cloud.edu.au/release/notes006.html</guid>
  <pubDate>Wed, 21 Feb 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Release Notes #5</title>
  <dc:creator>Mitchell Hargreaves</dc:creator>
  <link>https://docs.mlerp.cloud.edu.au/release/notes005.html</link>
  <description><![CDATA[ 



<p>Hello MLeRP users,</p>
<p>In the weeks since launching the platform’s open beta, we have provisioned over 60 additional individual accounts for the system, bringing our total to almost 80 users which has certainly kept us busy! We have also provisioned 7 group allocations ranging in size from 2-6 members. As always, if you’d like to ammend your allocation’s quota or would like to consider a group allocation to collaborate with others, talk to us and we’ll see what we can do for you.</p>
<p>Speaking of the launch, if you missed our launch webinar, the event was recorded and <a href="https://www.youtube.com/watch?v=iPUL7lb9tWU&amp;t=1s">is available here</a>. In it we discussed the guiding principles that we used when designing MLeRP along with an overview of the services that we offer as a part of the platform.</p>
<p>To accommodate this increase in users we have expanded into a second file system, bringing our total file storage for user data up to 40 TB. As a part of this refactor, all users will have a link to their allocation from the <code>/home</code> directory, meaning that your code will not need to change depnding on where your allocation actually sits.</p>
<p>We also expanded our applications volume dramatically, now weighing in at 500 GB, to allow us to continue to bring you new installations of software. As a part of this migration we found that the original DSKS environment <code>dsks_2023.05</code> could not be rebuilt due to some of the packages being deprecated. If you need it to rerun some legacy code, this environment is still accessible as a <a href="https://conda.github.io/conda-pack/"><code>conda-pack</code></a> at <code>/apps/conda-packs/dsks_2023.05</code>. Note that we haven’t found a way to make a <code>conda-pack</code> work with our Jupyter App yet so this will only support scripts. If you need to convert your notebook into a script, consider using <a href="https://nbconvert.readthedocs.io/en/latest/index.html"><code>nbconvert</code></a> which is available in any of our DSKS environments.</p>
<p>One of the new offerings we’ve developed with one of our users is a new conda environment for our Jupyter App that features the <a href="https://github.com/facebookresearch/detectron2">Detectron2</a> and <a href="https://github.com/facebookresearch/segment-anything">Segment Anything</a> packages by Facebook Research. You can view the full environment definition and package list <a href="../applications/environments/detectron-sam.html">here</a>.</p>
<p>If you’ve been working on an environment that you think will be useful to others in your field you want to share with others on the platform, we want to hear from you. Let us know and we’ll help you make it available to everyone.</p>
<p>If you’d like to work with software that we don’t currently have installed on the platform, that does not mean that we won’t be able to support you. It just means that you’ll need to be patient and willing to help blaze the path with us so that we can extend the functionality of the platform for you. You are also free to install anything into your allocation that only requires using user space. Sometimes this just means that rather than using <code>apt</code> or <code>apt-get</code> you will need to get the software from <code>conda-forge</code>.</p>
<p>The increase in scale has also come with a new set of challanges, especially regarding the Strudel2 API. We apologise for the instability that some of you will have experienced in this time. We have since rolled out a new version of Strudel2 which should be more performant and robust, as well as adding additional safeguards to prevent the whole system coming down if some users encounter unexpected states.</p>
<p>If you experience any unexpected behaviour from the file system, the Strudel2 web page or anywhere else on the system, do not hesitate to reach out to us and we will work with you to resolve the issue.</p>
<p>Regards,<br>
Mitchell Hargreaves</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/iPUL7lb9tWU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>



 ]]></description>
  <guid>https://docs.mlerp.cloud.edu.au/release/notes005.html</guid>
  <pubDate>Fri, 15 Dec 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Release Notes #4</title>
  <dc:creator>Mitchell Hargreaves</dc:creator>
  <link>https://docs.mlerp.cloud.edu.au/release/notes004.html</link>
  <description><![CDATA[ 



<p>Hello MLeRP users,</p>
<p>MLeRP is now in open beta!</p>
<p>For all of you who participated in the closed beta, thank you for your feedback and continued support of the platform. For those of you who are just joining us, welcome! You can read ARDC’s article about our service <a href="https://ardc.edu.au/article/new-machine-learning-service-for-australian-researchers/">here</a>.</p>
<p><strong>We will be running a webinar hosted by the <a href="https://www.ml4au.community/">Machine Learning Community of Practice for Australia (ML4AU)</a> on the 28th of November to support the launch of the open beta program</strong>. We will be introducing the platform’s capabilities and demonstrating some example use cases. If you’ve been wondering how you can better take advantage of the platform or are interested in knowing more about MLeRP before signing up, this webinar is for you. You can register for the webinar <a href="https://ardc.edu.au/event/introducing-machine-learning-eresearch-platform-mlerp/">here</a>.</p>
<p>In preperation for the launch we’ve been making some updates to the documentation. We have added a new section of the documentation archiving <a href="../release.html">these release notes</a>. We have also made these release notes available <a href="https://docs.mlerp.cloud.edu.au/release.xml">over RSS</a>, so if like me you prefer to get your news through a feed aggregator rather than email you can now do that. We also updated our <a href="../index.html">home page</a> to better acknowledge our collaborators and our <a href="../about.html">about page</a> to better introduce the platform and what makes it different from other HPC offerings.</p>
<p>We had some feedback that the Dask PyTorch tutorial was a too full on for users new to machine learning. We’ve now seperated out the Dask components into its own tutorial from the PyTorch adaptation tutorial to hopefully seperate out the concepts for easier onboarding. Please contact us if there are any aspects of the platform which could be better explained and we will work with you to develop new tutorials and documentation to support these usecases.</p>
<p>We also made some updates to Strudel2 updated the app descriptions in Strudel2 and added a link back to the <a href="../hardware.html">compute</a> page to make it clearer the difference between the compute flavours. There is also a link through to the documentation in the footer now.</p>
<p>The old DSKS specific Jupyter Lab has now been deprecated. If you haven’t migrated to the new <a href="https://docs.mlerp.cloud.edu.au/applications/strudel2.html#jupyter-lab">Jupyter Lab app</a> yet, you’ll need to do that now. Through the app’s <code>Conda Environment</code> dropdown, you will be able to access the DSKS environments, any other environments that we provide in the future, along with any environments you’ve created in <code>conda</code> or <code>mamba</code> installations that you maintain.</p>
<p>Regards,<br>
Mitchell Hargreaves</p>



 ]]></description>
  <guid>https://docs.mlerp.cloud.edu.au/release/notes004.html</guid>
  <pubDate>Fri, 10 Nov 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Release Notes #3</title>
  <dc:creator>Mitchell Hargreaves</dc:creator>
  <link>https://docs.mlerp.cloud.edu.au/release/notes003.html</link>
  <description><![CDATA[ 



<p>Hello MLeRP users,</p>
<p>We’re pleased to announce that we now have a better UI solution to use conda environments with our new <a href="../applications/strudel2.html#jupyter-lab">Jupyter Lab app</a>. Now, rather than each app being tied to a given conda environment and requiring users to create a new app to support their own environments, we are using a dropdown which will allow you to select from any of the environments we provide, or any that you provide for yourself.</p>
<p>The dropdown is populated using your <code>~/.conda/environments.txt​</code> file which conda should maintain as you create new installations of miniconda or mamba. This means that the app should automatically pick up any new environments that you create with no input from yourself. If for whatever reason this doesn’t happen and you can’t find the environment that you’re looking for, you can manually append a new environment to the file with this command:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> /path/to/your/environment <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;</span> ~/.conda/environments.txt​</span></code></pre></div>
<p>We have also used this opportunity to come out with a new version of DSKS that addresses some of the shortcomings with the previous version. The environment now has more packages to support a wider range of data types and tools, for a full list visit the <a href="../applications/environments/dsks/dsks_2023.10.html">DSKS environment’s page</a>.</p>
<p>If you still need to use the <a href="../applications/environments/dsks/dsks_2023.05.html">old version of DSKS</a>, it’s still there just renamed. From now on, we will be versioning the environments that we release, tagging them with the year and month that they were built. The old version of DSKS that you are familiar with can now be accessed as dsks_2023.05, while the new version can be accessed as dsks_2023.10​. Similarly, the DSKS specific Jupyter App will point to this renamed environment. A full list of every environment that we support will be available on <a href="../applications/environments.html">this new page of our documentation</a>. There’s only 2 versions of DSKS there now, but we’re sure that the list will grow as we get more requests for packages and functionality. If you have a curated environment that you think would be suitable for other users, let us know and we’ll see what we can do.</p>
<p>We are also going to be deprecating the Base Jupyter Lab application. The Base Jupyter Lab application has always been in a weird place in that it simultaneously has too many packages to be representative of a basic python installation, but not enough for the kind of useful data science that we expect from users in the system. The app was originally written to work isolated within a singularity container, but as we move towards providing environments through our mambaforge installation continuing to maintain this unicorn environment seemed more trouble as it was worth, especially since the DSKS environments offer as a superset of it’s functionality and the base environment that is created in a <a href="https://mamba.readthedocs.io/en/latest/">mambaforge</a> install is more suitable for minimal applications.</p>
<p>Please let us know how the new Jupyter Lab app works for you. If this experiment goes well, we’ll also deprecate the old DSKS specific Jupyter Lab since you can still reach that environment by selecting it in the environment dropdown.</p>
<p>Regards,<br>
Mitchell Hargreaves</p>



 ]]></description>
  <guid>https://docs.mlerp.cloud.edu.au/release/notes003.html</guid>
  <pubDate>Fri, 13 Oct 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Release Notes #2</title>
  <dc:creator>Mitchell Hargreaves</dc:creator>
  <link>https://docs.mlerp.cloud.edu.au/release/notes002.html</link>
  <description><![CDATA[ 



<p>Hello MLeRP users,</p>
<p>Over the last two weeks we’ve been addressing some of the initial feedback regarding onboarding to the service to try and smooth things out where we can.</p>
<p>We’ve had some users be confused about the difference between the QCIF and Monash regions. The two regions have different compute hardware and different file systems. As you all have been given file quota in the Monash region, <strong>you’ll need to select the Monash region in the ‘site selector’ on the left to launch your jobs</strong>. To help make this clearer to you all we’ve added a message in the ‘Account Info’ tab which will warn you if you’re trying to access the wrong region. You can read more about the differences between the regions <a href="../hardware.html">here</a>.</p>
<p>While we were at it, we also added a new dashboard to the Monash region which will display what compute resources are available for you to request so that . In the future we’d also like to have it break down GPU slices by type like we have but we had some difficulty with the implementation due to differences in SLURM version giving us different output formats so we will revisit this at a later date.</p>
<p>QCIF: <img src="https://docs.mlerp.cloud.edu.au/release/images/qcif_dashboard.png" class="img-fluid" alt="QCIF Dashboard"></p>
<p>Monash: <img src="https://docs.mlerp.cloud.edu.au/release/images/monash_dashboard.png" class="img-fluid" alt="Monash Dashboard"></p>
<p>We have also had feedback that DSKS is missing a few key packages for some use cases, such as NLP. We will be addressing this with the next version of DSKS coming soon, but before we implement this we want to work out a better way of displaying different conda environments as our current implementation would require us to have a new app for every version which could get cluttered really quickly. We don’t want to get in the habit of changing the environment under people’s feet, potentially breaking code so we will be putting this change off so we will be putting off this change until we have a good UI solution - which is the next feature we’ll be working on.</p>
<p>At the first user meeting there was a suggestion to support an environment which hosted similar packages to Google Colab’s default packages. We had a go at exporting the package list and trying to build this environment, but we were unable to get this environment to solve. Rather than iteratively trying to remove the problem packages until it builds, we believe we will be able to offer similar functionality through <a href="../applications/environments.html"><code>DSKS</code></a> by adding the key packages that you all want from Colab’s environment into the next version, so if there is something you want, please tell us which packages are missing that you’d like.</p>
<p>In the meantime, if our environments don’t suit your purposes, at this stage you’re unfortunately going to have to maintain your own conda or mamba environment. The definitions of all of our environments can be found in the folder: <code>/apps/conda-envs/</code>. At this time, this includes <code>DSKS</code> as well as a template which has the minimum packages that you need to be compatible with our Strudel apps which you can use as a basis for your environment. To help with this process <a href="../applications/custom.html">we’ve written a tutorial</a> for installing one on our system. If there is anything that isn’t clear in this tutorial, please let us know so that we can help you. If you’re comfortable with making your environment, we still recommend that you have a look through the tutorial since it also covers how to point Strudel at your environment so that you can run Jupyter Lab sessions with it.</p>
<p>All of our <a href="../applications/documentation.html">documentation</a> is <a href="https://github.com/mitchellshargreaves-monash/MLeRP-Documentation">publicly available on GitHub</a>. If you feel like our documentation is lacking, we encourage you to submit Issues and Pull Requests to help us make it better for all of you. Even if you’re not contributing, cloning the repository is a great way to get easy access to our notebook tutorials to explore the functionality of the cluster.</p>
<p>Until next time,<br>
Kind Regards,<br>
Mitchell</p>



 ]]></description>
  <guid>https://docs.mlerp.cloud.edu.au/release/notes002.html</guid>
  <pubDate>Fri, 22 Sep 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Release Notes #1</title>
  <dc:creator>Mitchell Hargreaves</dc:creator>
  <link>https://docs.mlerp.cloud.edu.au/release/notes001.html</link>
  <description><![CDATA[ 



<p>Hello MLeRP users,</p>
<p>I hope you are all doing well.</p>
<p>I have received a message from a user asking about getting help with provisioning, so I wanted to clear up that I provisioned all accounts according to your requested usernames and dataset sizes before the launch event. Meaning that you can all log in and test things right now through the <a href="https://mlerp.cloud.edu.au/login">login portal</a>. I apologise if that wasn’t communicated clearly. The cluster has been very quiet recently, making now a great time to test the system without any wait time. If you’re not sure where to start, have a look at <a href="../tutorials/0_getting_started.html">this tutorial</a> or have a look at our documentation on <a href="../applications/strudel2.html">connecting through the web portal</a>.</p>
<p>Speaking of, we have just improved our documentation on alternative methods for connecting to the cluster through <a href="../connecting/ssossh.html">SSH</a> or <a href="../connecting/vscode.html">VS Code remote sessions</a>. If this sounds like something that’s interesting to you, we’d love to get some feedback on this.</p>
<p>Since we last spoke at the launch event we’ve been working behind the scenes on some of your requested features. We’ve updated the user permissions of the home directory to 700 rather than 755. This means that privacy is now the default rather than collaboration. You still have the flexibility to change the permissions on your files if you’d like to do so.</p>
<p>We’ve also been having a think about the best way to implement the requested multiday low resource CPU notebooks (which we’ve been tentatively calling the Panther QoS internally). This is likely going to require changing the way we structure the cluster’s partitions under the hood, so we’ve hold off on implementing things so far but it’s on our radar. We’ll be in touch with more details when we have something for you all to try out.</p>
<p>Kind regards,<br>
Mitchell Hargreaves</p>



 ]]></description>
  <guid>https://docs.mlerp.cloud.edu.au/release/notes001.html</guid>
  <pubDate>Tue, 05 Sep 2023 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
