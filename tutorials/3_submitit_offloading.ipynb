{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: SubmitIt Offloading\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "  ipynb: default\n",
    "execute:\n",
    "    freeze: true\n",
    "format-links: [ipynb]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SubmitIt is a lower level library than Dask which you can also use to offload parts of your notebook to the SLURM queue. Rather than managing a cluster, you will instead directly be submitting python functions to the SLURM queue giving you more control. For more information, have a read of their [PyPi page](https://pypi.org/project/submitit/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import submitit\n",
    "\n",
    "# Define where we'd like submitit to place our logs\n",
    "executor = submitit.AutoExecutor(folder='~/submitit_logs')\n",
    "\n",
    "# Define the parameters of our slurm job\n",
    "# Just like Dasks' job_extra_directives, additional_parameters allows us to specify things that submitit doesn't support directly\n",
    "executor.update_parameters(timeout_min=30, mem_gb=128, cpus_per_task=16, slurm_partition=\"BigCats\", slurm_additional_parameters={\"gres\": \"gpu:1\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can submit our function to the cluster with the `executor.submit` method. This will return a future which can be unpacked with its result using `future.result()` just like when we were working with Dask. Because we are offloading to the SLURM queue print statements will not be visible, just like with Dask `SLURMClusters`. However, the full stack trace is still visible when an error or assertion is raised within the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_test(input1, input2, error=False, test=False):\n",
    "    # Force an error\n",
    "    if error:\n",
    "        assert 0 == 1\n",
    "    \n",
    "    # Stop after one batch when testing        \n",
    "    if test: \n",
    "        print(\"When running in a local cluster you can see print statements!\")\n",
    "\n",
    "    return input1, input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('input1', 'input2')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future = executor.submit(client_test, \"input1\", \"input2\", test=True)\n",
    "future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedJobError",
     "evalue": "Job (task=0) failed during processing with trace:\n----------------------\nTraceback (most recent call last):\n  File \"/apps/mambaforge/envs/dsks_2024.06/lib/python3.10/site-packages/submitit/core/submission.py\", line 55, in process_job\n    result = delayed.result()\n  File \"/apps/mambaforge/envs/dsks_2024.06/lib/python3.10/site-packages/submitit/core/utils.py\", line 133, in result\n    self._result = self.function(*self.args, **self.kwargs)\n  File \"/tmp/ipykernel_1235436/858968069.py\", line 4, in client_test\nAssertionError\n\n----------------------\nYou can check full logs with 'job.stderr(0)' and 'job.stdout(0)'or at paths:\n  - /home/mhar0048/submitit_logs/6952_0_log.err\n  - /home/mhar0048/submitit_logs/6952_0_log.out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedJobError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m future \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39msubmit(client_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput2\u001b[39m\u001b[38;5;124m\"\u001b[39m, error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/apps/mambaforge/envs/dsks_2024.06/lib/python3.10/site-packages/submitit/core/core.py:266\u001b[0m, in \u001b[0;36mJob.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m R:\n\u001b[0;32m--> 266\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sub_jobs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should use `results()` if your job has subtasks.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/apps/mambaforge/envs/dsks_2024.06/lib/python3.10/site-packages/submitit/core/core.py:294\u001b[0m, in \u001b[0;36mJob.results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m job_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown job exception\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m job_exception  \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [result]\n",
      "\u001b[0;31mFailedJobError\u001b[0m: Job (task=0) failed during processing with trace:\n----------------------\nTraceback (most recent call last):\n  File \"/apps/mambaforge/envs/dsks_2024.06/lib/python3.10/site-packages/submitit/core/submission.py\", line 55, in process_job\n    result = delayed.result()\n  File \"/apps/mambaforge/envs/dsks_2024.06/lib/python3.10/site-packages/submitit/core/utils.py\", line 133, in result\n    self._result = self.function(*self.args, **self.kwargs)\n  File \"/tmp/ipykernel_1235436/858968069.py\", line 4, in client_test\nAssertionError\n\n----------------------\nYou can check full logs with 'job.stderr(0)' and 'job.stdout(0)'or at paths:\n  - /home/mhar0048/submitit_logs/6952_0_log.err\n  - /home/mhar0048/submitit_logs/6952_0_log.out"
     ]
    }
   ],
   "source": [
    "future = executor.submit(client_test, \"input1\", \"input2\", error=True)\n",
    "future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since we are interacting directly with the queue, we don't need to clean up and shut down our cluster when using SubmitIt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If needed we can be more specific about the specific GPU type and QoS we need if we have more complex requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/mambaforge/envs/dsks_2024.06/lib/python3.10/site-packages/submitit/auto/auto.py:23: UserWarning: Setting 'additional_parameters' is deprecated. Use 'slurm_additional_parameters' instead.\n",
      "  warnings.warn(f\"Setting '{arg}' is deprecated. Use '{new_arg}' instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('input1', 'input2')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor.update_parameters(timeout_min=30, mem_gb=128, cpus_per_task=16, slurm_partition=\"BigCats\", slurm_additional_parameters={\"gres\": \"gpu:3g.20gb:1\", \"partition\": \"BigCats\"})\n",
    "executor.submit(client_test, \"input1\", \"input2\", test=True).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Dask\n",
    "As you can see, we've implemented the same use case with both Dask and SubmitIt. Which begs the question - which should you use for your research?\n",
    "\n",
    "Both packages have pros and cons, but on the whole, Dask is much better suited towards tasks which can benefit from being broken into many small tasks - like when preprocessing your data. SubmitIt on the other hand is much better suited for use cases where you are looking to offload one larger job at a time, like when you are training.\n",
    "\n",
    "Of the two, Dask is the more mature package with more flexibility and complete documentation - but if you are looking for a simple offloading package it is often far more complexity than you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "db096b8404a4f1f3e1df0cc89f001e138448327417ef835d10f5a76aa612f160"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
