{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Dask SLURMClusters\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "  ipynb: default\n",
    "execute:\n",
    "    freeze: true\n",
    "format-links: [ipynb]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLeRP notebook environment uses Dask SLURMClusters to create a middle ground that has the interactivity of a notebook backed by the power of a GPU Cluster. This notebook shows how you can use the lion service to use a CPU based notebook session for your basic analysis and code development. Then, when you're ready to run tests you will use Dask to submit your python functions to the SLURM queue. \n",
    "\n",
    "This enables:\n",
    "\n",
    "- Flexibility to experiment with your dataset interactively\n",
    "- Ability to change compute requirements such as RAM, size of GPU, number of processes and so on... without ever leaving the notebook environment\n",
    "- Elastic scaling of compute\n",
    "- Efficient utilisation of the hardware\n",
    "- Releasing of resources when not in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster\n",
    "import dask\n",
    "\n",
    "# Point Dask to the SLURM to use as it's back end\n",
    "cluster = SLURMCluster(\n",
    "    memory=\"64g\", processes=1, cores=8\n",
    ")\n",
    "\n",
    "# Scale out to 4 nodes\n",
    "num_nodes = 4\n",
    "cluster.scale(num_nodes)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask will now spin our jobs up in anticipation for work to the scale that you specify.\n",
    "\n",
    "You can check in on your jobs like you would with any other SLURM job with `squeue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "               933   BigCats dask-wor mhar0048 PD       0:00      1 (None)\n",
      "               932   BigCats dask-wor mhar0048 PD       0:00      1 (None)\n",
      "               931   BigCats dask-wor mhar0048 PD       0:00      1 (None)\n",
      "               930   BigCats dask-wor mhar0048 PD       0:00      1 (None)\n",
      "               919   BigCats Jupyter  ramachap  R      51:44      1 mlerp-monash-node00\n",
      "               920   BigCats Jupyter  ramachap  R      47:22      1 mlerp-monash-node00\n",
      "               916   BigCats Jupyter    charla  R    5:02:19      1 mlerp-monash-node00\n"
     ]
    }
   ],
   "source": [
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can modify the output of `squeue` to work for you by passing in flags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTITIO            NAME    STATE       TIME    TIME_LEFT CPUS MIN_MEM NODELIST(REASON) QOS\n",
      " BigCats     dask-worker  RUNNING       0:00        30:00    8     60G mlerp-monash-node00 cheetah\n",
      " BigCats     dask-worker  RUNNING       0:00        30:00    8     60G mlerp-monash-node00 cheetah\n",
      " BigCats     dask-worker  RUNNING       0:00        30:00    8     60G mlerp-monash-node00 cheetah\n",
      " BigCats     dask-worker  RUNNING       0:00        30:00    8     60G mlerp-monash-node00 cheetah\n"
     ]
    }
   ],
   "source": [
    "!squeue --me --format \"%.8P %.15j %.8T %.10M %.12L %.4C %.7m %R %q\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use the adapt method, which will let us scale out as we need the compute... and scale back when we're idle letting others use the cluster. \n",
    "\n",
    "We reccommend that you use the adapt method while you're actively developing your code so that you don't need to worry about cleaning up after yourself. The scale method can be used when you're ready to run longer tests with higher utilisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<distributed.deploy.adaptive.Adaptive at 0x7fcf13681270>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.adapt(minimum=0, maximum=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "               919   BigCats Jupyter  ramachap  R      51:44      1 mlerp-monash-node00\n",
      "               920   BigCats Jupyter  ramachap  R      47:22      1 mlerp-monash-node00\n",
      "               930   BigCats dask-wor mhar0048  R       0:00      1 mlerp-monash-node00\n",
      "               931   BigCats dask-wor mhar0048  R       0:00      1 mlerp-monash-node00\n",
      "               932   BigCats dask-wor mhar0048  R       0:00      1 mlerp-monash-node00\n",
      "               933   BigCats dask-wor mhar0048  R       0:00      1 mlerp-monash-node00\n",
      "               916   BigCats Jupyter    charla  R    5:02:19      1 mlerp-monash-node00\n"
     ]
    }
   ],
   "source": [
    "# You may need to run this cell a few times while waiting for Dask to clean up\n",
    "!squeue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask has a UI that will let you see how the tasks are being computed.\n",
    "You won't be able to connect to this with your web browser but VSCode and Jupyter have extensions for you to connect to it. \n",
    "\n",
    "Use the loopback address: http://127.0.0.1:8787 (Adjust the port to the one listed when you make the client if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a dask array and perform some computation. Dask arrays are parallelised across your workers nodes so they can be greater than the size of one worker's memory. Dask evaluates lazily, retuning 'futures' which record the tasks needed to be completed in the compute graph. They can be computed later for its value. \n",
    "\n",
    "Dask also has parallelised implementations of dataframes and collections of objects (called bags). These are written to be as similar as possible to familiar libraries like numpy, pandas and pyspark. You can read more about [arrays](https://docs.dask.org/en/stable/array.html), [dataframes](https://docs.dask.org/en/stable/dataframe.html) and [bags](https://docs.dask.org/en/stable/bag.html) with Dask's documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 7.45 GiB </td>\n",
       "                        <td> 126.51 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1000, 1000, 1000) </td>\n",
       "                        <td> (255, 255, 255) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 64 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"250\" height=\"240\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"30\" x2=\"80\" y2=\"101\" />\n",
       "  <line x1=\"10\" y1=\"61\" x2=\"80\" y2=\"131\" />\n",
       "  <line x1=\"10\" y1=\"91\" x2=\"80\" y2=\"162\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"80\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"138\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"156\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"64\" y2=\"174\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,190.58823529411765 10.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"148\" y2=\"18\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"166\" y2=\"36\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"184\" y2=\"54\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"200\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"40\" y1=\"0\" x2=\"111\" y2=\"70\" />\n",
       "  <line x1=\"71\" y1=\"0\" x2=\"141\" y2=\"70\" />\n",
       "  <line x1=\"101\" y1=\"0\" x2=\"172\" y2=\"70\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"200\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 200.58823529411765,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"200\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"101\" x2=\"200\" y2=\"101\" />\n",
       "  <line x1=\"80\" y1=\"131\" x2=\"200\" y2=\"131\" />\n",
       "  <line x1=\"80\" y1=\"162\" x2=\"200\" y2=\"162\" />\n",
       "  <line x1=\"80\" y1=\"190\" x2=\"200\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"111\" y1=\"70\" x2=\"111\" y2=\"190\" />\n",
       "  <line x1=\"141\" y1=\"70\" x2=\"141\" y2=\"190\" />\n",
       "  <line x1=\"172\" y1=\"70\" x2=\"172\" y2=\"190\" />\n",
       "  <line x1=\"200\" y1=\"70\" x2=\"200\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 200.58823529411765,70.58823529411765 200.58823529411765,190.58823529411765 80.58823529411765,190.58823529411765\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"140.588235\" y=\"210.588235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1000</text>\n",
       "  <text x=\"220.588235\" y=\"130.588235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,220.588235,130.588235)\">1000</text>\n",
       "  <text x=\"35.294118\" y=\"175.294118\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,175.294118)\">1000</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<random_sample, shape=(1000, 1000, 1000), dtype=float64, chunksize=(255, 255, 255), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.array as da\n",
    "x = da.random.random((1000, 1000, 1000))\n",
    "x  # Note how the value of the array hasn't been computed yet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check squeue while this is running to see the jobs dynamically spinning up to perform the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66750137, 0.25089681, 0.7443936 , 0.7159385 , 0.09395558,\n",
       "       0.86980697, 0.11161041, 0.28340384, 0.19653293, 0.69794351])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][:10].compute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can shut down the SLURMCluster now that we're done with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 05:05:33,925 - distributed.deploy.adaptive_core - INFO - Adaptive stop\n"
     ]
    }
   ],
   "source": [
    "# Shut down the cluster\n",
    "client.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "db096b8404a4f1f3e1df0cc89f001e138448327417ef835d10f5a76aa612f160"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
